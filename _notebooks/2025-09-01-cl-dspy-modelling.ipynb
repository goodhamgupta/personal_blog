{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Curriculum Learning ü§ù DSPy: Modelling\"\n",
    "author: Shubham Gupta\n",
    "date: '2025-09-01'\n",
    "image: ../cl_dspy/submission_mlflow_traces.png\n",
    "description: Mapping ConvFinQA and crafting a curriculum for financial QA\n",
    "lightbox: true\n",
    "toc: true\n",
    "footnotes-hover: false\n",
    "resources:\n",
    "  - _2025-09-01-cl-dspy-modelling.html \n",
    "  - 2025-09-01-cl-dspy-modelling_files/*\n",
    "redirect: _2025-09-01-cl-dspy-modelling.html\n",
    "categories:\n",
    "- programming\n",
    "- dspy\n",
    "- curriculum-learning\n",
    "freeze: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our [previous exploration](../2025-08-31-cl-dspy-eda.ipynb), we analyzed 3,458 ConvFinQA records and established a curriculum learning framework with three difficulty stages: **Easy** (‚â§2 ops, simple context), **Medium** (2-3 ops, moderate complexity), and **Hard** (‚â•4 ops, complex multi-turn reasoning). \n",
    "\n",
    "Now it's time to put this curriculum to work by implementing and evaluating our models.\n",
    "\n",
    "## From Prompting to Programming\n",
    "\n",
    "Traditionally, LLM applications rely on hand-rolled prompts‚Äîcarefully crafted text instructions that are often brittle and difficult to optimize, especially for complex multi-step reasoning tasks like financial QA.\n",
    "\n",
    "Our curriculum learning approach demands systematic experimentation across models, difficulty levels, and optimization strategies. This makes DSPy the ideal framework, as it transforms prompting from an art into systematic, testable code.\n",
    "\n",
    "**Why DSPy for curriculum learning?**\n",
    "\n",
    "- **Reproducible experiments**: Prompts become Python objects ‚Üí diffable, unit-testable, version-controlled\n",
    "- **Optimization**: Built-in optimizers (LabeledFewShot, BootstrapFewShot) auto-search the prompt space across our curriculum stages\n",
    "- **Clean evaluation pipeline**: First-class metrics support‚Äîplug in exact match, hit .compile(), get train/val loops with curriculum-aware sampling\n",
    "- **Model flexibility**: Test curriculum effects across GPT-4, o4-mini, Gemini, and open-source models with one-line swaps\n",
    "- **Efficient iteration**: Caching and threading speed up development cycles crucial for curriculum experiments\n",
    "\n",
    "This approach lets us test whether our Easy‚ÜíMedium‚ÜíHard curriculum improves financial reasoning compared to random sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exploratory analysis, we need a clear metric to measure model performance across our curriculum learning experiments. Following the original ConvFinQA paper, we adopt **Exact Match (EM)** as our primary evaluation metric.\n",
    "\n",
    "### Primary Metric: Turn-level EM\n",
    "\n",
    "**Turn-level EM** measures whether the generated answer for a specific dialogue turn exactly matches the gold standard answer. This binary metric (1 for exact match, 0 otherwise) provides a strict but interpretable measure of performance that directly aligns with the task requirements.\n",
    "\n",
    "We choose this as our primary metric for several reasons:\n",
    "- **Simplicity**: Easy to implement and interpret for initial experimentation\n",
    "- **Strictness**: Financial reasoning requires precision‚Äîapproximate answers can be misleading\n",
    "- **Comparability**: Direct comparison with baseline results from the original paper\n",
    "- **Curriculum sensitivity**: Clear signal for measuring improvement across difficulty levels\n",
    "\n",
    "### Additional Metrics (Future Work)\n",
    "\n",
    "There are several other metrics could be useful:\n",
    "\n",
    "**Conversation-level metrics** like Dialogue Mean EM and Joint EM would better capture multi-turn reasoning dependencies, but add complexity to curriculum design. Since our curriculum is based on individual example difficulty rather than conversation-level complexity, turn-level metrics are more appropriate for this phase.\n",
    "\n",
    "**Diagnostic metrics** such as Exec-agree % and numeric error analysis would help distinguish between reasoning failures and execution errors. However, for establishing whether curriculum learning improves over random sampling, the binary success signal from exact match provides sufficient discriminative power.\n",
    "\n",
    "**Efficiency metrics** like program length and evidence tokens could reveal interesting patterns about how curriculum learning affects model behavior, but are secondary to establishing basic performance improvements.\n",
    "\n",
    "We've skipped the other metrics for now for the sake of brevity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider the following _families_ of models:\n",
    "\n",
    "| Family | Rationale | Benchmarked Checkpoints |\n",
    "|--------|-----------|-------------------------|\n",
    "| **Non-Reasoning** | Classic next-token predictors. Useful as baselines for curriculum-learning because they expose the value of explicit reasoning. | ‚Ä¢ `openai/gpt-4.1-2025-04-14`  <br>‚Ä¢ `openai/gpt-4.1-mini-2025-04-14` |\n",
    "| **Reasoning** | Architected for multi-step, chain-of-thought inference. Expected to excel once the curriculum introduces compositional tasks. | ‚Ä¢ `openai/o4-mini-2025-04-16` <br>‚Ä¢ `anthropic/claude-sonnet-4-20250514` <br>‚Ä¢ `gemini-2.5-flash` <br>‚Ä¢ `gemini-2.5-flash-lite` |\n",
    "| **Frontier** | Flagship models from frontier labs. Highest quality but costly‚Äîkept only for upper-bound comparisons, not final deployment. | ‚Ä¢ `openai/o3-2025-04-16` <br>‚Ä¢ `anthropic/claude-opus-4-20250514` <br>‚Ä¢ `gemini-2.5-pro` |\n",
    "| **Open-Source** | Critical for cost-sensitive deployments(an OS models FTW). Benchmarked to quantify the closed‚Äìopen gap. | ‚Ä¢ `qwen3-32b` |\n",
    "\n",
    "### Two-Stage Gating Protocol\n",
    "\n",
    "1. **Gate**  \n",
    "   ‚Ä¢ Dataset: 50 ‚ÄúEasy‚Äù teacher-forced dialogues  \n",
    "   ‚Ä¢ Retain a model only if **Turn-EM ‚â• 0.55**\n",
    "\n",
    "2. **Probe**  \n",
    "   ‚Ä¢ Dataset: 30 dialogues (15 Medium + 15 Hard), closed-loop  \n",
    "   ‚Ä¢ Retain a model only if **Final-Turn EM ‚â• 0.35** _and_ **Dialogue-mean EM ‚â• 0.35**\n",
    "\n",
    "This pipeline quickly eliminates weak candidates while preserving models whose strengths surface in longer, reasoning-heavy contexts.\n",
    "\n",
    "### Experiment Tracking\n",
    "\n",
    "All training and evaluation runs are logged with **MLflow**:\n",
    "\n",
    "- MLflow Tracking ‚Äì run metadata, metrics, and artifacts for DSPy experiments  \n",
    "- MLflow Model ‚Äì package DSPy programs for reproducible rollout  \n",
    "- MLflow Evaluate ‚Äì built-in GenAI evaluators for rapid iteration  \n",
    "- MLflow Tracing ‚Äì one-line capture of DSPy internals for debugging\n",
    "\n",
    "In production, the deployment pipeline would look as follows:\n",
    "\n",
    "<p align=\"center\">,\n",
    "  <img src=\"../cl_dspy/mlflow_dspy.png\" alt=\"DSPy Production deployment with MLFlow. Source: DSPy Docs\" width=\"200\" height=\"300\"/>,\n",
    "  <br>,\n",
    "  <sub>,\n",
    "    DSPy Production deployment with MLFlow. Source: <a href=\"https://mlflow.org/docs/latest/genai/flavors/dspy/\">MLFlow Docs</a>,\n",
    "  </sub>,\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1753611058221, experiment_id='1', last_update_time=1753611058221, lifecycle_stage='active', name='DSPy', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "from IPython.display import IFrame, HTML, display\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.dspy.autolog(log_compiles=True, log_evals=True, log_traces_from_compile=True)\n",
    "result = mlflow.set_experiment(\"DSPy\")\n",
    "\n",
    "# Display MLFlow UI in an iframe to prevent HTML document conflicts\n",
    "print(f\"Experiment: {result.name} (ID: {result.experiment_id})\")\n",
    "display(HTML(f'<p><a href=\"http://localhost:5000/#/experiments/{result.experiment_id}\" target=\"_blank\">View MLFlow Experiment UI</a></p>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "import dspy\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "MAX_TOKENS = 20_000\n",
    "\n",
    "lm_oai_gpt_4_1 = dspy.LM(\n",
    "    \"openai/gpt-4.1-2025-04-14\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    max_tokens=MAX_TOKENS,\n",
    ")\n",
    "lm_oai_gpt_4_1_mini = dspy.LM(\n",
    "    \"openai/gpt-4.1-mini-2025-04-14\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    max_tokens=MAX_TOKENS,\n",
    ")\n",
    "\n",
    "lm_oai_o4_mini = dspy.LM(\n",
    "    \"openai/o4-mini-2025-04-16\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    temperature=1.0,\n",
    "    max_tokens=MAX_TOKENS,\n",
    ")\n",
    "lm_anthropic_sonnet_4_0 = dspy.LM(\n",
    "    \"anthropic/claude-sonnet-4-20250514\",\n",
    "    api_key=os.environ[\"ANTHROPIC_API_KEY\"],\n",
    "    max_tokens=MAX_TOKENS,\n",
    ")\n",
    "lm_gemini_flash_2_5 = dspy.LM(\n",
    "    \"gemini/gemini-2.5-flash\",\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    max_tokens=MAX_TOKENS,\n",
    ")\n",
    "lm_gemini_flash_2_5_lite = dspy.LM(\n",
    "    \"gemini/gemini-2.5-flash-lite\",\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    max_tokens=MAX_TOKENS,\n",
    ")\n",
    "\n",
    "lm_oai_o3 = dspy.LM(\n",
    "    \"openai/o3-2025-04-16\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    temperature=1.0,\n",
    "    max_tokens=MAX_TOKENS,\n",
    ")\n",
    "lm_anthropic_opus_4_0 = dspy.LM(\n",
    "    \"anthropic/claude-opus-4-20250514\",\n",
    "    api_key=os.environ[\"ANTHROPIC_API_KEY\"],\n",
    "    max_tokens=MAX_TOKENS,\n",
    ")\n",
    "lm_gemini_pro_2_5 = dspy.LM(\n",
    "    \"gemini/gemini-2.5-pro\",\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    max_tokens=MAX_TOKENS,\n",
    ")\n",
    "\n",
    "lm_qwen3_32b = dspy.LM(\n",
    "    \"ollama/qwen3:32b\",\n",
    "    api_base=\"http://localhost:11434\",\n",
    "    api_key=\"\",\n",
    "    max_tokens=MAX_TOKENS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai/gpt-4.1-2025-04-14: Today's date is June 13, 2024.\n",
      "openai/gpt-4.1-mini-2025-04-14: The current date is June 15, 2024.\n",
      "openai/o4-mini-2025-04-16 Reasoning: The user asked for the current date. I will provide today's date in a clear, human-readable format.\n",
      "openai/o4-mini-2025-04-16: The current date is May 30, 2024.\n",
      "anthropic/claude-sonnet-4-20250514 Reasoning: The user is asking for the current date. However, I don't have access to real-time information or the ability to know what the current date is. I should explain that I cannot provide the current date and suggest how they can find this information.\n",
      "anthropic/claude-sonnet-4-20250514: I don't have access to real-time information, so I cannot tell you the current date. To find today's date, you can:\n",
      "- Check your computer, phone, or other device\n",
      "- Search \"what is today's date\" in a search engine\n",
      "- Ask a voice assistant like Siri, Alexa, or Google Assistant\n",
      "gemini/gemini-2.5-flash Reasoning: The user is asking for the current date. I will provide today's date.\n",
      "gemini/gemini-2.5-flash: June 10, 2024\n",
      "gemini/gemini-2.5-flash-lite Reasoning: The user is asking for the current date. I need to access the current date and format it as requested.\n",
      "gemini/gemini-2.5-flash-lite: The current date is October 26, 2023.\n",
      "openai/o3-2025-04-16 Reasoning: I don‚Äôt have real-time access to the system clock, so I‚Äôm unable to determine the exact current date at the moment of this response.\n",
      "openai/o3-2025-04-16: I‚Äôm sorry, I don‚Äôt have access to real-time information to tell today‚Äôs date.\n",
      "anthropic/claude-opus-4-20250514 Reasoning: The user is asking for the current date. However, as an AI assistant, I don't have access to real-time information and cannot provide the current date. I should explain this limitation clearly to the user.\n",
      "anthropic/claude-opus-4-20250514: I don't have access to real-time information, so I cannot tell you today's date. To get the current date, you can check your device's calendar, search \"what's today's date\" in a search engine, or ask a voice assistant with real-time capabilities.\n",
      "gemini/gemini-2.5-pro Reasoning: The user has asked for the current date. I will access my internal system's real-time clock to provide the current calendar date.\n",
      "gemini/gemini-2.5-pro: Today's date is September 10, 2024.\n",
      "ollama/qwen3:32b Reasoning: I cannot access real-time data or the current date. My knowledge is static and up to July 2024. To find the current date, please check your device's clock or calendar.\n",
      "ollama/qwen3:32b: I cannot provide the current date as I do not have access to real-time information. Please check your device's clock or calendar for the current date.\n",
      "üèÉ View run Setup at: http://localhost:5000/#/experiments/1/runs/20df48ca1ad2461d9dcc0b1575caec6d\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=3be570b5035f48159f5f6f8b102b3565&amp;experiment_id=1&amp;trace_id=5ef345c76c844b5786e8d8d54b9de2c6&amp;experiment_id=1&amp;trace_id=9e5a6b35374a4fbc8cbc10bcf48a9765&amp;experiment_id=1&amp;trace_id=f54a2f585a8248feb6f8b0e56b6821ca&amp;experiment_id=1&amp;trace_id=7d0291783ca34ac3a2304daa01790993&amp;experiment_id=1&amp;trace_id=7d7c7c7e1e534a6abdcba8718079d6e1&amp;experiment_id=1&amp;trace_id=0a13673c74a146c4b6fdbfde935a0390&amp;experiment_id=1&amp;trace_id=0e3ebc3c4d1d4d4e8b2cef92e92d608a&amp;experiment_id=1&amp;trace_id=c5866268627d4319a05eb6af34b78672&amp;experiment_id=1&amp;trace_id=1f253b525ef547649472ffd87573560d&amp;experiment_id=1&amp;version=3.1.4\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=3be570b5035f48159f5f6f8b102b3565), Trace(trace_id=5ef345c76c844b5786e8d8d54b9de2c6), Trace(trace_id=9e5a6b35374a4fbc8cbc10bcf48a9765), Trace(trace_id=f54a2f585a8248feb6f8b0e56b6821ca), Trace(trace_id=7d0291783ca34ac3a2304daa01790993), Trace(trace_id=7d7c7c7e1e534a6abdcba8718079d6e1), Trace(trace_id=0a13673c74a146c4b6fdbfde935a0390), Trace(trace_id=0e3ebc3c4d1d4d4e8b2cef92e92d608a), Trace(trace_id=c5866268627d4319a05eb6af34b78672), Trace(trace_id=1f253b525ef547649472ffd87573560d)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "llms = [\n",
    "    lm_oai_gpt_4_1,\n",
    "    lm_oai_gpt_4_1_mini,\n",
    "    lm_oai_o4_mini,\n",
    "    lm_anthropic_sonnet_4_0,\n",
    "    lm_gemini_flash_2_5,\n",
    "    lm_gemini_flash_2_5_lite,\n",
    "    lm_oai_o3,\n",
    "    lm_anthropic_opus_4_0,\n",
    "    lm_gemini_pro_2_5,\n",
    "    lm_qwen3_32b,\n",
    "]\n",
    "\n",
    "\n",
    "class Echo(dspy.Signature):\n",
    "    \"\"\"Echoes the input prompt.\"\"\"\n",
    "\n",
    "    prompt = dspy.InputField()\n",
    "    output = dspy.OutputField()\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"Setup\") as run:\n",
    "    for lm in llms:\n",
    "        try:\n",
    "            with dspy.context(lm=lm, track_usage=True, cache=True):\n",
    "                if lm in [lm_oai_gpt_4_1, lm_oai_gpt_4_1_mini]:\n",
    "                    program = dspy.Predict(\"instruction -> answer\")\n",
    "                else:\n",
    "                    program = dspy.ChainOfThought(\"instruction -> answer\")\n",
    "                response = program(instruction=\"What is the date?\")\n",
    "                if getattr(response, \"reasoning\", None):\n",
    "                    print(f\"{lm.model} Reasoning: {response.reasoning}\")\n",
    "                print(f\"{lm.model}: {response.answer}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{getattr(lm, 'model', lm)}: ERROR - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = json.load(open(\"../data/convfinqa_dataset.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **easy** problems stage, we will select a relatively straightforward implementation. Specifically, we will provide the model with all context, and ask it to answer the question in a zero-shot manner. \n",
    "\n",
    "This will help us identify strong baseline performance, and identify any issues with the model's ability to understand the problem.\n",
    "\n",
    "First, we will create the DSPy signatures for our dataset.\n",
    "Signatures are used to define the input and output of a model.\n",
    "\n",
    "Specifically, we will have two types of signatures: one that doesn't support reasoning model(for direct prediction models like GPT-4.1), and one that does support reasoning mode(for the reasoning models like o3, gemini pro, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SolveTurnWithoutReasoning(dspy.Signature):\n",
    "    conversation_context: str = dspy.InputField(desc=\"Conversation so far\")\n",
    "    evidence_snippets: str = dspy.InputField(\n",
    "        desc=\"Snippets of evidence surrounding the table\"\n",
    "    )\n",
    "    table: str = dspy.InputField(desc=\"Input financial table with metrics\")\n",
    "    question: str = dspy.InputField(desc=\"Question to answer\")\n",
    "\n",
    "    ops: str = dspy.OutputField(\n",
    "        desc=\"Comma-separated ConvFinQA DSL program. Allowed ops: add(x, y), subtract(x, y), multiply(x, y), divide(x, y), exp(x, y), greater(x, y). Args may be constants (e.g., const_100), numbers (int or float), or prior step refs (#0, #1‚Ä¶). Order always follows the pattern x <op> y‚Äîpick x and y deliberately. Example: subtract(const_100, 42), divide(#0, 3.14). Convert to percentages only if explicitly asked in the question.\"\n",
    "    )\n",
    "    answer: str = dspy.OutputField(\n",
    "        desc=\"Final answer. This will be a single number, or a boolean string(yes/no)\"\n",
    "    )\n",
    "\n",
    "\n",
    "class SolveTurnWithReasoning(dspy.Signature):\n",
    "    conversation_context: str = dspy.InputField(desc=\"Conversation so far\")\n",
    "    evidence_snippets: str = dspy.InputField(\n",
    "        desc=\"Snippets of evidence surrounding the table\"\n",
    "    )\n",
    "    table: str = dspy.InputField(desc=\"Input financial table with metrics\")\n",
    "    question: str = dspy.InputField(desc=\"Question to answer\")\n",
    "\n",
    "    reasoning: str = dspy.OutputField(\n",
    "        desc=\"Reasoning behind the answer. Carefully analyze the conversation_context, and especially the evidence_snippets and table for the given question, and generate your reasoning before generating the ops and answer.\"\n",
    "    )\n",
    "    ops: str = dspy.OutputField(\n",
    "        desc=\"Comma-separated ConvFinQA DSL program. Allowed ops: add(x, y), subtract(x, y), multiply(x, y), divide(x, y), exp(x, y), greater(x, y). Args may be constants (e.g., const_100), numbers (int or float), or prior step refs (#0, #1‚Ä¶). Order always follows the pattern x <op> y‚Äîpick x and y deliberately. Example: subtract(const_100, 42), divide(#0, 3.14). Convert to percentages only if explicitly asked in the question.\"\n",
    "    )\n",
    "    answer: str = dspy.OutputField(\n",
    "        desc=\"Final answer. This will be a single number, or a boolean string(yes/no)\"\n",
    "    )\n",
    "\n",
    "\n",
    "class TurnSolver(dspy.Module):\n",
    "    \"\"\"\n",
    "    In the context of this series of interconnected finance-related queries and the additional information provided by the pretext, table data, and posttext from a company's financial filings, please provide a response to the final question. This may require extracting information from the context and performing mathematical calculations. Please take into account the information provided in the preceding questions and their answers when formulating your response: \\n\\n\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, reasoning_lm=False):\n",
    "        super().__init__()\n",
    "        if reasoning_lm:\n",
    "            self.pred = dspy.ChainOfThought(SolveTurnWithReasoning)\n",
    "        else:\n",
    "            self.pred = dspy.Predict(SolveTurnWithoutReasoning)\n",
    "\n",
    "    def forward(self, conversation_context, evidence_snippets, table, question):\n",
    "        \"\"\"\n",
    "        Run the model to solve a single turn.\n",
    "\n",
    "        Args:\n",
    "            conversation_context (str): Conversation so far.\n",
    "            evidence_snippets (str): Evidence text around the table.\n",
    "            table (str): Financial table in markdown.\n",
    "            question (str): Question to answer.\n",
    "\n",
    "        Returns:\n",
    "            dspy.Prediction: Model output with reasoning, ops, and answer.\n",
    "        \"\"\"\n",
    "        return self.pred(\n",
    "            conversation_context=conversation_context,\n",
    "            evidence_snippets=evidence_snippets,\n",
    "            table=table,\n",
    "            question=question,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a few helper functions to format our dataset for the DSPy model.\n",
    "We intentionally don't spend too much time here for now, and will come back to this later, during the _optimization_ phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_ans(x):\n",
    "    \"\"\"\n",
    "    Normalize an answer for comparison.\n",
    "\n",
    "    Converts input to string, strips whitespace, removes percent signs,\n",
    "    and attempts to cast to float. If conversion fails, returns the cleaned string.\n",
    "\n",
    "    Args:\n",
    "        x: The answer to normalize (str, float, or int).\n",
    "\n",
    "    Returns:\n",
    "        float or str: Normalized float if possible, else cleaned string.\n",
    "    \"\"\"\n",
    "    s = str(x).strip().replace(\"%\", \"\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return s\n",
    "\n",
    "\n",
    "def _table_md(table_dict: dict, max_cols: int | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Convert a dictionarised table to compact GitHub-markdown.\n",
    "\n",
    "    Accepted shapes\n",
    "    1) {row_name: {col_name: value, ‚Ä¶}, ‚Ä¶}   # regular 2-level mapping\n",
    "    2) {col_name: value, ‚Ä¶}                  # flat ‚Üí coerced to single row\n",
    "\n",
    "    Guarantees\n",
    "    ‚Ä¢ Original row order is kept.\n",
    "    ‚Ä¢ Column headers are kept in *first-seen* order; NO deduplication.\n",
    "    ‚Ä¢ max_cols (if given) truncates *after* enumeration, duplicates included.\n",
    "    ‚Ä¢ None ‚Üí \"\" and everything else is str()-ed.\n",
    "    \"\"\"\n",
    "    if not table_dict:\n",
    "        return \"\"\n",
    "\n",
    "    if all(not isinstance(v, dict) for v in table_dict.values()):\n",
    "        # flat mapping ‚Üí one anonymous row\n",
    "        table_dict = {\"\": dict(table_dict)}\n",
    "    else:\n",
    "        # ensure every value is a dict\n",
    "        table_dict = {\n",
    "            r: (v if isinstance(v, dict) else {\"\": v}) for r, v in table_dict.items()\n",
    "        }\n",
    "\n",
    "    row_ids = list(table_dict.keys())  # preserve caller order\n",
    "\n",
    "    cols: list = []\n",
    "    for r in row_ids:\n",
    "        cols.extend(table_dict[r].keys())\n",
    "    if max_cols is not None:\n",
    "        cols = cols[:max_cols]\n",
    "\n",
    "    header = \"| Row | \" + \" | \".join(map(str, cols)) + \" |\"\n",
    "    sep = \"|\" + \"---|\" * (len(cols) + 1)\n",
    "    lines = [header, sep]\n",
    "\n",
    "    for r in row_ids:\n",
    "        vals = [str(table_dict[r].get(c, \"\")) for c in cols]\n",
    "        lines.append(\"| \" + str(r) + \" | \" + \" | \".join(vals) + \" |\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def build_inputs_from_row(\n",
    "    row,\n",
    "    turn_idx,\n",
    "    *,\n",
    "    history_mode: str = \"teacher\",\n",
    "    state: dict | None = None,\n",
    "    max_table_cols: int = 100,\n",
    "):\n",
    "    \"\"\"\n",
    "    history_mode: 'teacher' | 'model' | 'none'\n",
    "    state: carries model predictions across turns when history_mode='model'\n",
    "           expected keys: {'pred_answers': list[str|float]}\n",
    "    evidence_builder: optional callable(row, turn_idx)->str; if None, use simple truncation.\n",
    "    \"\"\"\n",
    "    qs = row[\"dialogue_conv_questions\"]\n",
    "    gold = row[\"dialogue_executed_answers\"]\n",
    "\n",
    "    # ---- history ----\n",
    "    history_lines = []\n",
    "    for t in range(turn_idx):\n",
    "        history_lines.append(f\"Q{t + 1}: {qs[t]}\")\n",
    "        if history_mode == \"teacher\":\n",
    "            history_lines.append(f\"A{t + 1}: {gold[t]}\")\n",
    "        elif (\n",
    "            history_mode == \"model\" and state and len(state.get(\"pred_answers\", [])) > t\n",
    "        ):\n",
    "            history_lines.append(f\"A{t + 1}: {state['pred_answers'][t]}\")\n",
    "        elif history_mode == \"none\":\n",
    "            pass  # only questions\n",
    "    conversation_context = \"\\n\".join(history_lines) if history_lines else \"None\"\n",
    "\n",
    "    # compact pre/post: first N sentences\n",
    "    # def first_sents(txt, n):\n",
    "    #     if not txt: return \"\"\n",
    "    #     # very light sentence split\n",
    "    #     parts = [p.strip() for p in txt.split(\". \") if p.strip()]\n",
    "    #     return \". \".join(parts[:n])\n",
    "    # pre = first_sents(row.get(\"doc_pre_text\", \"\") or \"\", max_pre_sents)\n",
    "    # post= first_sents(row.get(\"doc_post_text\", \"\") or \"\", max_post_sents)\n",
    "    # evidence_snippets = f\"[PRE]\\n{pre}\\n[/PRE]\\n[POST]\\n{post}\\n[/POST]\"\n",
    "    evidence_snippets = (\n",
    "        f\"[PRE]\\n{row['doc_pre_text']}\\n[/PRE]\\n[POST]\\n{row['doc_post_text']}\\n[/POST]\"\n",
    "    )\n",
    "    table_md = _table_md(row.get(\"doc_table\", {}) or {}, max_cols=max_table_cols)\n",
    "\n",
    "    return dict(\n",
    "        conversation_context=conversation_context,\n",
    "        evidence_snippets=evidence_snippets,\n",
    "        table=table_md,\n",
    "        question=qs[turn_idx],\n",
    "        **row,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dialogues(model, df):\n",
    "    \"\"\"\n",
    "    Evaluate a dialogue model on a DataFrame of conversations.\n",
    "\n",
    "    Args:\n",
    "        model: Callable that takes unpacked input dict and returns an object with at least `.answer` (and optionally `.ops`).\n",
    "        df: pd.DataFrame with columns:\n",
    "            - \"dialogue_conv_questions\": list of str, all questions in the conversation\n",
    "            - \"dialogue_executed_answers\": list of str/float, all executed answers so far\n",
    "            - (other columns as needed by evidence_builder)\n",
    "\n",
    "    Returns:\n",
    "        dict with:\n",
    "            - \"turn_em_micro\": float, micro-averaged exact match over all turns\n",
    "            - \"dlg_mean_em_macro\": float, macro-averaged mean EM per dialogue\n",
    "            - \"joint_em\": float, fraction of dialogues with all turns correct\n",
    "            - \"final_turn_em\": float, EM on the final turn of each dialogue\n",
    "            - \"n_dialogues\": int, number of dialogues\n",
    "            - \"n_turns\": int, total number of turns\n",
    "    \"\"\"\n",
    "    turn_hits = 0\n",
    "    turn_tot = 0\n",
    "    # exec_hits = 0\n",
    "    dlg_mean_ems = []\n",
    "    dlg_joint_hits = 0\n",
    "    final_hits = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        qs = row[\"dialogue_conv_questions\"]\n",
    "        gold = row[\"dialogue_executed_answers\"]\n",
    "        ems = []\n",
    "        exec_flags = []\n",
    "        for t in range(len(qs)):\n",
    "            inp = build_inputs_from_row(row, t)\n",
    "            out = model(**inp)  # out.ops, out.answer\n",
    "            pa = norm_ans(out.answer)\n",
    "            ga = norm_ans(gold[t])\n",
    "            em = float(pa == ga)\n",
    "            ems.append(em)\n",
    "            turn_hits += em\n",
    "            turn_tot += 1\n",
    "\n",
    "            # (optional) exec check if you have your python DSL evaluator:\n",
    "            # exec_ok = False\n",
    "            # try:\n",
    "            #     # exec_ok = (run_dsl(out.ops, inp) == ga)   # plug your interpreter\n",
    "            #     exec_ok = False\n",
    "            # except Exception:\n",
    "            #     exec_ok = False\n",
    "            # exec_flags.append(exec_ok)\n",
    "            # exec_hits += float(exec_ok)\n",
    "\n",
    "        dlg_mean_ems.append(sum(ems) / len(ems))\n",
    "        if all(v == 1.0 for v in ems):\n",
    "            dlg_joint_hits += 1\n",
    "        final_hits += ems[-1]\n",
    "\n",
    "    return {\n",
    "        \"turn_em_micro\": turn_hits / max(1, turn_tot),\n",
    "        \"dlg_mean_em_macro\": sum(dlg_mean_ems) / max(1, len(dlg_mean_ems)),\n",
    "        \"joint_em\": dlg_joint_hits / max(1, len(dlg_mean_ems)),\n",
    "        \"final_turn_em\": final_hits / max(1, len(dlg_mean_ems)),\n",
    "        # \"exec_agree_rate\": exec_hits / max(1, turn_tot),\n",
    "        \"n_dialogues\": len(dlg_mean_ems),\n",
    "        \"n_turns\": turn_tot,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create the DSPy metric, used to _evaluate_ the performance of our model.\n",
    "\n",
    "We will focus on 2 parts to our metric:\n",
    "- If the answer is a floating point number, we will aim to compare it with the ground truth with some tolerance.\n",
    "- If the answer is a string, we will aim to perform **exact match** via DSPy's `exact_match` metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_em_metric(example, pred, trace=None):\n",
    "    \"\"\"\n",
    "    Compute turn-level exact match (EM) metric for a single example/prediction pair.\n",
    "\n",
    "    Args:\n",
    "        example: dict-like, must contain \"gold_answer\" key.\n",
    "        pred: object with an \"answer\" attribute.\n",
    "\n",
    "    Returns:\n",
    "        float: 1.0 if normalized prediction matches normalized gold answer (with tolerance for floats), else 0.0.\n",
    "    \"\"\"\n",
    "    from dspy.evaluate.metrics import answer_exact_match\n",
    "\n",
    "    pa = norm_ans(pred.answer)\n",
    "    ga = norm_ans(example[\"answer\"])\n",
    "    if isinstance(pa, float) and isinstance(ga, float):\n",
    "        return float(abs(pa - ga) <= 1e-2)\n",
    "    else:\n",
    "        # exact_match in DSPy needs the inputs to be in string format\n",
    "        # due to the normalisations DSPy performs internally.\n",
    "        ground_truth = dspy.Prediction(answer=str(example.answer))\n",
    "        pred_answer = dspy.Prediction(answer=str(pred.answer))\n",
    "        return float(answer_exact_match(ground_truth, pred_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_turn_examples(df, history_mode=\"teacher\"):\n",
    "    examples = []\n",
    "    for _, row in df.iterrows():\n",
    "        qs = row[\"dialogue_conv_questions\"]\n",
    "        gold = row[\"dialogue_executed_answers\"]\n",
    "        for t in range(len(qs)):\n",
    "            inp = build_inputs_from_row(row, t, history_mode=history_mode)\n",
    "            ex = dict(**inp, answer=gold[t])\n",
    "            examples.append(\n",
    "                dspy.Example(**ex).with_inputs(\n",
    "                    \"conversation_context\",\n",
    "                    \"evidence_snippets\",\n",
    "                    \"table\",\n",
    "                    \"question\",\n",
    "                )\n",
    "            )\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will prepare our datasets.\n",
    "\n",
    "We will aim to use the splits as follows:\n",
    "- `train`: Used primarily for the _optimisation_ phase. This will be discussed shortly.\n",
    "- `valid`: Used to evaluate the performance of an LM on an optimised model _trained_ using the train dataset.\n",
    "- `test`: Used to evaluate the performance of an LM on a held-out dataset. This will determine the overall stage performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(data[\"train\"])\n",
    "test_df = pd.DataFrame(data[\"dev\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten features to remove the indexing gymnastics\n",
    "train_flat_df = pd.concat(\n",
    "    [\n",
    "        train_df.drop([\"doc\", \"dialogue\", \"features\"], axis=1),\n",
    "        train_df[\"doc\"].apply(pd.Series).add_prefix(\"doc_\"),\n",
    "        train_df[\"dialogue\"].apply(pd.Series).add_prefix(\"dialogue_\"),\n",
    "        train_df[\"features\"].apply(pd.Series).add_prefix(\"features_\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "test_flat_df = pd.concat(\n",
    "    [\n",
    "        test_df.drop([\"doc\", \"dialogue\", \"features\"], axis=1),\n",
    "        test_df[\"doc\"].apply(pd.Series).add_prefix(\"doc_\"),\n",
    "        test_df[\"dialogue\"].apply(pd.Series).add_prefix(\"dialogue_\"),\n",
    "        test_df[\"features\"].apply(pd.Series).add_prefix(\"features_\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doc_pre_text</th>\n",
       "      <th>doc_post_text</th>\n",
       "      <th>doc_table</th>\n",
       "      <th>dialogue_conv_questions</th>\n",
       "      <th>dialogue_conv_answers</th>\n",
       "      <th>dialogue_turn_program</th>\n",
       "      <th>dialogue_executed_answers</th>\n",
       "      <th>dialogue_qa_split</th>\n",
       "      <th>features_num_dialogue_turns</th>\n",
       "      <th>features_has_type2_question</th>\n",
       "      <th>features_has_duplicate_columns</th>\n",
       "      <th>features_has_non_numeric_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Single_JKHY/2009/page_28.pdf-3</td>\n",
       "      <td>26 | 2009 annual report in fiscal 2008 , revenues in the credit un...</td>\n",
       "      <td>year ended june 30 , cash provided by operations increased $ 25587...</td>\n",
       "      <td>{'Year ended June 30, 2009': {'net income': 103102.0, 'non-cash ex...</td>\n",
       "      <td>[what is the net cash from operating activities in 2009?, what abo...</td>\n",
       "      <td>[206588, 181001, 25587, 14.1%]</td>\n",
       "      <td>[206588, 181001, subtract(206588, 181001), subtract(206588, 181001...</td>\n",
       "      <td>[206588.0, 181001.0, 25587.0, 0.14136]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Single_RSG/2008/page_114.pdf-2</td>\n",
       "      <td>substantially all of the goodwill and other intangible assets reco...</td>\n",
       "      <td>the above unaudited pro forma financial information includes adjus...</td>\n",
       "      <td>{'year ended december 31 2008 ( unaudited )': {'revenue': 9362.2, ...</td>\n",
       "      <td>[what were revenues in 2008?, what were they in 2007?, what was th...</td>\n",
       "      <td>[9362.2, 9244.9, 117.3, 1.3%]</td>\n",
       "      <td>[9362.2, 9244.9, subtract(9362.2, 9244.9), subtract(9362.2, 9244.9...</td>\n",
       "      <td>[9362.2, 9244.9, 117.3, 0.01269]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Single_AAPL/2002/page_23.pdf-1</td>\n",
       "      <td>in a new business model such as the retail segment is inherently r...</td>\n",
       "      <td>.</td>\n",
       "      <td>{'2002': {'net sales': 5742.0, 'cost of sales': 4139.0, 'gross mar...</td>\n",
       "      <td>[what was the total of net sales in 2001?, and what was that in 20...</td>\n",
       "      <td>[5363, 7983, -2620, -32%]</td>\n",
       "      <td>[5363, 7983, subtract(5363, 7983), subtract(5363, 7983), divide(#0...</td>\n",
       "      <td>[5363.0, 7983.0, -2620.0, -0.3282]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Single_UPS/2009/page_33.pdf-2</td>\n",
       "      <td>( 1 ) includes shares repurchased through our publicly announced s...</td>\n",
       "      <td>.</td>\n",
       "      <td>{'12/31/04': {'united parcel service inc .': 100.0, 's&amp;p 500 index...</td>\n",
       "      <td>[what was the change in the performance of the united parcel servi...</td>\n",
       "      <td>[-24.05, -24.05%, 102.11, 2.11, 2.11%, -26.16%]</td>\n",
       "      <td>[subtract(75.95, const_100), subtract(75.95, const_100), divide(#0...</td>\n",
       "      <td>[-24.05, -0.2405, 102.11, 2.11, 0.0211, -0.2616]</td>\n",
       "      <td>[False, False, False, False, False, False]</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Double_UPS/2009/page_33.pdf</td>\n",
       "      <td>( 1 ) includes shares repurchased through our publicly announced s...</td>\n",
       "      <td>.</td>\n",
       "      <td>{'12/31/04': {'united parcel service inc .': 100.0, 's&amp;p 500 index...</td>\n",
       "      <td>[what was the fluctuation of the performance price of the ups from...</td>\n",
       "      <td>[-8.94, -8.9%, -24.05, -24.05%, 2.11, 2.11%, -26.16%]</td>\n",
       "      <td>[subtract(91.06, const_100), subtract(91.06, const_100), divide(#0...</td>\n",
       "      <td>[-8.94, -0.0894, -24.05, -0.2405, 2.11, 0.0211, -0.2616]</td>\n",
       "      <td>[False, False, True, True, True, True, True]</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id  \\\n",
       "0  Single_JKHY/2009/page_28.pdf-3   \n",
       "1  Single_RSG/2008/page_114.pdf-2   \n",
       "2  Single_AAPL/2002/page_23.pdf-1   \n",
       "3   Single_UPS/2009/page_33.pdf-2   \n",
       "4     Double_UPS/2009/page_33.pdf   \n",
       "\n",
       "                                                            doc_pre_text  \\\n",
       "0  26 | 2009 annual report in fiscal 2008 , revenues in the credit un...   \n",
       "1  substantially all of the goodwill and other intangible assets reco...   \n",
       "2  in a new business model such as the retail segment is inherently r...   \n",
       "3  ( 1 ) includes shares repurchased through our publicly announced s...   \n",
       "4  ( 1 ) includes shares repurchased through our publicly announced s...   \n",
       "\n",
       "                                                           doc_post_text  \\\n",
       "0  year ended june 30 , cash provided by operations increased $ 25587...   \n",
       "1  the above unaudited pro forma financial information includes adjus...   \n",
       "2                                                                      .   \n",
       "3                                                                      .   \n",
       "4                                                                      .   \n",
       "\n",
       "                                                               doc_table  \\\n",
       "0  {'Year ended June 30, 2009': {'net income': 103102.0, 'non-cash ex...   \n",
       "1  {'year ended december 31 2008 ( unaudited )': {'revenue': 9362.2, ...   \n",
       "2  {'2002': {'net sales': 5742.0, 'cost of sales': 4139.0, 'gross mar...   \n",
       "3  {'12/31/04': {'united parcel service inc .': 100.0, 's&p 500 index...   \n",
       "4  {'12/31/04': {'united parcel service inc .': 100.0, 's&p 500 index...   \n",
       "\n",
       "                                                 dialogue_conv_questions  \\\n",
       "0  [what is the net cash from operating activities in 2009?, what abo...   \n",
       "1  [what were revenues in 2008?, what were they in 2007?, what was th...   \n",
       "2  [what was the total of net sales in 2001?, and what was that in 20...   \n",
       "3  [what was the change in the performance of the united parcel servi...   \n",
       "4  [what was the fluctuation of the performance price of the ups from...   \n",
       "\n",
       "                                   dialogue_conv_answers  \\\n",
       "0                         [206588, 181001, 25587, 14.1%]   \n",
       "1                          [9362.2, 9244.9, 117.3, 1.3%]   \n",
       "2                              [5363, 7983, -2620, -32%]   \n",
       "3        [-24.05, -24.05%, 102.11, 2.11, 2.11%, -26.16%]   \n",
       "4  [-8.94, -8.9%, -24.05, -24.05%, 2.11, 2.11%, -26.16%]   \n",
       "\n",
       "                                                   dialogue_turn_program  \\\n",
       "0  [206588, 181001, subtract(206588, 181001), subtract(206588, 181001...   \n",
       "1  [9362.2, 9244.9, subtract(9362.2, 9244.9), subtract(9362.2, 9244.9...   \n",
       "2  [5363, 7983, subtract(5363, 7983), subtract(5363, 7983), divide(#0...   \n",
       "3  [subtract(75.95, const_100), subtract(75.95, const_100), divide(#0...   \n",
       "4  [subtract(91.06, const_100), subtract(91.06, const_100), divide(#0...   \n",
       "\n",
       "                                  dialogue_executed_answers  \\\n",
       "0                    [206588.0, 181001.0, 25587.0, 0.14136]   \n",
       "1                          [9362.2, 9244.9, 117.3, 0.01269]   \n",
       "2                        [5363.0, 7983.0, -2620.0, -0.3282]   \n",
       "3          [-24.05, -0.2405, 102.11, 2.11, 0.0211, -0.2616]   \n",
       "4  [-8.94, -0.0894, -24.05, -0.2405, 2.11, 0.0211, -0.2616]   \n",
       "\n",
       "                              dialogue_qa_split  features_num_dialogue_turns  \\\n",
       "0                  [False, False, False, False]                            4   \n",
       "1                  [False, False, False, False]                            4   \n",
       "2                  [False, False, False, False]                            4   \n",
       "3    [False, False, False, False, False, False]                            6   \n",
       "4  [False, False, True, True, True, True, True]                            7   \n",
       "\n",
       "   features_has_type2_question  features_has_duplicate_columns  \\\n",
       "0                        False                           False   \n",
       "1                        False                           False   \n",
       "2                        False                           False   \n",
       "3                        False                           False   \n",
       "4                         True                           False   \n",
       "\n",
       "   features_has_non_numeric_values  \n",
       "0                            False  \n",
       "1                            False  \n",
       "2                            False  \n",
       "3                            False  \n",
       "4                            False  "
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_flat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_train_ids = pd.read_json(\"./splits/easy_train.jsonl\", lines=True)\n",
    "easy_valid_ids = pd.read_json(\"./splits/easy_valid.jsonl\", lines=True)\n",
    "easy_test_ids = pd.read_json(\"./splits/easy_test.jsonl\", lines=True)\n",
    "\n",
    "medium_train_ids = pd.read_json(\"./splits/medium_train.jsonl\", lines=True)\n",
    "medium_valid_ids = pd.read_json(\"./splits/medium_valid.jsonl\", lines=True)\n",
    "medium_test_ids = pd.read_json(\"./splits/medium_test.jsonl\", lines=True)\n",
    "\n",
    "hard_train_ids = pd.read_json(\"./splits/hard_train.jsonl\", lines=True)\n",
    "hard_valid_ids = pd.read_json(\"./splits/hard_valid.jsonl\", lines=True)\n",
    "hard_test_ids = pd.read_json(\"./splits/hard_test.jsonl\", lines=True)\n",
    "\n",
    "easy_train_df = train_flat_df[train_flat_df[\"id\"].isin(easy_train_ids[\"id\"])].copy()\n",
    "easy_valid_df = train_flat_df[train_flat_df[\"id\"].isin(easy_valid_ids[\"id\"])].copy()\n",
    "easy_test_df = test_flat_df[test_flat_df[\"id\"].isin(easy_test_ids[\"id\"])].copy()\n",
    "\n",
    "medium_train_df = train_flat_df[train_flat_df[\"id\"].isin(medium_train_ids[\"id\"])].copy()\n",
    "medium_valid_df = train_flat_df[train_flat_df[\"id\"].isin(medium_valid_ids[\"id\"])].copy()\n",
    "medium_test_df = test_flat_df[test_flat_df[\"id\"].isin(medium_test_ids[\"id\"])].copy()\n",
    "\n",
    "hard_train_df = train_flat_df[train_flat_df[\"id\"].isin(hard_train_ids[\"id\"])].copy()\n",
    "hard_valid_df = train_flat_df[train_flat_df[\"id\"].isin(hard_valid_ids[\"id\"])].copy()\n",
    "hard_test_df = test_flat_df[test_flat_df[\"id\"].isin(hard_test_ids[\"id\"])].copy()\n",
    "\n",
    "assert easy_train_ids.shape[0] == easy_train_df.shape[0]\n",
    "assert easy_valid_ids.shape[0] == easy_valid_df.shape[0]\n",
    "assert easy_test_ids.shape[0] == easy_test_df.shape[0]\n",
    "assert medium_train_ids.shape[0] == medium_train_df.shape[0]\n",
    "assert medium_valid_ids.shape[0] == medium_valid_df.shape[0]\n",
    "assert medium_test_ids.shape[0] == medium_test_df.shape[0]\n",
    "assert hard_train_ids.shape[0] == hard_train_df.shape[0]\n",
    "assert hard_valid_ids.shape[0] == hard_valid_df.shape[0]\n",
    "assert hard_test_ids.shape[0] == hard_test_df.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_train_examples = to_turn_examples(easy_train_df)\n",
    "easy_valid_examples = to_turn_examples(easy_valid_df)\n",
    "easy_test_examples = to_turn_examples(easy_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "852"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(easy_train_examples + easy_valid_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will used DSPy's `Evaluate` class to run our evals in parallel(internally, this is just implemented via threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure our setup works as expected, we will run a simple test first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 10 (80.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:18:42 INFO dspy.evaluate.evaluate: Average Metric: 8.0 / 10 (80.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_context</th>\n",
       "      <th>evidence_snippets</th>\n",
       "      <th>table</th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "      <th>doc_pre_text</th>\n",
       "      <th>doc_post_text</th>\n",
       "      <th>doc_table</th>\n",
       "      <th>dialogue_conv_questions</th>\n",
       "      <th>dialogue_conv_answers</th>\n",
       "      <th>...</th>\n",
       "      <th>dialogue_executed_answers</th>\n",
       "      <th>dialogue_qa_split</th>\n",
       "      <th>features_num_dialogue_turns</th>\n",
       "      <th>features_has_type2_question</th>\n",
       "      <th>features_has_duplicate_columns</th>\n",
       "      <th>features_has_non_numeric_values</th>\n",
       "      <th>example_answer</th>\n",
       "      <th>ops</th>\n",
       "      <th>pred_answer</th>\n",
       "      <th>turn_em_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>[PRE] entergy corporation and subsidiaries management's financial ...</td>\n",
       "      <td>| Row | 2009 net revenue | volume/weather | retail electric price ...</td>\n",
       "      <td>what was the difference in net revenue between 2009 and 2010?</td>\n",
       "      <td>Single_ETR/2011/page_22.pdf-3</td>\n",
       "      <td>entergy corporation and subsidiaries management's financial discus...</td>\n",
       "      <td>the volume/weather variance is primarily due to an increase of 836...</td>\n",
       "      <td>{'amount ( in millions )': {'2009 net revenue': 4694.0, 'volume/we...</td>\n",
       "      <td>['what was the difference in net revenue between 2009 and 2010?', ...</td>\n",
       "      <td>[357, 4694, 7.61%]</td>\n",
       "      <td>...</td>\n",
       "      <td>[357.0, 4694.0, 0.07605]</td>\n",
       "      <td>[False, False, False]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>357.00000</td>\n",
       "      <td>subtract(2010 net revenue, 2009 net revenue)</td>\n",
       "      <td>357.0</td>\n",
       "      <td>‚úîÔ∏è [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1: what was the difference in net revenue between 2009 and 2010?\\...</td>\n",
       "      <td>[PRE] entergy corporation and subsidiaries management's financial ...</td>\n",
       "      <td>| Row | 2009 net revenue | volume/weather | retail electric price ...</td>\n",
       "      <td>and the specific value for 2009 again?</td>\n",
       "      <td>Single_ETR/2011/page_22.pdf-3</td>\n",
       "      <td>entergy corporation and subsidiaries management's financial discus...</td>\n",
       "      <td>the volume/weather variance is primarily due to an increase of 836...</td>\n",
       "      <td>{'amount ( in millions )': {'2009 net revenue': 4694.0, 'volume/we...</td>\n",
       "      <td>['what was the difference in net revenue between 2009 and 2010?', ...</td>\n",
       "      <td>[357, 4694, 7.61%]</td>\n",
       "      <td>...</td>\n",
       "      <td>[357.0, 4694.0, 0.07605]</td>\n",
       "      <td>[False, False, False]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4694.00000</td>\n",
       "      <td>4694.0</td>\n",
       "      <td>4694.0</td>\n",
       "      <td>‚úîÔ∏è [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1: what was the difference in net revenue between 2009 and 2010?\\...</td>\n",
       "      <td>[PRE] entergy corporation and subsidiaries management's financial ...</td>\n",
       "      <td>| Row | 2009 net revenue | volume/weather | retail electric price ...</td>\n",
       "      <td>so what was the percentage change during this time?</td>\n",
       "      <td>Single_ETR/2011/page_22.pdf-3</td>\n",
       "      <td>entergy corporation and subsidiaries management's financial discus...</td>\n",
       "      <td>the volume/weather variance is primarily due to an increase of 836...</td>\n",
       "      <td>{'amount ( in millions )': {'2009 net revenue': 4694.0, 'volume/we...</td>\n",
       "      <td>['what was the difference in net revenue between 2009 and 2010?', ...</td>\n",
       "      <td>[357, 4694, 7.61%]</td>\n",
       "      <td>...</td>\n",
       "      <td>[357.0, 4694.0, 0.07605]</td>\n",
       "      <td>[False, False, False]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.07605</td>\n",
       "      <td>subtract(5051.0, 4694.0), divide(#0, 4694.0), multiply(#1, const_100)</td>\n",
       "      <td>7.61</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>[PRE] entergy new orleans , inc . management's financial discussio...</td>\n",
       "      <td>| Row | 2003 net revenue | base rates | volume/weather | 2004 defe...</td>\n",
       "      <td>what was the net revenue in 2004?</td>\n",
       "      <td>Single_ETR/2004/page_258.pdf-4</td>\n",
       "      <td>entergy new orleans , inc . management's financial discussion and ...</td>\n",
       "      <td>the increase in base rates was effective june 2003 . the rate incr...</td>\n",
       "      <td>{'( in millions )': {'2003 net revenue': 208.3, 'base rates': 10.6...</td>\n",
       "      <td>[what was the net revenue in 2004?, what was the net revenue in 20...</td>\n",
       "      <td>[239.0, 208.3, 30.7, 14.7%]</td>\n",
       "      <td>...</td>\n",
       "      <td>[239.0, 208.3, 30.7, 0.14738]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>239.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>239.0</td>\n",
       "      <td>‚úîÔ∏è [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1: what was the net revenue in 2004?\\nA1: 239.0</td>\n",
       "      <td>[PRE] entergy new orleans , inc . management's financial discussio...</td>\n",
       "      <td>| Row | 2003 net revenue | base rates | volume/weather | 2004 defe...</td>\n",
       "      <td>what was the net revenue in 2003?</td>\n",
       "      <td>Single_ETR/2004/page_258.pdf-4</td>\n",
       "      <td>entergy new orleans , inc . management's financial discussion and ...</td>\n",
       "      <td>the increase in base rates was effective june 2003 . the rate incr...</td>\n",
       "      <td>{'( in millions )': {'2003 net revenue': 208.3, 'base rates': 10.6...</td>\n",
       "      <td>[what was the net revenue in 2004?, what was the net revenue in 20...</td>\n",
       "      <td>[239.0, 208.3, 30.7, 14.7%]</td>\n",
       "      <td>...</td>\n",
       "      <td>[239.0, 208.3, 30.7, 0.14738]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>208.30000</td>\n",
       "      <td>None</td>\n",
       "      <td>208.3</td>\n",
       "      <td>‚úîÔ∏è [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q1: what was the net revenue in 2004?\\nA1: 239.0\\nQ2: what was the...</td>\n",
       "      <td>[PRE] entergy new orleans , inc . management's financial discussio...</td>\n",
       "      <td>| Row | 2003 net revenue | base rates | volume/weather | 2004 defe...</td>\n",
       "      <td>what was the change in value?</td>\n",
       "      <td>Single_ETR/2004/page_258.pdf-4</td>\n",
       "      <td>entergy new orleans , inc . management's financial discussion and ...</td>\n",
       "      <td>the increase in base rates was effective june 2003 . the rate incr...</td>\n",
       "      <td>{'( in millions )': {'2003 net revenue': 208.3, 'base rates': 10.6...</td>\n",
       "      <td>[what was the net revenue in 2004?, what was the net revenue in 20...</td>\n",
       "      <td>[239.0, 208.3, 30.7, 14.7%]</td>\n",
       "      <td>...</td>\n",
       "      <td>[239.0, 208.3, 30.7, 0.14738]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30.70000</td>\n",
       "      <td>subtract(239.0, 208.3)</td>\n",
       "      <td>30.7</td>\n",
       "      <td>‚úîÔ∏è [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q1: what was the net revenue in 2004? A1: 239.0 Q2: what was the n...</td>\n",
       "      <td>[PRE] entergy new orleans , inc . management's financial discussio...</td>\n",
       "      <td>| Row | 2003 net revenue | base rates | volume/weather | 2004 defe...</td>\n",
       "      <td>what is the percent change?</td>\n",
       "      <td>Single_ETR/2004/page_258.pdf-4</td>\n",
       "      <td>entergy new orleans , inc . management's financial discussion and ...</td>\n",
       "      <td>the increase in base rates was effective june 2003 . the rate incr...</td>\n",
       "      <td>{'( in millions )': {'2003 net revenue': 208.3, 'base rates': 10.6...</td>\n",
       "      <td>[what was the net revenue in 2004?, what was the net revenue in 20...</td>\n",
       "      <td>[239.0, 208.3, 30.7, 14.7%]</td>\n",
       "      <td>...</td>\n",
       "      <td>[239.0, 208.3, 30.7, 0.14738]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.14738</td>\n",
       "      <td>subtract(239.0, 208.3), divide(#0, 208.3), multiply(#1, 100)</td>\n",
       "      <td>14.72</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>[PRE] nike , inc . notes to consolidated financial statements 2014...</td>\n",
       "      <td>| Row | severance and related costs | cash payments | non-cash sto...</td>\n",
       "      <td>what was the value of the sale of the starter brand?</td>\n",
       "      <td>Single_NKE/2009/page_81.pdf-1</td>\n",
       "      <td>nike , inc . notes to consolidated financial statements 2014 ( con...</td>\n",
       "      <td>the accrual balance as of may 31 , 2009 will be relieved throughou...</td>\n",
       "      <td>{'$ 2014': {'severance and related costs': 195.0, 'cash payments':...</td>\n",
       "      <td>['what was the value of the sale of the starter brand?', 'what was...</td>\n",
       "      <td>[60.0, 28.6, 31.4, 91%]</td>\n",
       "      <td>...</td>\n",
       "      <td>[60.0, 28.6, 31.4, 0.91083]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>60.0</td>\n",
       "      <td>‚úîÔ∏è [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q1: what was the value of the sale of the starter brand?\\nA1: 60.0</td>\n",
       "      <td>[PRE] nike , inc . notes to consolidated financial statements 2014...</td>\n",
       "      <td>| Row | severance and related costs | cash payments | non-cash sto...</td>\n",
       "      <td>what was the gain resulting from the sale?</td>\n",
       "      <td>Single_NKE/2009/page_81.pdf-1</td>\n",
       "      <td>nike , inc . notes to consolidated financial statements 2014 ( con...</td>\n",
       "      <td>the accrual balance as of may 31 , 2009 will be relieved throughou...</td>\n",
       "      <td>{'$ 2014': {'severance and related costs': 195.0, 'cash payments':...</td>\n",
       "      <td>['what was the value of the sale of the starter brand?', 'what was...</td>\n",
       "      <td>[60.0, 28.6, 31.4, 91%]</td>\n",
       "      <td>...</td>\n",
       "      <td>[60.0, 28.6, 31.4, 0.91083]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>28.60000</td>\n",
       "      <td>None</td>\n",
       "      <td>28.6</td>\n",
       "      <td>‚úîÔ∏è [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q1: what was the value of the sale of the starter brand?\\nA1: 60.0...</td>\n",
       "      <td>[PRE] nike , inc . notes to consolidated financial statements 2014...</td>\n",
       "      <td>| Row | severance and related costs | cash payments | non-cash sto...</td>\n",
       "      <td>what was the change in value?</td>\n",
       "      <td>Single_NKE/2009/page_81.pdf-1</td>\n",
       "      <td>nike , inc . notes to consolidated financial statements 2014 ( con...</td>\n",
       "      <td>the accrual balance as of may 31 , 2009 will be relieved throughou...</td>\n",
       "      <td>{'$ 2014': {'severance and related costs': 195.0, 'cash payments':...</td>\n",
       "      <td>['what was the value of the sale of the starter brand?', 'what was...</td>\n",
       "      <td>[60.0, 28.6, 31.4, 91%]</td>\n",
       "      <td>...</td>\n",
       "      <td>[60.0, 28.6, 31.4, 0.91083]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31.40000</td>\n",
       "      <td>subtract(60.0, 28.6)</td>\n",
       "      <td>31.4</td>\n",
       "      <td>‚úîÔ∏è [1.000]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    conversation_context  \\\n",
       "0                                                                   None   \n",
       "1  Q1: what was the difference in net revenue between 2009 and 2010?\\...   \n",
       "2  Q1: what was the difference in net revenue between 2009 and 2010?\\...   \n",
       "3                                                                   None   \n",
       "4                       Q1: what was the net revenue in 2004?\\nA1: 239.0   \n",
       "5  Q1: what was the net revenue in 2004?\\nA1: 239.0\\nQ2: what was the...   \n",
       "6  Q1: what was the net revenue in 2004? A1: 239.0 Q2: what was the n...   \n",
       "7                                                                   None   \n",
       "8     Q1: what was the value of the sale of the starter brand?\\nA1: 60.0   \n",
       "9  Q1: what was the value of the sale of the starter brand?\\nA1: 60.0...   \n",
       "\n",
       "                                                       evidence_snippets  \\\n",
       "0  [PRE] entergy corporation and subsidiaries management's financial ...   \n",
       "1  [PRE] entergy corporation and subsidiaries management's financial ...   \n",
       "2  [PRE] entergy corporation and subsidiaries management's financial ...   \n",
       "3  [PRE] entergy new orleans , inc . management's financial discussio...   \n",
       "4  [PRE] entergy new orleans , inc . management's financial discussio...   \n",
       "5  [PRE] entergy new orleans , inc . management's financial discussio...   \n",
       "6  [PRE] entergy new orleans , inc . management's financial discussio...   \n",
       "7  [PRE] nike , inc . notes to consolidated financial statements 2014...   \n",
       "8  [PRE] nike , inc . notes to consolidated financial statements 2014...   \n",
       "9  [PRE] nike , inc . notes to consolidated financial statements 2014...   \n",
       "\n",
       "                                                                   table  \\\n",
       "0  | Row | 2009 net revenue | volume/weather | retail electric price ...   \n",
       "1  | Row | 2009 net revenue | volume/weather | retail electric price ...   \n",
       "2  | Row | 2009 net revenue | volume/weather | retail electric price ...   \n",
       "3  | Row | 2003 net revenue | base rates | volume/weather | 2004 defe...   \n",
       "4  | Row | 2003 net revenue | base rates | volume/weather | 2004 defe...   \n",
       "5  | Row | 2003 net revenue | base rates | volume/weather | 2004 defe...   \n",
       "6  | Row | 2003 net revenue | base rates | volume/weather | 2004 defe...   \n",
       "7  | Row | severance and related costs | cash payments | non-cash sto...   \n",
       "8  | Row | severance and related costs | cash payments | non-cash sto...   \n",
       "9  | Row | severance and related costs | cash payments | non-cash sto...   \n",
       "\n",
       "                                                        question  \\\n",
       "0  what was the difference in net revenue between 2009 and 2010?   \n",
       "1                         and the specific value for 2009 again?   \n",
       "2            so what was the percentage change during this time?   \n",
       "3                              what was the net revenue in 2004?   \n",
       "4                              what was the net revenue in 2003?   \n",
       "5                                  what was the change in value?   \n",
       "6                                    what is the percent change?   \n",
       "7           what was the value of the sale of the starter brand?   \n",
       "8                     what was the gain resulting from the sale?   \n",
       "9                                  what was the change in value?   \n",
       "\n",
       "                               id  \\\n",
       "0   Single_ETR/2011/page_22.pdf-3   \n",
       "1   Single_ETR/2011/page_22.pdf-3   \n",
       "2   Single_ETR/2011/page_22.pdf-3   \n",
       "3  Single_ETR/2004/page_258.pdf-4   \n",
       "4  Single_ETR/2004/page_258.pdf-4   \n",
       "5  Single_ETR/2004/page_258.pdf-4   \n",
       "6  Single_ETR/2004/page_258.pdf-4   \n",
       "7   Single_NKE/2009/page_81.pdf-1   \n",
       "8   Single_NKE/2009/page_81.pdf-1   \n",
       "9   Single_NKE/2009/page_81.pdf-1   \n",
       "\n",
       "                                                            doc_pre_text  \\\n",
       "0  entergy corporation and subsidiaries management's financial discus...   \n",
       "1  entergy corporation and subsidiaries management's financial discus...   \n",
       "2  entergy corporation and subsidiaries management's financial discus...   \n",
       "3  entergy new orleans , inc . management's financial discussion and ...   \n",
       "4  entergy new orleans , inc . management's financial discussion and ...   \n",
       "5  entergy new orleans , inc . management's financial discussion and ...   \n",
       "6  entergy new orleans , inc . management's financial discussion and ...   \n",
       "7  nike , inc . notes to consolidated financial statements 2014 ( con...   \n",
       "8  nike , inc . notes to consolidated financial statements 2014 ( con...   \n",
       "9  nike , inc . notes to consolidated financial statements 2014 ( con...   \n",
       "\n",
       "                                                           doc_post_text  \\\n",
       "0  the volume/weather variance is primarily due to an increase of 836...   \n",
       "1  the volume/weather variance is primarily due to an increase of 836...   \n",
       "2  the volume/weather variance is primarily due to an increase of 836...   \n",
       "3  the increase in base rates was effective june 2003 . the rate incr...   \n",
       "4  the increase in base rates was effective june 2003 . the rate incr...   \n",
       "5  the increase in base rates was effective june 2003 . the rate incr...   \n",
       "6  the increase in base rates was effective june 2003 . the rate incr...   \n",
       "7  the accrual balance as of may 31 , 2009 will be relieved throughou...   \n",
       "8  the accrual balance as of may 31 , 2009 will be relieved throughou...   \n",
       "9  the accrual balance as of may 31 , 2009 will be relieved throughou...   \n",
       "\n",
       "                                                               doc_table  \\\n",
       "0  {'amount ( in millions )': {'2009 net revenue': 4694.0, 'volume/we...   \n",
       "1  {'amount ( in millions )': {'2009 net revenue': 4694.0, 'volume/we...   \n",
       "2  {'amount ( in millions )': {'2009 net revenue': 4694.0, 'volume/we...   \n",
       "3  {'( in millions )': {'2003 net revenue': 208.3, 'base rates': 10.6...   \n",
       "4  {'( in millions )': {'2003 net revenue': 208.3, 'base rates': 10.6...   \n",
       "5  {'( in millions )': {'2003 net revenue': 208.3, 'base rates': 10.6...   \n",
       "6  {'( in millions )': {'2003 net revenue': 208.3, 'base rates': 10.6...   \n",
       "7  {'$ 2014': {'severance and related costs': 195.0, 'cash payments':...   \n",
       "8  {'$ 2014': {'severance and related costs': 195.0, 'cash payments':...   \n",
       "9  {'$ 2014': {'severance and related costs': 195.0, 'cash payments':...   \n",
       "\n",
       "                                                 dialogue_conv_questions  \\\n",
       "0  ['what was the difference in net revenue between 2009 and 2010?', ...   \n",
       "1  ['what was the difference in net revenue between 2009 and 2010?', ...   \n",
       "2  ['what was the difference in net revenue between 2009 and 2010?', ...   \n",
       "3  [what was the net revenue in 2004?, what was the net revenue in 20...   \n",
       "4  [what was the net revenue in 2004?, what was the net revenue in 20...   \n",
       "5  [what was the net revenue in 2004?, what was the net revenue in 20...   \n",
       "6  [what was the net revenue in 2004?, what was the net revenue in 20...   \n",
       "7  ['what was the value of the sale of the starter brand?', 'what was...   \n",
       "8  ['what was the value of the sale of the starter brand?', 'what was...   \n",
       "9  ['what was the value of the sale of the starter brand?', 'what was...   \n",
       "\n",
       "         dialogue_conv_answers  ...      dialogue_executed_answers  \\\n",
       "0           [357, 4694, 7.61%]  ...       [357.0, 4694.0, 0.07605]   \n",
       "1           [357, 4694, 7.61%]  ...       [357.0, 4694.0, 0.07605]   \n",
       "2           [357, 4694, 7.61%]  ...       [357.0, 4694.0, 0.07605]   \n",
       "3  [239.0, 208.3, 30.7, 14.7%]  ...  [239.0, 208.3, 30.7, 0.14738]   \n",
       "4  [239.0, 208.3, 30.7, 14.7%]  ...  [239.0, 208.3, 30.7, 0.14738]   \n",
       "5  [239.0, 208.3, 30.7, 14.7%]  ...  [239.0, 208.3, 30.7, 0.14738]   \n",
       "6  [239.0, 208.3, 30.7, 14.7%]  ...  [239.0, 208.3, 30.7, 0.14738]   \n",
       "7      [60.0, 28.6, 31.4, 91%]  ...    [60.0, 28.6, 31.4, 0.91083]   \n",
       "8      [60.0, 28.6, 31.4, 91%]  ...    [60.0, 28.6, 31.4, 0.91083]   \n",
       "9      [60.0, 28.6, 31.4, 91%]  ...    [60.0, 28.6, 31.4, 0.91083]   \n",
       "\n",
       "              dialogue_qa_split features_num_dialogue_turns  \\\n",
       "0         [False, False, False]                           3   \n",
       "1         [False, False, False]                           3   \n",
       "2         [False, False, False]                           3   \n",
       "3  [False, False, False, False]                           4   \n",
       "4  [False, False, False, False]                           4   \n",
       "5  [False, False, False, False]                           4   \n",
       "6  [False, False, False, False]                           4   \n",
       "7  [False, False, False, False]                           4   \n",
       "8  [False, False, False, False]                           4   \n",
       "9  [False, False, False, False]                           4   \n",
       "\n",
       "   features_has_type2_question  features_has_duplicate_columns  \\\n",
       "0                        False                           False   \n",
       "1                        False                           False   \n",
       "2                        False                           False   \n",
       "3                        False                           False   \n",
       "4                        False                           False   \n",
       "5                        False                           False   \n",
       "6                        False                           False   \n",
       "7                        False                           False   \n",
       "8                        False                           False   \n",
       "9                        False                           False   \n",
       "\n",
       "   features_has_non_numeric_values  example_answer  \\\n",
       "0                            False       357.00000   \n",
       "1                            False      4694.00000   \n",
       "2                            False         0.07605   \n",
       "3                            False       239.00000   \n",
       "4                            False       208.30000   \n",
       "5                            False        30.70000   \n",
       "6                            False         0.14738   \n",
       "7                            False        60.00000   \n",
       "8                            False        28.60000   \n",
       "9                            False        31.40000   \n",
       "\n",
       "                                                                     ops  \\\n",
       "0                           subtract(2010 net revenue, 2009 net revenue)   \n",
       "1                                                                 4694.0   \n",
       "2  subtract(5051.0, 4694.0), divide(#0, 4694.0), multiply(#1, const_100)   \n",
       "3                                                                   None   \n",
       "4                                                                   None   \n",
       "5                                                 subtract(239.0, 208.3)   \n",
       "6           subtract(239.0, 208.3), divide(#0, 208.3), multiply(#1, 100)   \n",
       "7                                                                   None   \n",
       "8                                                                   None   \n",
       "9                                                   subtract(60.0, 28.6)   \n",
       "\n",
       "  pred_answer turn_em_metric  \n",
       "0       357.0     ‚úîÔ∏è [1.000]  \n",
       "1      4694.0     ‚úîÔ∏è [1.000]  \n",
       "2        7.61                 \n",
       "3       239.0     ‚úîÔ∏è [1.000]  \n",
       "4       208.3     ‚úîÔ∏è [1.000]  \n",
       "5        30.7     ‚úîÔ∏è [1.000]  \n",
       "6       14.72                 \n",
       "7        60.0     ‚úîÔ∏è [1.000]  \n",
       "8        28.6     ‚úîÔ∏è [1.000]  \n",
       "9        31.4     ‚úîÔ∏è [1.000]  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/a5433773d6ef4e359825412ad138c520\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=caea82d0bc0c4f0d800313b99bd69581&amp;experiment_id=1&amp;trace_id=ed4476c7920b49f3b2e909e88548e086&amp;experiment_id=1&amp;trace_id=6ba8b539ea0f49798599b294060d1213&amp;experiment_id=1&amp;trace_id=711aae8d07b14f619312af02495f941a&amp;experiment_id=1&amp;trace_id=fd97772c93064b3daf30f61009d81fe2&amp;experiment_id=1&amp;trace_id=5b665669eca649c9bd46b04a6f9737ad&amp;experiment_id=1&amp;trace_id=23be442a4d64413abe335a55bebe6a5a&amp;experiment_id=1&amp;trace_id=d057b5aed88a46fb8562a39db0ebd15d&amp;experiment_id=1&amp;trace_id=02f1ddeee02448f58babae2fb6afa3b9&amp;experiment_id=1&amp;trace_id=8e058d1aa41a4932a83c8f0505a867fd&amp;experiment_id=1&amp;version=3.1.4\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=caea82d0bc0c4f0d800313b99bd69581), Trace(trace_id=ed4476c7920b49f3b2e909e88548e086), Trace(trace_id=6ba8b539ea0f49798599b294060d1213), Trace(trace_id=711aae8d07b14f619312af02495f941a), Trace(trace_id=fd97772c93064b3daf30f61009d81fe2), Trace(trace_id=5b665669eca649c9bd46b04a6f9737ad), Trace(trace_id=23be442a4d64413abe335a55bebe6a5a), Trace(trace_id=d057b5aed88a46fb8562a39db0ebd15d), Trace(trace_id=02f1ddeee02448f58babae2fb6afa3b9), Trace(trace_id=8e058d1aa41a4932a83c8f0505a867fd)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "evaluator = Evaluate(\n",
    "    devset=easy_valid_examples[:10],\n",
    "    num_threads=32,\n",
    "    display_progress=True,\n",
    "    display_table=True,\n",
    "    provide_traceback=True,\n",
    "    return_all_scores=True,\n",
    "    return_outputs=True,\n",
    ")\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "tlm = deepcopy(lm_oai_gpt_4_1)\n",
    "tlm.cache = False\n",
    "\n",
    "# HACK: Weird bug in dspy where the context doesn't set the cache to False, causing answers to be returned from memory. I've found that creating a deepcopy and setting the attribute manually fixes this.\n",
    "with dspy.context(lm=tlm) as ctx:\n",
    "    evaluator(TurnSolver(reasoning_lm=False), metric=turn_em_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "bootstrap_rs_random_easy_subset = random.sample(easy_train_examples, 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 3 traces per predictor.\n",
      "Will attempt to bootstrap 5 candidate sets.\n",
      "Average Metric: 45.00 / 70 (64.3%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:00<00:00, 87.74it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:08 INFO dspy.evaluate.evaluate: Average Metric: 45.0 / 70 (64.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_0 at: http://localhost:5000/#/experiments/3/runs/fcce9b07d50e41609bc04c3d9c2235c7\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "New best score: 64.29 for seed -3\n",
      "Scores so far: [64.29]\n",
      "Best score so far: 64.29\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:08 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 26.00 / 38 (68.4%):  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 37/70 [00:00<00:00, 82.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:08 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 46.00 / 70 (65.7%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:00<00:00, 76.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:09 INFO dspy.evaluate.evaluate: Average Metric: 46.0 / 70 (65.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_1 at: http://localhost:5000/#/experiments/3/runs/7575401319f442499f871ca8d849bfd1\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "New best score: 65.71 for seed -2\n",
      "Scores so far: [64.29, 65.71]\n",
      "Best score so far: 65.71\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa596c147174804958bfd90f9e69998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 3/70 [00:00<00:04, 13.83it/s]2025/07/29 01:03:09 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "  9%|‚ñä         | 6/70 [00:00<00:03, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fac575b2f714ab3a5f079b5b8c068e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 47.00 / 70 (67.1%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 62.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:11 INFO dspy.evaluate.evaluate: Average Metric: 47.0 / 70 (67.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_2 at: http://localhost:5000/#/experiments/3/runs/3406309f3f0a4041a580021eaf5eff13\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "New best score: 67.14 for seed -1\n",
      "Scores so far: [64.29, 65.71, 67.14]\n",
      "Best score so far: 67.14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9352e516d8b848579ba0d22b01c35fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 2/70 [00:00<00:02, 32.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd46b6737ed8418484d64e9cef39a594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 48.00 / 70 (68.6%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 52.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:12 INFO dspy.evaluate.evaluate: Average Metric: 48.0 / 70 (68.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_3 at: http://localhost:5000/#/experiments/3/runs/8cad7a93fb494289a4d6691d5796f84e\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "New best score: 68.57 for seed 0\n",
      "Scores so far: [64.29, 65.71, 67.14, 68.57]\n",
      "Best score so far: 68.57\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d7fe20fa6b4fb7bb39768109a6e96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/70 [00:00<00:03, 18.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ac51afacd244629a94d3d29cc78260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 46.00 / 70 (65.7%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 54.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:15 INFO dspy.evaluate.evaluate: Average Metric: 46.0 / 70 (65.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_4 at: http://localhost:5000/#/experiments/3/runs/ab8c076e18394080bbf9634eeff7af35\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "Scores so far: [64.29, 65.71, 67.14, 68.57, 65.71]\n",
      "Best score so far: 68.57\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a5a9849439471b90be1451f4ed6d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/70 [00:00<00:02, 24.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795ab895387b4c0e9eac571ee453ac88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 45.00 / 70 (64.3%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 44.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:17 INFO dspy.evaluate.evaluate: Average Metric: 45.0 / 70 (64.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_5 at: http://localhost:5000/#/experiments/3/runs/679c914720674946a877f4a6a91665ee\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "Scores so far: [64.29, 65.71, 67.14, 68.57, 65.71, 64.29]\n",
      "Best score so far: 68.57\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650c0bd2cb2a4041bdf156931c25130c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/70 [00:00<00:12,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16c05df32404d64b8a8431d48d39234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 47.00 / 70 (67.1%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 61.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:19 INFO dspy.evaluate.evaluate: Average Metric: 47.0 / 70 (67.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_6 at: http://localhost:5000/#/experiments/3/runs/ab818ec11652430b9bd68e17dc197665\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "Scores so far: [64.29, 65.71, 67.14, 68.57, 65.71, 64.29, 67.14]\n",
      "Best score so far: 68.57\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0479a155634a4c4ba4d92bebca0b0727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/70 [00:00<00:02, 28.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea69ff24378d45a3998851b5aa0962d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 51.00 / 70 (72.9%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 51.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:21 INFO dspy.evaluate.evaluate: Average Metric: 51.0 / 70 (72.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_7 at: http://localhost:5000/#/experiments/3/runs/f9f17e61c1334a9ea6903ae3a1105fd8\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "New best score: 72.86 for seed 4\n",
      "Scores so far: [64.29, 65.71, 67.14, 68.57, 65.71, 64.29, 67.14, 72.86]\n",
      "Best score so far: 72.86\n",
      "8 candidate programs found.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8c7a6497d04213a381c037724d4895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bootstrap_few_shot_rs_openai_o4-mini-2025-04-16 at: http://localhost:5000/#/experiments/3/runs/b08500752c9041d5acccbc261bd33931\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "Going to sample between 1 and 3 traces per predictor.\n",
      "Will attempt to bootstrap 5 candidate sets.\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:21 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 43.00 / 70 (61.4%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 48.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:22 INFO dspy.evaluate.evaluate: Average Metric: 43.0 / 70 (61.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_0 at: http://localhost:5000/#/experiments/3/runs/578a2f04172f4ecbb41d04350201b2d5\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "New best score: 61.43 for seed -3\n",
      "Scores so far: [61.43]\n",
      "Best score so far: 61.43\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:23 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.00 / 42 (69.0%):  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 41/70 [00:01<00:00, 32.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:24 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 35.00 / 51 (68.6%):  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 50/70 [00:01<00:00, 42.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:24 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 47.00 / 70 (67.1%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 43.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:24 INFO dspy.evaluate.evaluate: Average Metric: 47.0 / 70 (67.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_1 at: http://localhost:5000/#/experiments/3/runs/cf868ddb4c5945149422186e878e4ee8\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "New best score: 67.14 for seed -2\n",
      "Scores so far: [61.43, 67.14]\n",
      "Best score so far: 67.14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc397a6b03924336bbc43a1bd839784c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñä         | 6/70 [00:00<00:03, 16.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43544d6f72f40dbaae08ad6b18cb0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 46.00 / 70 (65.7%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 65.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:27 INFO dspy.evaluate.evaluate: Average Metric: 46.0 / 70 (65.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_2 at: http://localhost:5000/#/experiments/3/runs/a83ba7facae34ee2b495fd0bcb478044\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "Scores so far: [61.43, 67.14, 65.71]\n",
      "Best score so far: 67.14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7c85dbd6f64f61a359ea5a37c40ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 2/70 [00:00<00:03, 21.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6913487151e04ab7a89037c30da2cfd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 46.00 / 70 (65.7%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 36.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:30 INFO dspy.evaluate.evaluate: Average Metric: 46.0 / 70 (65.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_3 at: http://localhost:5000/#/experiments/3/runs/343b2f8e893044da9a9bee74f6be8853\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "Scores so far: [61.43, 67.14, 65.71, 65.71]\n",
      "Best score so far: 67.14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6a3e6ba2a646a093455efcf2d34a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/70 [00:00<00:02, 28.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102094c059e84577861cd1271f22e414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 45.00 / 70 (64.3%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 37.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:32 INFO dspy.evaluate.evaluate: Average Metric: 45.0 / 70 (64.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_4 at: http://localhost:5000/#/experiments/3/runs/3ad1f0eea05b4d7b88e7c47e2c0c29ab\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "Scores so far: [61.43, 67.14, 65.71, 65.71, 64.29]\n",
      "Best score so far: 67.14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5351ffa3e234f7f92c3f1932b3dd438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/70 [00:00<00:02, 25.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e11c2f024d4ec090827c250d4258ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 47.00 / 70 (67.1%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 35.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:34 INFO dspy.evaluate.evaluate: Average Metric: 47.0 / 70 (67.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_5 at: http://localhost:5000/#/experiments/3/runs/29b7cf7738bc47d89e81309a65595be0\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "Scores so far: [61.43, 67.14, 65.71, 65.71, 64.29, 67.14]\n",
      "Best score so far: 67.14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cff124f59634e5b9279882b0501180a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/70 [00:00<00:10,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043eb11fea0a462684dac9bbb48f4f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 48.00 / 70 (68.6%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:02<00:00, 31.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:38 INFO dspy.evaluate.evaluate: Average Metric: 48.0 / 70 (68.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_6 at: http://localhost:5000/#/experiments/3/runs/d3a6322d0555421784dbb34087099455\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "New best score: 68.57 for seed 3\n",
      "Scores so far: [61.43, 67.14, 65.71, 65.71, 64.29, 67.14, 68.57]\n",
      "Best score so far: 68.57\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e694033bfb9e4689bd6c07fc39d0801c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/70 [00:00<00:05, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db37866855a049b88bb7e4c9dd3597c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 60.00 / 70 (85.7%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:02<00:00, 28.22it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:41 INFO dspy.evaluate.evaluate: Average Metric: 60.0 / 70 (85.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_7 at: http://localhost:5000/#/experiments/3/runs/93c1cafdbb6b440699788970eb6ffa88\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "New best score: 85.71 for seed 4\n",
      "Scores so far: [61.43, 67.14, 65.71, 65.71, 64.29, 67.14, 68.57, 85.71]\n",
      "Best score so far: 85.71\n",
      "8 candidate programs found.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fd5af0c6644afc978088bc68e1ee83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bootstrap_few_shot_rs_gemini_gemini-2_5-flash at: http://localhost:5000/#/experiments/3/runs/621ba195ed244875a4370e2050418a06\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "Going to sample between 1 and 3 traces per predictor.\n",
      "Will attempt to bootstrap 5 candidate sets.\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:42 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/29 01:03:42 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/29 01:03:42 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/29 01:03:43 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 29 (75.9%):  40%|‚ñà‚ñà‚ñà‚ñà      | 28/70 [00:00<00:00, 71.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:43 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 36.00 / 49 (73.5%):  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 48/70 [00:01<00:00, 69.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:44 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 52.00 / 70 (74.3%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 37.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:44 INFO dspy.evaluate.evaluate: Average Metric: 52.0 / 70 (74.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_0 at: http://localhost:5000/#/experiments/3/runs/377a453f2e0745e38fc89508f7ab1d26\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "New best score: 74.29 for seed -3\n",
      "Scores so far: [74.29]\n",
      "Best score so far: 74.29\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:44 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 4 (25.0%):   4%|‚ñç         | 3/70 [00:00<00:17,  3.91it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:45 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 8 (62.5%):  10%|‚ñà         | 7/70 [00:00<00:16,  3.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:45 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 16 (81.2%):  23%|‚ñà‚ñà‚ñé       | 16/70 [00:00<00:01, 39.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:45 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 41 (73.2%):  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 40/70 [00:01<00:01, 17.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:46 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 33.00 / 44 (75.0%):  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 43/70 [00:01<00:01, 17.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:46 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 52.00 / 70 (74.3%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 36.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:46 INFO dspy.evaluate.evaluate: Average Metric: 52.0 / 70 (74.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_1 at: http://localhost:5000/#/experiments/3/runs/d9e37616e88748d8890de6056370f801\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "Scores so far: [74.29, 74.29]\n",
      "Best score so far: 74.29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa8485009e94f079807723d8dbc5ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 4/70 [00:00<00:04, 15.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cce25e5c7941d6bf6a39bcd3c76bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 52.00 / 70 (74.3%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 35.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:03:49 INFO dspy.evaluate.evaluate: Average Metric: 52.0 / 70 (74.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_2 at: http://localhost:5000/#/experiments/3/runs/7bfc22c9728f4862931e5bb8bf4d379e\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "Scores so far: [74.29, 74.29, 74.29]\n",
      "Best score so far: 74.29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90ceb161810483ab7c0fb2a38dd46e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 2/70 [00:12<06:55,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d26bd076e4845b193dfa48d40f9e51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 43.00 / 53 (81.1%):  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 53/70 [00:22<00:09,  1.74it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:04:25 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 50.00 / 68 (73.5%):  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 68/70 [00:55<00:04,  2.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:05:26 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 51.00 / 70 (72.9%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [01:56<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:05:59 INFO dspy.evaluate.evaluate: Average Metric: 51.0 / 70 (72.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_3 at: http://localhost:5000/#/experiments/3/runs/7cc38c776c8c40ad983a78690454b768\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "Scores so far: [74.29, 74.29, 74.29, 72.86]\n",
      "Best score so far: 74.29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bceaac3cdcd48a0b05bc0f5e0c884a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/70 [00:05<06:47,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab959aa00cf145d0984217e3c543fcd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 34.00 / 37 (91.9%):  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 37/70 [00:16<00:15,  2.18it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:06:22 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 49.00 / 62 (79.0%):  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 62/70 [00:33<00:07,  1.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:06:40 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 52.00 / 70 (74.3%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:52<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:06:57 INFO dspy.evaluate.evaluate: Average Metric: 52.0 / 70 (74.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_4 at: http://localhost:5000/#/experiments/3/runs/3d4799840b5145f38c55cd04a510b4eb\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "Scores so far: [74.29, 74.29, 74.29, 72.86, 74.29]\n",
      "Best score so far: 74.29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a19b204ef7443e3964026a61386dbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/70 [00:03<04:04,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0944c174ba5d4b7f888c2c78316eeb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 53.00 / 70 (75.7%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:49<00:00,  1.41it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:07:51 INFO dspy.evaluate.evaluate: Average Metric: 53.0 / 70 (75.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_5 at: http://localhost:5000/#/experiments/3/runs/826af9f09c4e4410b2b21424430e67f1\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "New best score: 75.71 for seed 2\n",
      "Scores so far: [74.29, 74.29, 74.29, 72.86, 74.29, 75.71]\n",
      "Best score so far: 75.71\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58455aed23543369dda147cdcc46ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/70 [00:05<06:22,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9faa0b381e48b4a3239439f9b5c8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 44.00 / 48 (91.7%):  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 48/70 [00:18<00:08,  2.53it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:08:16 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 53.00 / 70 (75.7%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [01:02<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:08:59 INFO dspy.evaluate.evaluate: Average Metric: 53.0 / 70 (75.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_6 at: http://localhost:5000/#/experiments/3/runs/a029e23cfbe14b92a2ba6ce26146642b\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "Scores so far: [74.29, 74.29, 74.29, 72.86, 74.29, 75.71, 75.71]\n",
      "Best score so far: 75.71\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d1357491a342a6b3cbb1a778076b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/70 [00:04<04:43,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3146876614a146569534ee1e0cef7f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 56.00 / 70 (80.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:44<00:00,  1.58it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 01:09:48 INFO dspy.evaluate.evaluate: Average Metric: 56.0 / 70 (80.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval_7 at: http://localhost:5000/#/experiments/3/runs/861f0c753b754e6a8eb3372287edd9bc\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "New best score: 80.0 for seed 4\n",
      "Scores so far: [74.29, 74.29, 74.29, 72.86, 74.29, 75.71, 75.71, 80.0]\n",
      "Best score so far: 80.0\n",
      "8 candidate programs found.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e21760751a482c874fbc57b485e178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bootstrap_few_shot_rs_openai_o3-2025-04-16 at: http://localhost:5000/#/experiments/3/runs/8576b067ea60468ebc37cda1a17be1dc\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "üèÉ View run bootstrap_few_shot_rs_easy at: http://localhost:5000/#/experiments/3/runs/b5f08a070a634f74888fb8c42f24bfa3\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=bc6ccffd18824246934194a85933d3fd&amp;experiment_id=3&amp;trace_id=e37a0ba10d0543bb908e397933697d6d&amp;experiment_id=3&amp;trace_id=b37797a381b44f7eb13e1f42eca0567c&amp;experiment_id=3&amp;trace_id=9a18ced106784364ae12831ce45a8748&amp;experiment_id=3&amp;trace_id=3d7bb8edeb78492bac5473d6e52c4846&amp;experiment_id=3&amp;trace_id=d42d241ebb9e40b1affe006598cae983&amp;experiment_id=3&amp;trace_id=344ea0c049b946e8b780a9e02d720688&amp;experiment_id=3&amp;trace_id=4cac19ef64574b50b38d4baf81b360d5&amp;experiment_id=3&amp;trace_id=c4ca77588233486e9d234e95aa976329&amp;experiment_id=3&amp;trace_id=c9921423c3aa4f16933885eb15242313&amp;experiment_id=3&amp;version=3.1.4\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=bc6ccffd18824246934194a85933d3fd), Trace(trace_id=e37a0ba10d0543bb908e397933697d6d), Trace(trace_id=b37797a381b44f7eb13e1f42eca0567c), Trace(trace_id=9a18ced106784364ae12831ce45a8748), Trace(trace_id=3d7bb8edeb78492bac5473d6e52c4846), Trace(trace_id=d42d241ebb9e40b1affe006598cae983), Trace(trace_id=344ea0c049b946e8b780a9e02d720688), Trace(trace_id=4cac19ef64574b50b38d4baf81b360d5), Trace(trace_id=c4ca77588233486e9d234e95aa976329), Trace(trace_id=c9921423c3aa4f16933885eb15242313)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import litellm\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# Config needed to prevent the optimizer from using _unsupported_ temperature\n",
    "# for reasoning models.\n",
    "litellm.drop_params = True\n",
    "\n",
    "\n",
    "config = dict(\n",
    "    max_bootstrapped_demos=3,\n",
    "    max_labeled_demos=2,\n",
    "    num_candidate_programs=5,\n",
    "    num_threads=32,\n",
    "    max_rounds=1,\n",
    ")\n",
    "\n",
    "bootstrap_rs_easy_compiled_programs = []\n",
    "\n",
    "with mlflow.start_run(run_name=\"bootstrap_few_shot_rs_easy\"):\n",
    "    for candidate_lm in selected_llms:\n",
    "        run_name = f\"bootstrap_few_shot_rs_{candidate_lm.model.replace('/', '_')}\"\n",
    "        sanitized_run_name = re.sub(r\"[^a-zA-Z0-9_\\-]\", \"_\", run_name)\n",
    "        with mlflow.start_run(run_name=sanitized_run_name, nested=True):\n",
    "            with dspy.context(lm=candidate_lm) as ctx:\n",
    "                teleprompter = BootstrapFewShotWithRandomSearch(\n",
    "                    metric=turn_em_metric, **config\n",
    "                )\n",
    "                optimized_program = teleprompter.compile(\n",
    "                    dspy.ChainOfThought(SolveTurnWithReasoning),\n",
    "                    trainset=bootstrap_rs_random_easy_subset,\n",
    "                )\n",
    "                bootstrap_rs_easy_compiled_programs.append(optimized_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, it looks like GPT-4.1 gives an score of 80% on the validation set, WITHOUT ANY PROMPT ENGINEERING/FEW-SHOT PROMPTING. This is great!\n",
    "\n",
    "As mentioned earlier, due to cost and time constraints, we want to first narrow down the list of models we want to test on the harder stages.\n",
    "\n",
    "As a recap, our implementation strategy here will be as follows: instead of just using the performance of the models on the \"easy\" validation set, we will use a combination of two datasets: \n",
    "\n",
    "1. Gate - 50 Easy dialogs, teacher - forced. Drop model if Turn-EM < 0.55.\n",
    "2. Probe - 30-dialog mixed micro-set (15 Medium + 15 Hard, closed loop).\n",
    "   Keep model only if Final-Turn EM ‚â• 0.35, Dialogue-mean EM ‚â• 0.35\n",
    "\n",
    "We will now create our \"gate\" and \"probe\" datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_ids = easy_valid_ids.sample(50, random_state=42)\n",
    "probe_medium_ids = medium_valid_ids.sample(15, random_state=42)\n",
    "probe_hard_ids = hard_valid_ids.sample(30, random_state=42)\n",
    "\n",
    "gate_df = easy_valid_df[easy_valid_df[\"id\"].isin(gate_ids[\"id\"])].copy()\n",
    "probe_df = pd.concat(\n",
    "    [\n",
    "        medium_valid_df[medium_valid_df[\"id\"].isin(probe_medium_ids[\"id\"])],\n",
    "        hard_valid_df[hard_valid_df[\"id\"].isin(probe_hard_ids[\"id\"])],\n",
    "    ]\n",
    ").copy()\n",
    "\n",
    "assert gate_df.shape[0] == gate_ids.shape[0]\n",
    "assert probe_df.shape[0] == probe_medium_ids.shape[0] + probe_hard_ids.shape[0]\n",
    "\n",
    "gate_examples = to_turn_examples(gate_df, history_mode=\"teacher\")\n",
    "probe_examples = to_turn_examples(probe_df, history_mode=\"teacher\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also save the `gate` and `probe` dataset ids, to compare performance of different models on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"validation_datasets\", exist_ok=True)\n",
    "\n",
    "gate_ids.to_json(\"validation_datasets/gate_ids.jsonl\", orient=\"records\", lines=True)\n",
    "probe_medium_ids.to_json(\n",
    "    \"validation_datasets/probe_medium_ids.jsonl\", orient=\"records\", lines=True\n",
    ")\n",
    "probe_hard_ids.to_json(\n",
    "    \"validation_datasets/probe_hard_ids.jsonl\", orient=\"records\", lines=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation_context': 'None',\n",
       " 'evidence_snippets': \"[PRE]\\nentergy corporation and subsidiaries management's financial discussion and analysis refer to 201cselected financial data - five-year comparison of entergy corporation and subsidiaries 201d which accompanies entergy corporation 2019s financial statements in this report for further information with respect to operating statistics . in november 2007 the board approved a plan to pursue a separation of entergy 2019s non-utility nuclear business from entergy through a spin-off of the business to entergy shareholders . in april 2010 , entergy announced that it planned to unwind the business infrastructure associated with the proposed spin-off transaction . as a result of the plan to unwind the business infrastructure , entergy recorded expenses in 2010 for the write-off of certain capitalized costs incurred in connection with the planned spin-off transaction . these costs are discussed in more detail below and throughout this section . net revenue utility following is an analysis of the change in net revenue comparing 2010 to 2009 . amount ( in millions ) .\\n[/PRE]\\n[POST]\\nthe volume/weather variance is primarily due to an increase of 8362 gwh , or 8% ( 8 % ) , in billed electricity usage in all retail sectors , including the effect on the residential sector of colder weather in the first quarter 2010 compared to 2009 and warmer weather in the second and third quarters 2010 compared to 2009 . the industrial sector reflected strong sales growth on continuing signs of economic recovery . the improvement in this sector was primarily driven by inventory restocking and strong exports with the chemicals , refining , and miscellaneous manufacturing sectors leading the improvement . the retail electric price variance is primarily due to : increases in the formula rate plan riders at entergy gulf states louisiana effective november 2009 , january 2010 , and september 2010 , at entergy louisiana effective november 2009 , and at entergy mississippi effective july 2009 ; a base rate increase at entergy arkansas effective july 2010 ; rate actions at entergy texas , including base rate increases effective in may and august 2010 ; a formula rate plan provision of $ 16.6 million recorded in the third quarter 2009 for refunds that were made to customers in accordance with settlements approved by the lpsc ; and the recovery in 2009 by entergy arkansas of 2008 extraordinary storm costs , as approved by the apsc , which ceased in january 2010 . the recovery of storm costs is offset in other operation and maintenance expenses . see note 2 to the financial statements for further discussion of the proceedings referred to above. .\\n[/POST]\",\n",
       " 'table': '| Row | 2009 net revenue | volume/weather | retail electric price | provision for regulatory proceedings | rough production cost equalization | ano decommissioning trust | fuel recovery | other | 2010 net revenue |\\n|---|---|---|---|---|---|---|---|---|---|\\n| amount ( in millions ) | 4694.0 | 231.0 | 137.0 | 26.0 | 19.0 | -24.0 | -44.0 | 12.0 | 5051.0 |',\n",
       " 'question': 'what was the difference in net revenue between 2009 and 2010?',\n",
       " 'id': 'Single_ETR/2011/page_22.pdf-3',\n",
       " 'doc_pre_text': \"entergy corporation and subsidiaries management's financial discussion and analysis refer to 201cselected financial data - five-year comparison of entergy corporation and subsidiaries 201d which accompanies entergy corporation 2019s financial statements in this report for further information with respect to operating statistics . in november 2007 the board approved a plan to pursue a separation of entergy 2019s non-utility nuclear business from entergy through a spin-off of the business to entergy shareholders . in april 2010 , entergy announced that it planned to unwind the business infrastructure associated with the proposed spin-off transaction . as a result of the plan to unwind the business infrastructure , entergy recorded expenses in 2010 for the write-off of certain capitalized costs incurred in connection with the planned spin-off transaction . these costs are discussed in more detail below and throughout this section . net revenue utility following is an analysis of the change in net revenue comparing 2010 to 2009 . amount ( in millions ) .\",\n",
       " 'doc_post_text': 'the volume/weather variance is primarily due to an increase of 8362 gwh , or 8% ( 8 % ) , in billed electricity usage in all retail sectors , including the effect on the residential sector of colder weather in the first quarter 2010 compared to 2009 and warmer weather in the second and third quarters 2010 compared to 2009 . the industrial sector reflected strong sales growth on continuing signs of economic recovery . the improvement in this sector was primarily driven by inventory restocking and strong exports with the chemicals , refining , and miscellaneous manufacturing sectors leading the improvement . the retail electric price variance is primarily due to : increases in the formula rate plan riders at entergy gulf states louisiana effective november 2009 , january 2010 , and september 2010 , at entergy louisiana effective november 2009 , and at entergy mississippi effective july 2009 ; a base rate increase at entergy arkansas effective july 2010 ; rate actions at entergy texas , including base rate increases effective in may and august 2010 ; a formula rate plan provision of $ 16.6 million recorded in the third quarter 2009 for refunds that were made to customers in accordance with settlements approved by the lpsc ; and the recovery in 2009 by entergy arkansas of 2008 extraordinary storm costs , as approved by the apsc , which ceased in january 2010 . the recovery of storm costs is offset in other operation and maintenance expenses . see note 2 to the financial statements for further discussion of the proceedings referred to above. .',\n",
       " 'doc_table': {'amount ( in millions )': {'2009 net revenue': 4694.0,\n",
       "   'volume/weather': 231.0,\n",
       "   'retail electric price': 137.0,\n",
       "   'provision for regulatory proceedings': 26.0,\n",
       "   'rough production cost equalization': 19.0,\n",
       "   'ano decommissioning trust': -24.0,\n",
       "   'fuel recovery': -44.0,\n",
       "   'other': 12.0,\n",
       "   '2010 net revenue': 5051.0}},\n",
       " 'dialogue_conv_questions': ['what was the difference in net revenue between 2009 and 2010?',\n",
       "  'and the specific value for 2009 again?',\n",
       "  'so what was the percentage change during this time?'],\n",
       " 'dialogue_conv_answers': ['357', '4694', '7.61%'],\n",
       " 'dialogue_turn_program': ['subtract(5051, 4694)',\n",
       "  '4694',\n",
       "  'subtract(5051, 4694), divide(#0, 4694)'],\n",
       " 'dialogue_executed_answers': [357.0, 4694.0, 0.07605],\n",
       " 'dialogue_qa_split': [False, False, False],\n",
       " 'features_num_dialogue_turns': 3,\n",
       " 'features_has_type2_question': False,\n",
       " 'features_has_duplicate_columns': False,\n",
       " 'features_has_non_numeric_values': False,\n",
       " 'answer': 357.0}"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_examples[0].toDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation_context': 'None',\n",
       " 'evidence_snippets': \"[PRE]\\nentergy corporation and subsidiaries management's financial discussion and analysis refer to 201cselected financial data - five-year comparison of entergy corporation and subsidiaries 201d which accompanies entergy corporation 2019s financial statements in this report for further information with respect to operating statistics . in november 2007 the board approved a plan to pursue a separation of entergy 2019s non-utility nuclear business from entergy through a spin-off of the business to entergy shareholders . in april 2010 , entergy announced that it planned to unwind the business infrastructure associated with the proposed spin-off transaction . as a result of the plan to unwind the business infrastructure , entergy recorded expenses in 2010 for the write-off of certain capitalized costs incurred in connection with the planned spin-off transaction . these costs are discussed in more detail below and throughout this section . net revenue utility following is an analysis of the change in net revenue comparing 2010 to 2009 . amount ( in millions ) .\\n[/PRE]\\n[POST]\\nthe volume/weather variance is primarily due to an increase of 8362 gwh , or 8% ( 8 % ) , in billed electricity usage in all retail sectors , including the effect on the residential sector of colder weather in the first quarter 2010 compared to 2009 and warmer weather in the second and third quarters 2010 compared to 2009 . the industrial sector reflected strong sales growth on continuing signs of economic recovery . the improvement in this sector was primarily driven by inventory restocking and strong exports with the chemicals , refining , and miscellaneous manufacturing sectors leading the improvement . the retail electric price variance is primarily due to : increases in the formula rate plan riders at entergy gulf states louisiana effective november 2009 , january 2010 , and september 2010 , at entergy louisiana effective november 2009 , and at entergy mississippi effective july 2009 ; a base rate increase at entergy arkansas effective july 2010 ; rate actions at entergy texas , including base rate increases effective in may and august 2010 ; a formula rate plan provision of $ 16.6 million recorded in the third quarter 2009 for refunds that were made to customers in accordance with settlements approved by the lpsc ; and the recovery in 2009 by entergy arkansas of 2008 extraordinary storm costs , as approved by the apsc , which ceased in january 2010 . the recovery of storm costs is offset in other operation and maintenance expenses . see note 2 to the financial statements for further discussion of the proceedings referred to above. .\\n[/POST]\",\n",
       " 'table': '| Row | 2009 net revenue | volume/weather | retail electric price | provision for regulatory proceedings | rough production cost equalization | ano decommissioning trust | fuel recovery | other | 2010 net revenue |\\n|---|---|---|---|---|---|---|---|---|---|\\n| amount ( in millions ) | 4694.0 | 231.0 | 137.0 | 26.0 | 19.0 | -24.0 | -44.0 | 12.0 | 5051.0 |',\n",
       " 'question': 'what was the difference in net revenue between 2009 and 2010?'}"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_examples[0].inputs().toDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gate Dataset Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 10 (80.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 65.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:19:36 INFO dspy.evaluate.evaluate: Average Metric: 8.0 / 10 (80.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/502b5457f9db44339a5afce34d13d847\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_openai_gpt-4_1-2025-04-14 at: http://localhost:5000/#/experiments/1/runs/7e61e1f47f4e408c8cec59ee1bf9c0dd\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 5.00 / 10 (50.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 58.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:19:37 INFO dspy.evaluate.evaluate: Average Metric: 5.0 / 10 (50.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/1b4ea94ac47e4660b30234d6ad78c8d8\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_openai_gpt-4_1-mini-2025-04-14 at: http://localhost:5000/#/experiments/1/runs/fa03278692c848e996a3e43e6422099f\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 6.00 / 10 (60.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 79.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:19:37 INFO dspy.evaluate.evaluate: Average Metric: 6.0 / 10 (60.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/ce1366eaa8c146eabba86650fae12f74\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_openai_o4-mini-2025-04-16 at: http://localhost:5000/#/experiments/1/runs/3d1fb9c72b914d5a942312db0a6a5088\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 6.00 / 10 (60.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 81.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:19:37 INFO dspy.evaluate.evaluate: Average Metric: 6.0 / 10 (60.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/9e00a96bfd114bbaa9e47dcb478b4423\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_anthropic_claude-sonnet-4-20250514 at: http://localhost:5000/#/experiments/1/runs/76c2180b1f3c4510ab13158d3b0d36eb\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 7.00 / 10 (70.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 65.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:19:37 INFO dspy.evaluate.evaluate: Average Metric: 7.0 / 10 (70.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/4a3c7957aaab4a4e972b06a7754fe6d4\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_gemini_gemini-2_5-flash at: http://localhost:5000/#/experiments/1/runs/aa191551b2844b57bb9d2db37e50c4f0\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:19:37 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:19:37 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 10 (70.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 61.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:19:38 INFO dspy.evaluate.evaluate: Average Metric: 7.0 / 10 (70.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/809ee64fbd164475b3592ff2340b2595\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_gemini_gemini-2_5-flash-lite at: http://localhost:5000/#/experiments/1/runs/90ea53b2a2484cc0a5302b7c8245184e\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 8.00 / 10 (80.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 74.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:19:38 INFO dspy.evaluate.evaluate: Average Metric: 8.0 / 10 (80.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/6f1bec87d6ce4137b10e055e94bf54d4\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_openai_o3-2025-04-16 at: http://localhost:5000/#/experiments/1/runs/7e4f8e42c8244b94af37787cacd12ee5\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 7.00 / 10 (70.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 86.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:19:38 INFO dspy.evaluate.evaluate: Average Metric: 7.0 / 10 (70.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/ab105090285e4b55a93205dc6f1bde64\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_anthropic_claude-opus-4-20250514 at: http://localhost:5000/#/experiments/1/runs/58c90aae89644af8a1d2c7dc845b0c07\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 8.00 / 10 (80.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 39.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:19:38 INFO dspy.evaluate.evaluate: Average Metric: 8.0 / 10 (80.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/e786a0b633844e7ebdb6a165561b81ec\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_gemini_gemini-2_5-pro at: http://localhost:5000/#/experiments/1/runs/9e1f42bcc8064a9383ed590c1add4d01\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 7.00 / 10 (70.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 71.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:19:39 INFO dspy.evaluate.evaluate: Average Metric: 7.0 / 10 (70.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/f4ae2cb32a2b401aa5ab8f7b02dc7b86\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_ollama_qwen3_32b at: http://localhost:5000/#/experiments/1/runs/ca6c0d988ca94f2998eb08f339fdf22a\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_dataset_results at: http://localhost:5000/#/experiments/1/runs/0b0e82f0b3724ec1afedde0d7a036dfe\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=9f5fdac684c74647a0a88cbdcd16d89b&amp;experiment_id=1&amp;trace_id=3de6592234f74ca4ba6a450f2a01b37a&amp;experiment_id=1&amp;trace_id=31e022f38c354840b5abbe64b417306d&amp;experiment_id=1&amp;trace_id=0756d03769c4417e861f7171ecb7bcb8&amp;experiment_id=1&amp;trace_id=f1dcee538d454f96a41dc1d59c3a27f9&amp;experiment_id=1&amp;trace_id=283f1f0436c24afabdb9d865b3c0e802&amp;experiment_id=1&amp;trace_id=ddb2286507bd47fd8580b5e8dd923d7e&amp;experiment_id=1&amp;trace_id=427f384f2d604830844675df25de1226&amp;experiment_id=1&amp;trace_id=789bab02c70346c1a50c91de5f67376b&amp;experiment_id=1&amp;trace_id=2c112f9efbb44a9796a0ca64a43b8b5d&amp;experiment_id=1&amp;version=3.1.4\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=9f5fdac684c74647a0a88cbdcd16d89b), Trace(trace_id=3de6592234f74ca4ba6a450f2a01b37a), Trace(trace_id=31e022f38c354840b5abbe64b417306d), Trace(trace_id=0756d03769c4417e861f7171ecb7bcb8), Trace(trace_id=f1dcee538d454f96a41dc1d59c3a27f9), Trace(trace_id=283f1f0436c24afabdb9d865b3c0e802), Trace(trace_id=ddb2286507bd47fd8580b5e8dd923d7e), Trace(trace_id=427f384f2d604830844675df25de1226), Trace(trace_id=789bab02c70346c1a50c91de5f67376b), Trace(trace_id=2c112f9efbb44a9796a0ca64a43b8b5d)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "results = []\n",
    "\n",
    "with mlflow.start_run(run_name=\"gate_dataset_results\") as parent_ctx:\n",
    "    for candidate_lm in llms:\n",
    "        run_name = f\"gate_{candidate_lm.model.replace('/', '_')}\"\n",
    "        sanitized_run_name = re.sub(r\"[^a-zA-Z0-9_\\-]\", \"_\", run_name)\n",
    "        with mlflow.start_run(run_name=sanitized_run_name, nested=True):\n",
    "            current_evaluator = Evaluate(\n",
    "                devset=gate_examples[:10],\n",
    "                num_threads=32,\n",
    "                display_progress=True,\n",
    "                # display_table=True,\n",
    "                # provide_traceback=True,\n",
    "                return_all_scores=True,\n",
    "                return_outputs=True,\n",
    "            )\n",
    "            with dspy.context(lm=candidate_lm) as ctx:\n",
    "                current_result = current_evaluator(\n",
    "                    TurnSolver(reasoning_lm=True), metric=turn_em_metric\n",
    "                )\n",
    "                results.append(current_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  LLM  Evaluation Score\n",
      "0           openai/gpt-4.1-2025-04-14              80.0\n",
      "1      openai/gpt-4.1-mini-2025-04-14              50.0\n",
      "2           openai/o4-mini-2025-04-16              60.0\n",
      "3  anthropic/claude-sonnet-4-20250514              60.0\n",
      "4             gemini/gemini-2.5-flash              70.0\n",
      "5        gemini/gemini-2.5-flash-lite              70.0\n",
      "6                openai/o3-2025-04-16              80.0\n",
      "7    anthropic/claude-opus-4-20250514              70.0\n",
      "8               gemini/gemini-2.5-pro              80.0\n",
      "9                    ollama/qwen3:32b              70.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        {\"LLM\": llms[idx].model, \"Evaluation Score\": candidate[0]}\n",
    "        for idx, candidate in enumerate(results)\n",
    "    ]\n",
    ")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the small test above, we see that most of the models score in a similar range. I think it's expected that GPT-4.1-mini performs poorly, given that it's a much smaller model compared to all the competetiors.\n",
    "\n",
    "From the MLFlow logs, we also see that while Qwen3:32b has a relatively high score, inference is quite slow. For now, we will skip this model during the model selection phase, and revisit it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection_llms = [\n",
    "    lm_oai_gpt_4_1,\n",
    "    lm_oai_gpt_4_1_mini,\n",
    "    lm_oai_o4_mini,\n",
    "    lm_anthropic_sonnet_4_0,\n",
    "    lm_gemini_flash_2_5,\n",
    "    lm_gemini_flash_2_5_lite,\n",
    "    lm_oai_o3,\n",
    "    lm_anthropic_opus_4_0,\n",
    "    lm_gemini_pro_2_5,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 95.00 / 151 (62.9%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:02<00:00, 74.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:32 INFO dspy.evaluate.evaluate: Average Metric: 95.0 / 151 (62.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/e18f45df89fb4a0e9e98e6f01d74bf71\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_openai_gpt-4_1-2025-04-14 at: http://localhost:5000/#/experiments/1/runs/f15c1d3760fc489b95ec5950f3e992b9\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 81.00 / 151 (53.6%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:02<00:00, 74.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:34 INFO dspy.evaluate.evaluate: Average Metric: 81.0 / 151 (53.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/9f40a5f2dc2a4e09977f8b8c53822605\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_openai_gpt-4_1-mini-2025-04-14 at: http://localhost:5000/#/experiments/1/runs/c882d7c82d5f4a3abb510bf57d506c53\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 31.00 / 55 (56.4%):  36%|‚ñà‚ñà‚ñà‚ñå      | 54/151 [00:00<00:01, 53.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:35 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 44.00 / 72 (61.1%):  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 71/151 [00:01<00:01, 73.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:35 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 62.00 / 106 (58.5%):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 105/151 [00:01<00:00, 82.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:36 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 95.00 / 151 (62.9%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:02<00:00, 71.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:36 INFO dspy.evaluate.evaluate: Average Metric: 95.0 / 151 (62.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/8154049643d040d39c7642b56ac6d7c5\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_openai_o4-mini-2025-04-16 at: http://localhost:5000/#/experiments/1/runs/938b45e4b5204804b4e4660feebf563a\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 95.00 / 151 (62.9%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:02<00:00, 70.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:38 INFO dspy.evaluate.evaluate: Average Metric: 95.0 / 151 (62.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/599e8c7040b04b8c8f0ca24c6dc94d37\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_anthropic_claude-sonnet-4-20250514 at: http://localhost:5000/#/experiments/1/runs/4442e20dc743456b966821c18219c23e\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "  0%|          | 0/151 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:39 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 18:21:39 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.00 / 47 (66.0%):  30%|‚ñà‚ñà‚ñà       | 46/151 [00:01<00:02, 47.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:40 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 57.00 / 93 (61.3%):  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 93/151 [00:01<00:00, 79.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:40 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 73.00 / 122 (59.8%):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 121/151 [00:01<00:00, 89.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:40 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 96.00 / 151 (63.6%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:02<00:00, 67.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:41 INFO dspy.evaluate.evaluate: Average Metric: 96.0 / 151 (63.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/bcea3ffb8c6f4cbb98725e43e88cbdd0\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_gemini_gemini-2_5-flash at: http://localhost:5000/#/experiments/1/runs/7db59c48c06c4948adf754477705c360\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "  0%|          | 0/151 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:41 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:21:41 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:21:41 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:21:41 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 18:21:41 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 18:21:41 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:21:41 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 18:21:41 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 18:21:41 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:21:41 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 12 (66.7%):   7%|‚ñã         | 11/151 [00:00<00:03, 38.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:41 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:21:41 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 13 (69.2%):   8%|‚ñä         | 12/151 [00:00<00:03, 38.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:41 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:21:41 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 29 (62.1%):  19%|‚ñà‚ñâ        | 29/151 [00:00<00:01, 62.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:42 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:21:42 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 32 (62.5%):  21%|‚ñà‚ñà        | 31/151 [00:00<00:01, 62.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:42 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 33 (60.6%):  21%|‚ñà‚ñà        | 32/151 [00:00<00:01, 62.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:42 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 18:21:42 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 34 (61.8%):  22%|‚ñà‚ñà‚ñè       | 33/151 [00:00<00:01, 62.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:42 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 38 (57.9%):  25%|‚ñà‚ñà‚ñç       | 37/151 [00:00<00:01, 61.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:42 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:21:42 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 44.00 / 75 (58.7%):  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 74/151 [00:01<00:01, 57.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:42 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 44.00 / 76 (57.9%):  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 75/151 [00:01<00:01, 57.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:42 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 44.00 / 78 (56.4%):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 77/151 [00:01<00:01, 58.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:42 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 47.00 / 84 (56.0%):  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 84/151 [00:01<00:01, 60.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:42 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:21:42 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 51.00 / 89 (57.3%):  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 88/151 [00:01<00:01, 60.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:43 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:21:43 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:21:43 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 52.00 / 90 (57.8%):  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 89/151 [00:01<00:01, 60.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:43 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 55.00 / 96 (57.3%):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 95/151 [00:01<00:00, 60.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:43 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 56.00 / 97 (57.7%):  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 96/151 [00:01<00:00, 60.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:43 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 59.00 / 107 (55.1%):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 106/151 [00:01<00:00, 67.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:43 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 59.00 / 108 (54.6%):  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 108/151 [00:01<00:00, 69.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:43 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 62.00 / 112 (55.4%):  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 111/151 [00:01<00:00, 69.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:43 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:21:43 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 69.00 / 123 (56.1%):  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 122/151 [00:01<00:00, 69.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:43 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:21:43 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 87.00 / 151 (57.6%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:02<00:00, 60.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:43 INFO dspy.evaluate.evaluate: Average Metric: 87.0 / 151 (57.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/c348c68458124441865ac735d0b7d641\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_gemini_gemini-2_5-flash-lite at: http://localhost:5000/#/experiments/1/runs/598582fb690540e7baca55a097fee220\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 22.00 / 32 (68.8%):  21%|‚ñà‚ñà        | 31/151 [00:00<00:01, 64.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:44 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 69.00 / 100 (69.0%):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 99/151 [00:01<00:00, 62.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:45 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 106.00 / 151 (70.2%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:02<00:00, 51.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:47 INFO dspy.evaluate.evaluate: Average Metric: 106.0 / 151 (70.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/853504669f224faf8773cf2d9436fb41\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_openai_o3-2025-04-16 at: http://localhost:5000/#/experiments/1/runs/f122d81f9c1d46d582ce64553f6ee3ea\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 103.00 / 151 (68.2%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:02<00:00, 67.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:49 INFO dspy.evaluate.evaluate: Average Metric: 103.0 / 151 (68.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/96826db5718c45d6a2dc0b2c5526441e\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_anthropic_claude-opus-4-20250514 at: http://localhost:5000/#/experiments/1/runs/d329de90de1e40e0b467681f0442656a\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 103.00 / 151 (68.2%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:02<00:00, 71.07it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:21:51 INFO dspy.evaluate.evaluate: Average Metric: 103.0 / 151 (68.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/1fbbc1c758204d438fd050d77d524632\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_gemini_gemini-2_5-pro at: http://localhost:5000/#/experiments/1/runs/6e2dd13cb21f455c905159caa8335678\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run gate_dataset_results_full at: http://localhost:5000/#/experiments/1/runs/51176a64c2af4fbc803a1e1f0775e924\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=5276eb031180473cb92d03ceca489d38&amp;experiment_id=1&amp;trace_id=0f2dffe6dfd74fe3b5697a0bffb47658&amp;experiment_id=1&amp;trace_id=35c112a62c334012a612cdca116e9b09&amp;experiment_id=1&amp;trace_id=e30a2c51605b4102b190affb869475f4&amp;experiment_id=1&amp;trace_id=1b74fe5cb6c8453b82c227eb63e11221&amp;experiment_id=1&amp;trace_id=5310ed582ac0431382787b65f63de317&amp;experiment_id=1&amp;trace_id=f713426ecd20413ba2acbb7af0228b2d&amp;experiment_id=1&amp;trace_id=0f44b811a42c41dd9d867b5e12f80044&amp;experiment_id=1&amp;trace_id=543c31429f2d4d7cb4d2284daf66b3f9&amp;experiment_id=1&amp;trace_id=d624a05b74cc43a0a69bc8b400465a69&amp;experiment_id=1&amp;version=3.1.4\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=5276eb031180473cb92d03ceca489d38), Trace(trace_id=0f2dffe6dfd74fe3b5697a0bffb47658), Trace(trace_id=35c112a62c334012a612cdca116e9b09), Trace(trace_id=e30a2c51605b4102b190affb869475f4), Trace(trace_id=1b74fe5cb6c8453b82c227eb63e11221), Trace(trace_id=5310ed582ac0431382787b65f63de317), Trace(trace_id=f713426ecd20413ba2acbb7af0228b2d), Trace(trace_id=0f44b811a42c41dd9d867b5e12f80044), Trace(trace_id=543c31429f2d4d7cb4d2284daf66b3f9), Trace(trace_id=d624a05b74cc43a0a69bc8b400465a69)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "results = []\n",
    "\n",
    "with mlflow.start_run(run_name=\"gate_dataset_results_full\") as parent_ctx:\n",
    "    for candidate_lm in model_selection_llms:\n",
    "        run_name = f\"gate_{candidate_lm.model.replace('/', '_')}\"\n",
    "        sanitized_run_name = re.sub(r\"[^a-zA-Z0-9_\\-]\", \"_\", run_name)\n",
    "        with mlflow.start_run(run_name=sanitized_run_name, nested=True):\n",
    "            current_evaluator = Evaluate(\n",
    "                devset=gate_examples,\n",
    "                num_threads=32,\n",
    "                display_progress=True,\n",
    "                # display_table=True,\n",
    "                # provide_traceback=True,\n",
    "                return_all_scores=True,\n",
    "                return_outputs=True,\n",
    "            )\n",
    "            with dspy.context(lm=candidate_lm) as ctx:\n",
    "                current_result = current_evaluator(\n",
    "                    TurnSolver(reasoning_lm=True), metric=turn_em_metric\n",
    "                )\n",
    "                results.append(current_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now run the evaluation suite over the entire `gate dataset` for all the models in the above list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  LLM  Evaluation Score\n",
      "0           openai/gpt-4.1-2025-04-14             62.91\n",
      "1      openai/gpt-4.1-mini-2025-04-14             53.64\n",
      "2           openai/o4-mini-2025-04-16             62.91\n",
      "3  anthropic/claude-sonnet-4-20250514             62.91\n",
      "4             gemini/gemini-2.5-flash             63.58\n",
      "5        gemini/gemini-2.5-flash-lite             57.62\n",
      "6                openai/o3-2025-04-16             70.20\n",
      "7    anthropic/claude-opus-4-20250514             68.21\n",
      "8               gemini/gemini-2.5-pro             68.21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tdf = pd.DataFrame(\n",
    "    [\n",
    "        {\"LLM\": llms[idx].model, \"Evaluation Score\": candidate[0]}\n",
    "        for idx, candidate in enumerate(results)\n",
    "    ]\n",
    ")\n",
    "print(tdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, we see a few interesting things:\n",
    "\n",
    "- By default, most of the **reasoning** models perform better on the \"gate\" dataset, with OAI O3 performing the best with a score of 70.20%\n",
    "- Reasoning models from the remaining two frontier labs score the same i.e 68.21%\n",
    "- We also see that the smaller reasoning models perform similar across the labs, with an average score of 63.58%, but at a **significantly lower cost**.\n",
    "- The outputs from sonnet-4 failed the structured output test, but this could be fixed using the DSPy TypingPredictor in the future. More on this later!\n",
    "- Finally, while a _non-reasoning_ model like GPT-4.1 performs as well as the small reasoning models, the price of input/outputs tokens for GPT-4.1 is significantly higher compared to it's counterparts.\n",
    "\n",
    "We will also run the test over the \"probe\" dataset, before deciding our final list of LLMs based on the performance-to-cost ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probe Dataset Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 150.00 / 200 (75.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 69.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:15 INFO dspy.evaluate.evaluate: Average Metric: 150.0 / 200 (75.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/6cccc46d61ae4365b9921586ed0ef193\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run probe_openai_gpt-4_1-2025-04-14 at: http://localhost:5000/#/experiments/1/runs/3b839cca27264ffaaace2643e23975c7\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 130.00 / 200 (65.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:03<00:00, 60.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:18 INFO dspy.evaluate.evaluate: Average Metric: 130.0 / 200 (65.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/8c371daf948343eb8a18370f1756a850\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run probe_openai_gpt-4_1-mini-2025-04-14 at: http://localhost:5000/#/experiments/1/runs/dcfce79bf36446929e2924273e0a2db5\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 79.00 / 102 (77.5%):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:02<00:02, 36.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:20 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 122.00 / 157 (77.7%):  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:03<00:00, 48.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:21 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 157.00 / 200 (78.5%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:03<00:00, 53.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:22 INFO dspy.evaluate.evaluate: Average Metric: 157.0 / 200 (78.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/758a3867a75541c2a3eab91ac6faf42b\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run probe_openai_o4-mini-2025-04-16 at: http://localhost:5000/#/experiments/1/runs/aafc2286d5ab4819aa467440328eed77\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 150.00 / 200 (75.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:04<00:00, 49.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:26 INFO dspy.evaluate.evaluate: Average Metric: 150.0 / 200 (75.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/3b6644b108a241f99e8dd0e2e1d051fa\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run probe_anthropic_claude-sonnet-4-20250514 at: http://localhost:5000/#/experiments/1/runs/3b4f42a464cd4e3496f4b1755decd7ce\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 24.00 / 31 (77.4%):  15%|‚ñà‚ñå        | 30/200 [00:00<00:03, 50.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:27 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 148.00 / 200 (74.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:03<00:00, 51.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:30 INFO dspy.evaluate.evaluate: Average Metric: 148.0 / 200 (74.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/99af33e15c234269aa69333eebecb916\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run probe_gemini_gemini-2_5-flash at: http://localhost:5000/#/experiments/1/runs/7d11aa5ec28841adafa6b0e66733e13d\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:30 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:30 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 18:22:30 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:30 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 16 (68.8%):   8%|‚ñä         | 15/200 [00:00<00:04, 41.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:31 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:31 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 24 (75.0%):  12%|‚ñà‚ñè        | 23/200 [00:00<00:03, 50.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:31 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:31 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.00 / 26 (73.1%):  12%|‚ñà‚ñé        | 25/200 [00:00<00:03, 50.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:31 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:31 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 31 (67.7%):  15%|‚ñà‚ñå        | 30/200 [00:00<00:02, 58.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:31 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:31 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 33 (66.7%):  16%|‚ñà‚ñå        | 32/200 [00:00<00:02, 58.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:31 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:31 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 42 (64.3%):  20%|‚ñà‚ñà        | 41/200 [00:01<00:04, 33.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:31 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:31 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 53 (60.4%):  26%|‚ñà‚ñà‚ñå       | 52/200 [00:01<00:03, 43.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:31 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:32 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 36.00 / 61 (59.0%):  30%|‚ñà‚ñà‚ñà       | 60/200 [00:01<00:02, 49.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:32 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:32 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 18:22:32 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 39.00 / 65 (60.0%):  32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:01<00:02, 60.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:32 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 39.00 / 66 (59.1%):  32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:01<00:02, 60.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:32 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 41.00 / 68 (60.3%):  34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:01<00:02, 60.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:32 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 18:22:32 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:32 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 54.00 / 84 (64.3%):  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:01<00:01, 69.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:32 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 60.00 / 93 (64.5%):  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:01<00:01, 70.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:32 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:32 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 62.00 / 96 (64.6%):  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:01<00:01, 70.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:32 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 62.00 / 97 (63.9%):  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:01<00:01, 70.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:32 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 62.00 / 98 (63.3%):  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:01<00:01, 74.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:32 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 63.00 / 99 (63.6%):  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:01<00:01, 74.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:32 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 64.00 / 102 (62.7%):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:01, 74.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:32 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 65.00 / 103 (63.1%):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:01<00:01, 74.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:32 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 73.00 / 115 (63.5%):  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:02<00:01, 56.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:32 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:32 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 76.00 / 119 (63.9%):  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:02<00:01, 56.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:33 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:33 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 78.00 / 123 (63.4%):  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:02<00:01, 53.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:33 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:33 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 82.00 / 129 (63.6%):  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:02<00:01, 45.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:33 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:33 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 82.00 / 130 (63.1%):  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:02<00:01, 45.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:33 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:33 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 82.00 / 134 (61.2%):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:02<00:01, 46.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:33 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 83.00 / 135 (61.5%):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:02<00:01, 46.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:33 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 99.00 / 159 (62.3%):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:03<00:00, 46.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:33 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n",
      "2025/07/28 18:22:33 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 104.00 / 165 (63.0%):  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:03<00:01, 35.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:34 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 105.00 / 166 (63.3%):  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:03<00:00, 35.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:34 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 18:22:34 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=20000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 105.00 / 167 (62.9%):  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:03<00:00, 35.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:34 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 128.00 / 200 (64.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:03<00:00, 52.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:34 INFO dspy.evaluate.evaluate: Average Metric: 128.0 / 200 (64.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/20a1fa6983f349a0888cca2696bcae76\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run probe_gemini_gemini-2_5-flash-lite at: http://localhost:5000/#/experiments/1/runs/0c5ca9e2a1e84041b2937cd264727d94\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 48.00 / 61 (78.7%):  30%|‚ñà‚ñà‚ñà       | 60/200 [00:01<00:03, 45.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:35 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 66.00 / 83 (79.5%):  41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:01<00:01, 76.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:36 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 162.00 / 200 (81.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:03<00:00, 52.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:38 INFO dspy.evaluate.evaluate: Average Metric: 162.0 / 200 (81.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/513ceb4b58c44816894f0196c05f1d27\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run probe_openai_o3-2025-04-16 at: http://localhost:5000/#/experiments/1/runs/07039e1be0154904a14bf5b215b36bfb\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 160.00 / 200 (80.0%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:04<00:00, 46.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:22:43 INFO dspy.evaluate.evaluate: Average Metric: 160.0 / 200 (80.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/fa3840a6fc86489195ff4b93ba3525d3\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run probe_anthropic_claude-opus-4-20250514 at: http://localhost:5000/#/experiments/1/runs/242a848220a34df18fefcd752c6b1edf\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "Average Metric: 157.00 / 200 (78.5%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:20<00:00,  9.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/28 18:23:03 INFO dspy.evaluate.evaluate: Average Metric: 157.0 / 200 (78.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run eval at: http://localhost:5000/#/experiments/1/runs/28468bf07dea42438e3b2835cf8bd5d1\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run probe_gemini_gemini-2_5-pro at: http://localhost:5000/#/experiments/1/runs/b9decff973db41ce9863d93d41eff7c3\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run probe_dataset_results_full at: http://localhost:5000/#/experiments/1/runs/7f0b1ff0f4e94143b9fb5509ed6319be\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=c5d368d7011e416bb8a6a45fb5757cc5&amp;experiment_id=1&amp;trace_id=c838fe37a1554a709c48aa7d91df4051&amp;experiment_id=1&amp;trace_id=e3e3b12245c145609fbd9f2ea7a38b35&amp;experiment_id=1&amp;trace_id=f05d4d95db7d4aceb8b4158a8cf0cfb0&amp;experiment_id=1&amp;trace_id=e996a1553f3b4c7b97af98bc3665f7aa&amp;experiment_id=1&amp;trace_id=02d784d19b414f16bc36df2f6cace3af&amp;experiment_id=1&amp;trace_id=a4955baaaf944dbbadcd4f05cb1c10aa&amp;experiment_id=1&amp;trace_id=fcaf8824996d4c7eab4d03bd198f2c33&amp;experiment_id=1&amp;trace_id=73db052bdbe1418eb46bc6ec442df95e&amp;experiment_id=1&amp;trace_id=66a0910a43384a9f993773961116b241&amp;experiment_id=1&amp;version=3.1.4\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=c5d368d7011e416bb8a6a45fb5757cc5), Trace(trace_id=c838fe37a1554a709c48aa7d91df4051), Trace(trace_id=e3e3b12245c145609fbd9f2ea7a38b35), Trace(trace_id=f05d4d95db7d4aceb8b4158a8cf0cfb0), Trace(trace_id=e996a1553f3b4c7b97af98bc3665f7aa), Trace(trace_id=02d784d19b414f16bc36df2f6cace3af), Trace(trace_id=a4955baaaf944dbbadcd4f05cb1c10aa), Trace(trace_id=fcaf8824996d4c7eab4d03bd198f2c33), Trace(trace_id=73db052bdbe1418eb46bc6ec442df95e), Trace(trace_id=66a0910a43384a9f993773961116b241)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "probe_results = []\n",
    "\n",
    "with mlflow.start_run(run_name=\"probe_dataset_results_full\") as parent_ctx:\n",
    "    for candidate_lm in model_selection_llms:\n",
    "        run_name = f\"probe_{candidate_lm.model.replace('/', '_')}\"\n",
    "        sanitized_run_name = re.sub(r\"[^a-zA-Z0-9_\\-]\", \"_\", run_name)\n",
    "        with mlflow.start_run(run_name=sanitized_run_name, nested=True):\n",
    "            current_evaluator = Evaluate(\n",
    "                devset=probe_examples,\n",
    "                num_threads=32,\n",
    "                display_progress=True,\n",
    "                # display_table=True,\n",
    "                # provide_traceback=True,\n",
    "                return_all_scores=True,\n",
    "                return_outputs=True,\n",
    "            )\n",
    "            with dspy.context(lm=candidate_lm) as ctx:\n",
    "                current_result = current_evaluator(\n",
    "                    TurnSolver(reasoning_lm=True), metric=turn_em_metric\n",
    "                )\n",
    "                probe_results.append(current_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  LLM  Evaluation Score\n",
      "0           openai/gpt-4.1-2025-04-14              75.0\n",
      "1      openai/gpt-4.1-mini-2025-04-14              65.0\n",
      "2           openai/o4-mini-2025-04-16              78.5\n",
      "3  anthropic/claude-sonnet-4-20250514              75.0\n",
      "4             gemini/gemini-2.5-flash              74.0\n",
      "5        gemini/gemini-2.5-flash-lite              64.0\n",
      "6                openai/o3-2025-04-16              81.0\n",
      "7    anthropic/claude-opus-4-20250514              80.0\n",
      "8               gemini/gemini-2.5-pro              78.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tdf = pd.DataFrame(\n",
    "    [\n",
    "        {\"LLM\": llms[idx].model, \"Evaluation Score\": candidate[0]}\n",
    "        for idx, candidate in enumerate(probe_results)\n",
    "    ]\n",
    ")\n",
    "print(tdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we see that:\n",
    "\n",
    "- Similar to the gate-only results, the _probe_ dataset results should that OAI o3 performs the best, with 81% accuracy.\n",
    "- Anthropic Opus is a close second, with 80% accuracy. However, it is **significantly** more expensive, at $15/Million tokens üò±\n",
    "- Google's Frontier model Gemini-pro is third, with 78% accuracy.\n",
    "- We see that the smaller reasoning models do quite well, with o4-mini getting around 78.5% accuracy, Anthropic sonnet-4 around 75% accuracy, and Google Gemini 2.5-flash at 74%. Note that, even here, Anthropic's costs are significantly higher than the other models.\n",
    "- We also see that the \"mini/lite\" version of models provided by Google and OAI have similar performance, around ~65%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the above insights, we can now select our models:\n",
    "\n",
    "- **Anthropic Cost**\n",
    "  - All Anthropic models are significantly more expensive than the competitors, and have a performance on par or below the competetiors.\n",
    "  - Hence, from our final list, we will exclude Anthropic models.\n",
    "- **Frontier Model Cost**\n",
    "  - Frontier models are generally quite expensive.\n",
    "  - From our tests, we see that OAI o3 has the best performace, with Google Gemini 2.5-pro having a performance on or below o3.\n",
    "  - To save costs, we will keep only one frontier model in the final list i.e o3\n",
    "- **Smaller Reasoning Models**\n",
    "  - We also see the following models showing promising results across the board:\n",
    "    - o4-mini\n",
    "    - gemini-2.5-flash\n",
    "- **Non reaosning models**\n",
    "  - GPT-4.1 seems to perform as well as the smaller reasoning models, but it is about 50% more expensive($2/Million input tokens).\n",
    "  - Given that we already plan to include models with similar reasoning capabilities, we will exclude GPT-4.1 from our final list.\n",
    "- **Small models**\n",
    "  - Currently, the small models variants of all models are significantly behind the larger models.\n",
    "  - While they are cost effective, and likely their performance can be increased with improvements to the prompts, fine-tuning, etc., we will skip this models for now due to time constraits.\n",
    "\n",
    "Hence, our final list of models will be:\n",
    "\n",
    "- o3\n",
    "- o4-mini\n",
    "- gemini-2.5-flash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we have the results for the gate and probe datasets, we can perform some quick preliminary error analysis to understand the performance of the models on these datasets.\n",
    "\n",
    "We will restrict our analysis to the final list of models(o3, o4-mini and gemini-2.5-flash).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_selected_models = [\n",
    "    lm_oai_o4_mini,\n",
    "    lm_gemini_flash_2_5,\n",
    "    lm_oai_o3,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_and_probe_results = results + probe_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gate_and_probe_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_records = []\n",
    "for idx, record in enumerate(gate_and_probe_results):\n",
    "    # Hack: Dirty hack to get results our selected LLMs. Sorry!\n",
    "    if idx in [2, 4, 6, 11, 13, 15]:\n",
    "        for example, prediction, score in record[1]:\n",
    "            model_idx = idx if idx < 9 else idx - 9\n",
    "            example_copy = deepcopy(example)\n",
    "            example_copy[\"ground_truth_answer\"] = example_copy[\"answer\"]\n",
    "            del example_copy[\"answer\"]\n",
    "\n",
    "            selected_records.append(\n",
    "                {\n",
    "                    \"model_name\": model_selection_llms[model_idx].model,\n",
    "                    \"turn_em_metric_score\": score,\n",
    "                    **example_copy.toDict(),\n",
    "                    **prediction.toDict(),\n",
    "                }\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'openai/o4-mini-2025-04-16',\n",
       " 'turn_em_metric_score': 1.0,\n",
       " 'conversation_context': 'None',\n",
       " 'evidence_snippets': \"[PRE]\\nentergy corporation and subsidiaries management's financial discussion and analysis refer to 201cselected financial data - five-year comparison of entergy corporation and subsidiaries 201d which accompanies entergy corporation 2019s financial statements in this report for further information with respect to operating statistics . in november 2007 the board approved a plan to pursue a separation of entergy 2019s non-utility nuclear business from entergy through a spin-off of the business to entergy shareholders . in april 2010 , entergy announced that it planned to unwind the business infrastructure associated with the proposed spin-off transaction . as a result of the plan to unwind the business infrastructure , entergy recorded expenses in 2010 for the write-off of certain capitalized costs incurred in connection with the planned spin-off transaction . these costs are discussed in more detail below and throughout this section . net revenue utility following is an analysis of the change in net revenue comparing 2010 to 2009 . amount ( in millions ) .\\n[/PRE]\\n[POST]\\nthe volume/weather variance is primarily due to an increase of 8362 gwh , or 8% ( 8 % ) , in billed electricity usage in all retail sectors , including the effect on the residential sector of colder weather in the first quarter 2010 compared to 2009 and warmer weather in the second and third quarters 2010 compared to 2009 . the industrial sector reflected strong sales growth on continuing signs of economic recovery . the improvement in this sector was primarily driven by inventory restocking and strong exports with the chemicals , refining , and miscellaneous manufacturing sectors leading the improvement . the retail electric price variance is primarily due to : increases in the formula rate plan riders at entergy gulf states louisiana effective november 2009 , january 2010 , and september 2010 , at entergy louisiana effective november 2009 , and at entergy mississippi effective july 2009 ; a base rate increase at entergy arkansas effective july 2010 ; rate actions at entergy texas , including base rate increases effective in may and august 2010 ; a formula rate plan provision of $ 16.6 million recorded in the third quarter 2009 for refunds that were made to customers in accordance with settlements approved by the lpsc ; and the recovery in 2009 by entergy arkansas of 2008 extraordinary storm costs , as approved by the apsc , which ceased in january 2010 . the recovery of storm costs is offset in other operation and maintenance expenses . see note 2 to the financial statements for further discussion of the proceedings referred to above. .\\n[/POST]\",\n",
       " 'table': '| Row | 2009 net revenue | volume/weather | retail electric price | provision for regulatory proceedings | rough production cost equalization | ano decommissioning trust | fuel recovery | other | 2010 net revenue |\\n|---|---|---|---|---|---|---|---|---|---|\\n| amount ( in millions ) | 4694.0 | 231.0 | 137.0 | 26.0 | 19.0 | -24.0 | -44.0 | 12.0 | 5051.0 |',\n",
       " 'question': 'what was the difference in net revenue between 2009 and 2010?',\n",
       " 'id': 'Single_ETR/2011/page_22.pdf-3',\n",
       " 'doc_pre_text': \"entergy corporation and subsidiaries management's financial discussion and analysis refer to 201cselected financial data - five-year comparison of entergy corporation and subsidiaries 201d which accompanies entergy corporation 2019s financial statements in this report for further information with respect to operating statistics . in november 2007 the board approved a plan to pursue a separation of entergy 2019s non-utility nuclear business from entergy through a spin-off of the business to entergy shareholders . in april 2010 , entergy announced that it planned to unwind the business infrastructure associated with the proposed spin-off transaction . as a result of the plan to unwind the business infrastructure , entergy recorded expenses in 2010 for the write-off of certain capitalized costs incurred in connection with the planned spin-off transaction . these costs are discussed in more detail below and throughout this section . net revenue utility following is an analysis of the change in net revenue comparing 2010 to 2009 . amount ( in millions ) .\",\n",
       " 'doc_post_text': 'the volume/weather variance is primarily due to an increase of 8362 gwh , or 8% ( 8 % ) , in billed electricity usage in all retail sectors , including the effect on the residential sector of colder weather in the first quarter 2010 compared to 2009 and warmer weather in the second and third quarters 2010 compared to 2009 . the industrial sector reflected strong sales growth on continuing signs of economic recovery . the improvement in this sector was primarily driven by inventory restocking and strong exports with the chemicals , refining , and miscellaneous manufacturing sectors leading the improvement . the retail electric price variance is primarily due to : increases in the formula rate plan riders at entergy gulf states louisiana effective november 2009 , january 2010 , and september 2010 , at entergy louisiana effective november 2009 , and at entergy mississippi effective july 2009 ; a base rate increase at entergy arkansas effective july 2010 ; rate actions at entergy texas , including base rate increases effective in may and august 2010 ; a formula rate plan provision of $ 16.6 million recorded in the third quarter 2009 for refunds that were made to customers in accordance with settlements approved by the lpsc ; and the recovery in 2009 by entergy arkansas of 2008 extraordinary storm costs , as approved by the apsc , which ceased in january 2010 . the recovery of storm costs is offset in other operation and maintenance expenses . see note 2 to the financial statements for further discussion of the proceedings referred to above. .',\n",
       " 'doc_table': {'amount ( in millions )': {'2009 net revenue': 4694.0,\n",
       "   'volume/weather': 231.0,\n",
       "   'retail electric price': 137.0,\n",
       "   'provision for regulatory proceedings': 26.0,\n",
       "   'rough production cost equalization': 19.0,\n",
       "   'ano decommissioning trust': -24.0,\n",
       "   'fuel recovery': -44.0,\n",
       "   'other': 12.0,\n",
       "   '2010 net revenue': 5051.0}},\n",
       " 'dialogue_conv_questions': ['what was the difference in net revenue between 2009 and 2010?',\n",
       "  'and the specific value for 2009 again?',\n",
       "  'so what was the percentage change during this time?'],\n",
       " 'dialogue_conv_answers': ['357', '4694', '7.61%'],\n",
       " 'dialogue_turn_program': ['subtract(5051, 4694)',\n",
       "  '4694',\n",
       "  'subtract(5051, 4694), divide(#0, 4694)'],\n",
       " 'dialogue_executed_answers': [357.0, 4694.0, 0.07605],\n",
       " 'dialogue_qa_split': [False, False, False],\n",
       " 'features_num_dialogue_turns': 3,\n",
       " 'features_has_type2_question': False,\n",
       " 'features_has_duplicate_columns': False,\n",
       " 'features_has_non_numeric_values': False,\n",
       " 'ground_truth_answer': 357.0,\n",
       " 'reasoning': 'The table shows 2009 net revenue of 4,694.0 million and 2010 net revenue of 5,051.0 million. The difference is 5,051.0 minus 4,694.0, which equals 357.0 million.',\n",
       " 'ops': 'subtract(const_5051.0, const_4694.0)',\n",
       " 'answer': '357.0'}"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "import dspy\n",
    "\n",
    "\n",
    "class AssessmentSignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Categorize model predictions by comparing them to ground truth, context, and evidence.\n",
    "    Assign a specific error type or OK label, with concise justification, based on rubric.\n",
    "\n",
    "    When comparing numerical answers, always allow a tolerance of 1e-2. For eg: If the question asks for a percentage, but the ground_truth_answer is given as a decimal, the assessment_answer label will be GROUND_TRUTH_INCORRECT\n",
    "    \"\"\"\n",
    "\n",
    "    ground_truth_answer: str = dspy.InputField(\n",
    "        desc=\"The correct answer as per the ground truth data.\"\n",
    "    )\n",
    "    table: str = dspy.InputField(\n",
    "        desc=\"Tabular data (as string) relevant to the question and answer.\"\n",
    "    )\n",
    "    conversation_context: str = dspy.InputField(\n",
    "        desc=\"Previous dialogue turns or context for the current question.\"\n",
    "    )\n",
    "    evidence_snippets: str = dspy.InputField(\n",
    "        desc=\"Text snippets from the source document supporting the answer.\"\n",
    "    )\n",
    "    question: str = dspy.InputField(desc=\"The question being answered by the model.\")\n",
    "\n",
    "    predicted_reasoning: str = dspy.InputField(\n",
    "        desc=\"Model's step-by-step explanation or justification for its answer.\"\n",
    "    )\n",
    "    predicted_ops: str = dspy.InputField(\n",
    "        desc=\"Operations or programmatic steps the model used to derive its answer.\"\n",
    "    )\n",
    "    predicted_answer: str = dspy.InputField(\n",
    "        desc=\"The answer predicted by the model for the given question.\"\n",
    "    )\n",
    "\n",
    "    assessment_answer: Literal[\n",
    "        \"OK\",\n",
    "        \"NUMERICAL_ANSWER_WRONG\",\n",
    "        \"TEXTUAL_SELECTION_ANSWER_WRONG\",\n",
    "        \"FORMAT_ERROR\",\n",
    "        \"EVIDENCE_MISMATCH\",\n",
    "        \"GROUND_TRUTH_INCORRECT\",\n",
    "    ] = dspy.OutputField(desc=\"Single categorical label.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'openai/o4-mini-2025-04-16',\n",
       " 'turn_em_metric_score': 1.0,\n",
       " 'conversation_context': 'None',\n",
       " 'evidence_snippets': \"[PRE]\\nentergy corporation and subsidiaries management's financial discussion and analysis refer to 201cselected financial data - five-year comparison of entergy corporation and subsidiaries 201d which accompanies entergy corporation 2019s financial statements in this report for further information with respect to operating statistics . in november 2007 the board approved a plan to pursue a separation of entergy 2019s non-utility nuclear business from entergy through a spin-off of the business to entergy shareholders . in april 2010 , entergy announced that it planned to unwind the business infrastructure associated with the proposed spin-off transaction . as a result of the plan to unwind the business infrastructure , entergy recorded expenses in 2010 for the write-off of certain capitalized costs incurred in connection with the planned spin-off transaction . these costs are discussed in more detail below and throughout this section . net revenue utility following is an analysis of the change in net revenue comparing 2010 to 2009 . amount ( in millions ) .\\n[/PRE]\\n[POST]\\nthe volume/weather variance is primarily due to an increase of 8362 gwh , or 8% ( 8 % ) , in billed electricity usage in all retail sectors , including the effect on the residential sector of colder weather in the first quarter 2010 compared to 2009 and warmer weather in the second and third quarters 2010 compared to 2009 . the industrial sector reflected strong sales growth on continuing signs of economic recovery . the improvement in this sector was primarily driven by inventory restocking and strong exports with the chemicals , refining , and miscellaneous manufacturing sectors leading the improvement . the retail electric price variance is primarily due to : increases in the formula rate plan riders at entergy gulf states louisiana effective november 2009 , january 2010 , and september 2010 , at entergy louisiana effective november 2009 , and at entergy mississippi effective july 2009 ; a base rate increase at entergy arkansas effective july 2010 ; rate actions at entergy texas , including base rate increases effective in may and august 2010 ; a formula rate plan provision of $ 16.6 million recorded in the third quarter 2009 for refunds that were made to customers in accordance with settlements approved by the lpsc ; and the recovery in 2009 by entergy arkansas of 2008 extraordinary storm costs , as approved by the apsc , which ceased in january 2010 . the recovery of storm costs is offset in other operation and maintenance expenses . see note 2 to the financial statements for further discussion of the proceedings referred to above. .\\n[/POST]\",\n",
       " 'table': '| Row | 2009 net revenue | volume/weather | retail electric price | provision for regulatory proceedings | rough production cost equalization | ano decommissioning trust | fuel recovery | other | 2010 net revenue |\\n|---|---|---|---|---|---|---|---|---|---|\\n| amount ( in millions ) | 4694.0 | 231.0 | 137.0 | 26.0 | 19.0 | -24.0 | -44.0 | 12.0 | 5051.0 |',\n",
       " 'question': 'what was the difference in net revenue between 2009 and 2010?',\n",
       " 'id': 'Single_ETR/2011/page_22.pdf-3',\n",
       " 'doc_pre_text': \"entergy corporation and subsidiaries management's financial discussion and analysis refer to 201cselected financial data - five-year comparison of entergy corporation and subsidiaries 201d which accompanies entergy corporation 2019s financial statements in this report for further information with respect to operating statistics . in november 2007 the board approved a plan to pursue a separation of entergy 2019s non-utility nuclear business from entergy through a spin-off of the business to entergy shareholders . in april 2010 , entergy announced that it planned to unwind the business infrastructure associated with the proposed spin-off transaction . as a result of the plan to unwind the business infrastructure , entergy recorded expenses in 2010 for the write-off of certain capitalized costs incurred in connection with the planned spin-off transaction . these costs are discussed in more detail below and throughout this section . net revenue utility following is an analysis of the change in net revenue comparing 2010 to 2009 . amount ( in millions ) .\",\n",
       " 'doc_post_text': 'the volume/weather variance is primarily due to an increase of 8362 gwh , or 8% ( 8 % ) , in billed electricity usage in all retail sectors , including the effect on the residential sector of colder weather in the first quarter 2010 compared to 2009 and warmer weather in the second and third quarters 2010 compared to 2009 . the industrial sector reflected strong sales growth on continuing signs of economic recovery . the improvement in this sector was primarily driven by inventory restocking and strong exports with the chemicals , refining , and miscellaneous manufacturing sectors leading the improvement . the retail electric price variance is primarily due to : increases in the formula rate plan riders at entergy gulf states louisiana effective november 2009 , january 2010 , and september 2010 , at entergy louisiana effective november 2009 , and at entergy mississippi effective july 2009 ; a base rate increase at entergy arkansas effective july 2010 ; rate actions at entergy texas , including base rate increases effective in may and august 2010 ; a formula rate plan provision of $ 16.6 million recorded in the third quarter 2009 for refunds that were made to customers in accordance with settlements approved by the lpsc ; and the recovery in 2009 by entergy arkansas of 2008 extraordinary storm costs , as approved by the apsc , which ceased in january 2010 . the recovery of storm costs is offset in other operation and maintenance expenses . see note 2 to the financial statements for further discussion of the proceedings referred to above. .',\n",
       " 'doc_table': {'amount ( in millions )': {'2009 net revenue': 4694.0,\n",
       "   'volume/weather': 231.0,\n",
       "   'retail electric price': 137.0,\n",
       "   'provision for regulatory proceedings': 26.0,\n",
       "   'rough production cost equalization': 19.0,\n",
       "   'ano decommissioning trust': -24.0,\n",
       "   'fuel recovery': -44.0,\n",
       "   'other': 12.0,\n",
       "   '2010 net revenue': 5051.0}},\n",
       " 'dialogue_conv_questions': ['what was the difference in net revenue between 2009 and 2010?',\n",
       "  'and the specific value for 2009 again?',\n",
       "  'so what was the percentage change during this time?'],\n",
       " 'dialogue_conv_answers': ['357', '4694', '7.61%'],\n",
       " 'dialogue_turn_program': ['subtract(5051, 4694)',\n",
       "  '4694',\n",
       "  'subtract(5051, 4694), divide(#0, 4694)'],\n",
       " 'dialogue_executed_answers': [357.0, 4694.0, 0.07605],\n",
       " 'dialogue_qa_split': [False, False, False],\n",
       " 'features_num_dialogue_turns': 3,\n",
       " 'features_has_type2_question': False,\n",
       " 'features_has_duplicate_columns': False,\n",
       " 'features_has_non_numeric_values': False,\n",
       " 'ground_truth_answer': 357.0,\n",
       " 'reasoning': 'The table shows 2009 net revenue of 4,694.0 million and 2010 net revenue of 5,051.0 million. The difference is 5,051.0 minus 4,694.0, which equals 357.0 million.',\n",
       " 'ops': 'subtract(const_5051.0, const_4694.0)',\n",
       " 'answer': '357.0'}"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_examples = []\n",
    "\n",
    "for record in selected_records:\n",
    "    if record[\"turn_em_metric_score\"] != 1:\n",
    "        judge_examples.append(\n",
    "            dspy.Example(\n",
    "                id=record[\"id\"],\n",
    "                model_name=record[\"model_name\"],\n",
    "                predicted_reasoning=record[\"reasoning\"],\n",
    "                predicted_ops=record[\"ops\"],\n",
    "                predicted_answer=record[\"answer\"],\n",
    "                ground_truth_answer=record[\"ground_truth_answer\"],\n",
    "                table=record[\"table\"],\n",
    "                conversation_context=record[\"conversation_context\"],\n",
    "                evidence_snippets=record[\"evidence_snippets\"],\n",
    "                question=record[\"question\"],\n",
    "            ).with_inputs(\n",
    "                \"predicted_reasoning\",\n",
    "                \"predicted_ops\",\n",
    "                \"predicted_answer\",\n",
    "                \"ground_truth_answer\",\n",
    "                \"table\",\n",
    "                \"conversation_context\",\n",
    "                \"evidence_snippets\",\n",
    "                \"question\",\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Gemini Flash 2.5 as our judge model, for classifying the generated predictions for error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judging examples:   1%|          | 2/289 [00:00<00:17, 16.77it/s]2025/07/28 20:07:50 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:   1%|‚ñè         | 4/289 [00:00<00:19, 14.79it/s]2025/07/28 20:07:50 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:   2%|‚ñè         | 6/289 [00:00<00:19, 14.85it/s]2025/07/28 20:07:50 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:50 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:   4%|‚ñç         | 11/289 [00:00<00:22, 12.42it/s]2025/07/28 20:07:51 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:   5%|‚ñç         | 14/289 [00:00<00:18, 15.05it/s]2025/07/28 20:07:51 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:51 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:   6%|‚ñå         | 17/289 [00:01<00:15, 18.13it/s]2025/07/28 20:07:51 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:51 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:   7%|‚ñã         | 20/289 [00:01<00:13, 19.77it/s]2025/07/28 20:07:51 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:   8%|‚ñä         | 24/289 [00:01<00:11, 23.48it/s]2025/07/28 20:07:51 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  10%|‚ñâ         | 28/289 [00:01<00:09, 26.52it/s]2025/07/28 20:07:51 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  11%|‚ñà         | 32/289 [00:01<00:09, 27.24it/s]2025/07/28 20:07:51 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:52 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:52 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  12%|‚ñà‚ñè        | 35/289 [00:01<00:10, 23.43it/s]2025/07/28 20:07:52 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  13%|‚ñà‚ñé        | 38/289 [00:01<00:10, 23.92it/s]2025/07/28 20:07:52 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:52 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  14%|‚ñà‚ñç        | 41/289 [00:01<00:10, 23.64it/s]2025/07/28 20:07:52 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  15%|‚ñà‚ñå        | 44/289 [00:02<00:10, 24.06it/s]2025/07/28 20:07:52 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:52 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  16%|‚ñà‚ñã        | 47/289 [00:02<00:09, 24.36it/s]2025/07/28 20:07:52 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  17%|‚ñà‚ñã        | 50/289 [00:02<00:09, 24.44it/s]2025/07/28 20:07:52 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:52 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:52 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  18%|‚ñà‚ñä        | 53/289 [00:02<00:10, 23.14it/s]2025/07/28 20:07:52 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:53 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  20%|‚ñà‚ñà        | 59/289 [00:02<00:11, 20.29it/s]2025/07/28 20:07:53 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  21%|‚ñà‚ñà‚ñè       | 62/289 [00:03<00:13, 16.86it/s]2025/07/28 20:07:53 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:53 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  22%|‚ñà‚ñà‚ñè       | 65/289 [00:03<00:11, 19.32it/s]2025/07/28 20:07:53 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:53 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:53 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  24%|‚ñà‚ñà‚ñé       | 68/289 [00:03<00:10, 20.77it/s]2025/07/28 20:07:53 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:53 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:53 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  25%|‚ñà‚ñà‚ñç       | 71/289 [00:03<00:09, 22.32it/s]2025/07/28 20:07:53 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  26%|‚ñà‚ñà‚ñå       | 74/289 [00:03<00:09, 22.84it/s]2025/07/28 20:07:53 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  27%|‚ñà‚ñà‚ñã       | 77/289 [00:03<00:09, 22.32it/s]2025/07/28 20:07:54 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  28%|‚ñà‚ñà‚ñä       | 80/289 [00:03<00:10, 20.68it/s]2025/07/28 20:07:54 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  30%|‚ñà‚ñà‚ñâ       | 86/289 [00:04<00:09, 21.69it/s]2025/07/28 20:07:54 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:54 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:54 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  31%|‚ñà‚ñà‚ñà       | 89/289 [00:04<00:09, 21.10it/s]2025/07/28 20:07:54 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  32%|‚ñà‚ñà‚ñà‚ñè      | 92/289 [00:04<00:09, 21.50it/s]2025/07/28 20:07:54 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:54 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  33%|‚ñà‚ñà‚ñà‚ñé      | 95/289 [00:04<00:08, 22.81it/s]2025/07/28 20:07:54 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  34%|‚ñà‚ñà‚ñà‚ñç      | 98/289 [00:04<00:07, 23.91it/s]2025/07/28 20:07:55 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  35%|‚ñà‚ñà‚ñà‚ñç      | 101/289 [00:04<00:07, 24.41it/s]2025/07/28 20:07:55 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:55 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  36%|‚ñà‚ñà‚ñà‚ñå      | 104/289 [00:04<00:08, 20.70it/s]2025/07/28 20:07:55 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:55 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  37%|‚ñà‚ñà‚ñà‚ñã      | 107/289 [00:05<00:11, 16.11it/s]2025/07/28 20:07:55 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  38%|‚ñà‚ñà‚ñà‚ñä      | 110/289 [00:05<00:09, 18.39it/s]2025/07/28 20:07:55 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:55 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  39%|‚ñà‚ñà‚ñà‚ñâ      | 114/289 [00:05<00:08, 21.66it/s]2025/07/28 20:07:55 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:55 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:55 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  41%|‚ñà‚ñà‚ñà‚ñà      | 118/289 [00:05<00:07, 24.12it/s]2025/07/28 20:07:56 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:56 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 122/289 [00:05<00:06, 25.92it/s]2025/07/28 20:07:56 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 128/289 [00:05<00:06, 23.89it/s]2025/07/28 20:07:56 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:56 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 131/289 [00:06<00:06, 22.85it/s]2025/07/28 20:07:56 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 134/289 [00:06<00:06, 23.46it/s]2025/07/28 20:07:56 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 137/289 [00:06<00:06, 23.90it/s]2025/07/28 20:07:56 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:56 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 140/289 [00:06<00:06, 23.84it/s]2025/07/28 20:07:56 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 149/289 [00:06<00:05, 24.60it/s]2025/07/28 20:07:57 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:57 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:57 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 155/289 [00:07<00:06, 22.09it/s]2025/07/28 20:07:57 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:57 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:57 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 158/289 [00:07<00:07, 18.30it/s]2025/07/28 20:07:57 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:57 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 161/289 [00:07<00:06, 19.50it/s]2025/07/28 20:07:57 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:57 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 164/289 [00:07<00:05, 21.21it/s]2025/07/28 20:07:58 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:58 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 168/289 [00:07<00:05, 23.87it/s]2025/07/28 20:07:58 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 172/289 [00:07<00:04, 25.66it/s]2025/07/28 20:07:58 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:58 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 175/289 [00:07<00:04, 26.17it/s]2025/07/28 20:07:58 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 178/289 [00:08<00:05, 20.48it/s]2025/07/28 20:07:58 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 181/289 [00:08<00:05, 19.97it/s]2025/07/28 20:07:58 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:58 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 184/289 [00:08<00:04, 21.03it/s]2025/07/28 20:07:58 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:58 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:58 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 187/289 [00:08<00:04, 21.89it/s]2025/07/28 20:07:59 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:59 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:59 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 190/289 [00:08<00:04, 20.94it/s]2025/07/28 20:07:59 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 193/289 [00:08<00:04, 21.33it/s]2025/07/28 20:07:59 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 196/289 [00:09<00:04, 21.37it/s]2025/07/28 20:07:59 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:07:59 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 199/289 [00:09<00:05, 17.97it/s]2025/07/28 20:07:59 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 201/289 [00:09<00:05, 16.87it/s]2025/07/28 20:07:59 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 203/289 [00:09<00:05, 14.73it/s]2025/07/28 20:08:00 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:00 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 206/289 [00:09<00:04, 17.68it/s]2025/07/28 20:08:00 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 213/289 [00:09<00:03, 23.63it/s]2025/07/28 20:08:00 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 216/289 [00:10<00:02, 24.77it/s]2025/07/28 20:08:00 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 219/289 [00:10<00:02, 25.95it/s]2025/07/28 20:08:00 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:00 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 222/289 [00:10<00:02, 22.83it/s]2025/07/28 20:08:00 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:00 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 225/289 [00:10<00:03, 19.59it/s]2025/07/28 20:08:00 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:00 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:01 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 228/289 [00:10<00:03, 19.79it/s]2025/07/28 20:08:01 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 231/289 [00:10<00:02, 20.88it/s]2025/07/28 20:08:01 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 234/289 [00:10<00:02, 22.36it/s]2025/07/28 20:08:01 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 237/289 [00:11<00:02, 22.83it/s]2025/07/28 20:08:01 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:01 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:01 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 240/289 [00:11<00:02, 22.23it/s]2025/07/28 20:08:01 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:01 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 243/289 [00:11<00:02, 21.50it/s]2025/07/28 20:08:01 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:01 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 246/289 [00:11<00:02, 14.67it/s]2025/07/28 20:08:02 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 249/289 [00:11<00:02, 16.99it/s]2025/07/28 20:08:02 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:02 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:02 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 252/289 [00:11<00:01, 19.29it/s]2025/07/28 20:08:02 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 256/289 [00:12<00:01, 22.46it/s]2025/07/28 20:08:02 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:02 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 260/289 [00:12<00:01, 24.88it/s]2025/07/28 20:08:02 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:02 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 263/289 [00:12<00:01, 24.21it/s]2025/07/28 20:08:02 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 266/289 [00:12<00:00, 25.37it/s]2025/07/28 20:08:02 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:02 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 269/289 [00:12<00:00, 20.30it/s]2025/07/28 20:08:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 272/289 [00:12<00:00, 19.67it/s]2025/07/28 20:08:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 275/289 [00:12<00:00, 20.71it/s]2025/07/28 20:08:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 278/289 [00:13<00:00, 21.31it/s]2025/07/28 20:08:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 281/289 [00:13<00:00, 22.55it/s]2025/07/28 20:08:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 284/289 [00:13<00:00, 22.90it/s]2025/07/28 20:08:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 287/289 [00:13<00:00, 23.65it/s]2025/07/28 20:08:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/07/28 20:08:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "Judging examples: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 289/289 [00:13<00:00, 21.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run error_analysis_gemini_2.5_flash at: http://localhost:5000/#/experiments/1/runs/d415524ddcf94cd086f2f221c2f6f177\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=f51ec31b099c4ccb884824cd84faf244&amp;experiment_id=1&amp;trace_id=2b2a5bac43db4bdf8f1ba27a0c72707f&amp;experiment_id=1&amp;trace_id=33d30ce093eb4bcb8959b7e7b14f4f03&amp;experiment_id=1&amp;trace_id=585d29108d074c8eb2546d615be4e058&amp;experiment_id=1&amp;trace_id=f458046f22604e4cbb206f2ddea55891&amp;experiment_id=1&amp;trace_id=fae282bd8d524323a37fbafd71e5e50f&amp;experiment_id=1&amp;trace_id=e0f8503464d846308c8ac03dd3897e1a&amp;experiment_id=1&amp;trace_id=2f17ef3a251a4472920aac663506297b&amp;experiment_id=1&amp;trace_id=cb93f2fdd18b4a1289219be14632eeb9&amp;experiment_id=1&amp;trace_id=29a36ca6d3bb4720860417319bbe8d68&amp;experiment_id=1&amp;version=3.1.4\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=f51ec31b099c4ccb884824cd84faf244), Trace(trace_id=2b2a5bac43db4bdf8f1ba27a0c72707f), Trace(trace_id=33d30ce093eb4bcb8959b7e7b14f4f03), Trace(trace_id=585d29108d074c8eb2546d615be4e058), Trace(trace_id=f458046f22604e4cbb206f2ddea55891), Trace(trace_id=fae282bd8d524323a37fbafd71e5e50f), Trace(trace_id=e0f8503464d846308c8ac03dd3897e1a), Trace(trace_id=2f17ef3a251a4472920aac663506297b), Trace(trace_id=cb93f2fdd18b4a1289219be14632eeb9), Trace(trace_id=29a36ca6d3bb4720860417319bbe8d68)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "judge_lm = deepcopy(lm_gemini_flash_2_5)\n",
    "\n",
    "judge_results = []\n",
    "\n",
    "with mlflow.start_run(run_name=\"error_analysis_gemini_2.5_flash\") as run:\n",
    "    with dspy.context(lm=judge_lm, cache=True, track_cost=True):\n",
    "        for example in tqdm(judge_examples, desc=\"Judging examples\"):\n",
    "            module = dspy.ChainOfThought(AssessmentSignature)\n",
    "            jr = module(**example)\n",
    "            jr[\"assessment_reasoning\"] = jr[\"reasoning\"]\n",
    "            del jr[\"reasoning\"]\n",
    "            judge_results.append(\n",
    "                {\n",
    "                    \"id\": example[\"id\"],\n",
    "                    \"model_name\": example[\"model_name\"],\n",
    "                    \"question\": example[\"question\"],\n",
    "                    \"ground_truth_answer\": example[\"ground_truth_answer\"],\n",
    "                    \"predicted_answer\": example[\"predicted_answer\"],\n",
    "                    \"assessment_answer\": jr[\"assessment_answer\"],\n",
    "                    \"assessment_reasoning\": jr[\"assessment_reasoning\"],\n",
    "                }\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(judge_results)\n",
    "grouped = (\n",
    "    df.groupby([\"model_name\", \"assessment_answer\"]).size().reset_index(name=\"count\")\n",
    ")\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(data=grouped, x=\"model_name\", y=\"count\", hue=\"assessment_answer\")\n",
    "plt.title(\"Assessment Answer Counts by Model\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Model Name\")\n",
    "plt.legend(title=\"Assessment Answer\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add value annotations\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:\n",
    "        ax.annotate(\n",
    "            f\"{int(height)}\",\n",
    "            (p.get_x() + p.get_width() / 2, height),\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=10,\n",
    "            color=\"black\",\n",
    "            xytext=(0, 2),\n",
    "            textcoords=\"offset points\",\n",
    "        )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./judge_results/gate_and_probe_judge_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis above, we see that:\n",
    "- Majority of the errors for all our selected models are due to **incorrect ground truth**. \n",
    "- We also see cases where the model was unable to generate the answer in the format as expected by the ground truth. \n",
    "- Finally, somewhat surpringly, we see some results marked as \"OK\", even though we only selected records that didn't match the ground truth using our _exact match_ metric.\n",
    "\n",
    "Let's look through this more closely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth_answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>assessment_answer</th>\n",
       "      <th>assessment_reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Single_ETR/2011/page_22.pdf-3</td>\n",
       "      <td>openai/o4-mini-2025-04-16</td>\n",
       "      <td>so what was the percentage change during this time?</td>\n",
       "      <td>7.605000e-02</td>\n",
       "      <td>7.6%</td>\n",
       "      <td>GROUND_TRUTH_INCORRECT</td>\n",
       "      <td>The question asks for a \"percentage change\". The model correctly c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Single_ETR/2004/page_258.pdf-4</td>\n",
       "      <td>openai/o4-mini-2025-04-16</td>\n",
       "      <td>what is the percent change?</td>\n",
       "      <td>1.473800e-01</td>\n",
       "      <td>14.7%</td>\n",
       "      <td>GROUND_TRUTH_INCORRECT</td>\n",
       "      <td>The question asks for the \"percent change\". The predicted answer p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Single_ADI/2011/page_83.pdf-2</td>\n",
       "      <td>openai/o4-mini-2025-04-16</td>\n",
       "      <td>what growth rate does this represent?</td>\n",
       "      <td>8.290600e-01</td>\n",
       "      <td>82.9%</td>\n",
       "      <td>GROUND_TRUTH_INCORRECT</td>\n",
       "      <td>The question asks for a 'growth rate', which is typically expresse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Single_CB/2008/page_243.pdf-3</td>\n",
       "      <td>openai/o4-mini-2025-04-16</td>\n",
       "      <td>what was the percent change?</td>\n",
       "      <td>7.368000e-02</td>\n",
       "      <td>7.37</td>\n",
       "      <td>GROUND_TRUTH_INCORRECT</td>\n",
       "      <td>The question asks for the \"percent change\". The model correctly ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Single_AMT/2015/page_50.pdf-1</td>\n",
       "      <td>openai/o4-mini-2025-04-16</td>\n",
       "      <td>what was the low for share price for the quarter ended 12/31/15?</td>\n",
       "      <td>8.732000e+01</td>\n",
       "      <td>90.2</td>\n",
       "      <td>GROUND_TRUTH_INCORRECT</td>\n",
       "      <td>The question asks for the low share price for the quarter ended 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Single_SLG/2017/page_114.pdf-3</td>\n",
       "      <td>openai/o3-2025-04-16</td>\n",
       "      <td>so what was the percentage of pension plan contributions out of th...</td>\n",
       "      <td>2.302800e-01</td>\n",
       "      <td>23.03</td>\n",
       "      <td>GROUND_TRUTH_INCORRECT</td>\n",
       "      <td>The question asks for a \"percentage\". The model correctly calculat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Single_JPM/2008/page_177.pdf-4</td>\n",
       "      <td>openai/o3-2025-04-16</td>\n",
       "      <td>what was the total amount of resale agreements in 2008, in millions?</td>\n",
       "      <td>2.080000e+04</td>\n",
       "      <td>200,265</td>\n",
       "      <td>GROUND_TRUTH_INCORRECT</td>\n",
       "      <td>The question asks for the 'total amount of resale agreements in 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Double_IPG/2014/page_95.pdf</td>\n",
       "      <td>openai/o3-2025-04-16</td>\n",
       "      <td>and what is it for the the 2009 one?</td>\n",
       "      <td>1.218121e+07</td>\n",
       "      <td>435259</td>\n",
       "      <td>GROUND_TRUTH_INCORRECT</td>\n",
       "      <td>The question asks for the value for \"the 2009 one\". The previous t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Single_APTV/2018/page_36.pdf-2</td>\n",
       "      <td>openai/o3-2025-04-16</td>\n",
       "      <td>how much does the change in the value of the aptiv plc represent i...</td>\n",
       "      <td>3.080000e-01</td>\n",
       "      <td>30.8%</td>\n",
       "      <td>GROUND_TRUTH_INCORRECT</td>\n",
       "      <td>The question asks for the answer \"in percentage\". The model correc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Single_RCL/2016/page_7.pdf-3</td>\n",
       "      <td>openai/o3-2025-04-16</td>\n",
       "      <td>what percentage change does this represent?</td>\n",
       "      <td>1.600000e-01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>GROUND_TRUTH_INCORRECT</td>\n",
       "      <td>The question asks for a 'percentage change'. The model correctly c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                 model_name  \\\n",
       "0     Single_ETR/2011/page_22.pdf-3  openai/o4-mini-2025-04-16   \n",
       "1    Single_ETR/2004/page_258.pdf-4  openai/o4-mini-2025-04-16   \n",
       "3     Single_ADI/2011/page_83.pdf-2  openai/o4-mini-2025-04-16   \n",
       "4     Single_CB/2008/page_243.pdf-3  openai/o4-mini-2025-04-16   \n",
       "5     Single_AMT/2015/page_50.pdf-1  openai/o4-mini-2025-04-16   \n",
       "..                              ...                        ...   \n",
       "282  Single_SLG/2017/page_114.pdf-3       openai/o3-2025-04-16   \n",
       "283  Single_JPM/2008/page_177.pdf-4       openai/o3-2025-04-16   \n",
       "284     Double_IPG/2014/page_95.pdf       openai/o3-2025-04-16   \n",
       "286  Single_APTV/2018/page_36.pdf-2       openai/o3-2025-04-16   \n",
       "288    Single_RCL/2016/page_7.pdf-3       openai/o3-2025-04-16   \n",
       "\n",
       "                                                                  question  \\\n",
       "0                      so what was the percentage change during this time?   \n",
       "1                                              what is the percent change?   \n",
       "3                                    what growth rate does this represent?   \n",
       "4                                             what was the percent change?   \n",
       "5         what was the low for share price for the quarter ended 12/31/15?   \n",
       "..                                                                     ...   \n",
       "282  so what was the percentage of pension plan contributions out of th...   \n",
       "283   what was the total amount of resale agreements in 2008, in millions?   \n",
       "284                                   and what is it for the the 2009 one?   \n",
       "286  how much does the change in the value of the aptiv plc represent i...   \n",
       "288                            what percentage change does this represent?   \n",
       "\n",
       "     ground_truth_answer predicted_answer       assessment_answer  \\\n",
       "0           7.605000e-02             7.6%  GROUND_TRUTH_INCORRECT   \n",
       "1           1.473800e-01            14.7%  GROUND_TRUTH_INCORRECT   \n",
       "3           8.290600e-01            82.9%  GROUND_TRUTH_INCORRECT   \n",
       "4           7.368000e-02             7.37  GROUND_TRUTH_INCORRECT   \n",
       "5           8.732000e+01             90.2  GROUND_TRUTH_INCORRECT   \n",
       "..                   ...              ...                     ...   \n",
       "282         2.302800e-01            23.03  GROUND_TRUTH_INCORRECT   \n",
       "283         2.080000e+04          200,265  GROUND_TRUTH_INCORRECT   \n",
       "284         1.218121e+07           435259  GROUND_TRUTH_INCORRECT   \n",
       "286         3.080000e-01            30.8%  GROUND_TRUTH_INCORRECT   \n",
       "288         1.600000e-01             16.0  GROUND_TRUTH_INCORRECT   \n",
       "\n",
       "                                                      assessment_reasoning  \n",
       "0    The question asks for a \"percentage change\". The model correctly c...  \n",
       "1    The question asks for the \"percent change\". The predicted answer p...  \n",
       "3    The question asks for a 'growth rate', which is typically expresse...  \n",
       "4    The question asks for the \"percent change\". The model correctly ca...  \n",
       "5    The question asks for the low share price for the quarter ended 12...  \n",
       "..                                                                     ...  \n",
       "282  The question asks for a \"percentage\". The model correctly calculat...  \n",
       "283  The question asks for the 'total amount of resale agreements in 20...  \n",
       "284  The question asks for the value for \"the 2009 one\". The previous t...  \n",
       "286  The question asks for the answer \"in percentage\". The model correc...  \n",
       "288  The question asks for a 'percentage change'. The model correctly c...  \n",
       "\n",
       "[226 rows x 7 columns]"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"assessment_answer\"] == \"GROUND_TRUTH_INCORRECT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curriculum-first pass surfaced a gap between our metric and reality. Several \"errors\" are actually correct answers hidden by formatting. Manual review shows many EM misses are due to surface form, not reasoning.\n",
    "\n",
    "There are also cases where the ground-truth in the dataset is incorrect.\n",
    "\n",
    "**What broke EM**\n",
    "\n",
    "- Numeric formatting: thousands separators, ‚Äú0.5M‚Äù vs ‚Äú500000‚Äù.\n",
    "- Units and scaling: $, %, M/B suffixes; percent vs decimal.\n",
    "- Rounding/tolerance: 2dp rounding vs full precision.\n",
    "- Boolean variants: yes/true/1 vs no/false/0.\n",
    "\n",
    "The above results are **not conclusive** by any means, since the LLM-as-a-judge approach also has known flaws. However, it does give us some pointers on how to improve the model performance from here!\n",
    "\n",
    "**Note**: LLM-as-judge remains imperfect. We‚Äôll retain periodic human spot-checks. With cleaner metrics and logging, the next step is to test if DSPy‚Äôs optimizers actually lift EM under the Easy‚ÜíMedium‚ÜíHard schedule without inflating token cost.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
