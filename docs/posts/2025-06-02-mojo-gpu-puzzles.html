<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Shubham Gupta - GPUs go brrr with Mojo</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-CLKTGRWBQT"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-CLKTGRWBQT', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Shubham Gupta</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/goodhamgupta"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">GPUs go brrr with Mojo</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#why-mojo" id="toc-why-mojo" class="nav-link active" data-scroll-target="#why-mojo">Why Mojo?</a></li>
  <li><a href="#gpu-memory" id="toc-gpu-memory" class="nav-link" data-scroll-target="#gpu-memory">GPUs 101</a></li>
  <li><a href="#infrastructure" id="toc-infrastructure" class="nav-link" data-scroll-target="#infrastructure">Infrastructure</a></li>
  <li><a href="#part-1-gpu-fundamentals" id="toc-part-1-gpu-fundamentals" class="nav-link" data-scroll-target="#part-1-gpu-fundamentals">Part 1: GPU Fundamentals</a>
  <ul class="collapse">
  <li><a href="#puzzle-01" id="toc-puzzle-01" class="nav-link" data-scroll-target="#puzzle-01">Puzzle 1: Map</a></li>
  <li><a href="#puzzle-02" id="toc-puzzle-02" class="nav-link" data-scroll-target="#puzzle-02">Puzzle 2: Zip</a></li>
  <li><a href="#puzzle-03" id="toc-puzzle-03" class="nav-link" data-scroll-target="#puzzle-03">Puzzle 3: Guards</a></li>
  <li><a href="#puzzle-04" id="toc-puzzle-04" class="nav-link" data-scroll-target="#puzzle-04">Puzzle 4: 2D Map</a></li>
  <li><a href="#puzzle-05" id="toc-puzzle-05" class="nav-link" data-scroll-target="#puzzle-05">Puzzle 5: Broadcast</a></li>
  <li><a href="#puzzle-06" id="toc-puzzle-06" class="nav-link" data-scroll-target="#puzzle-06">Puzzle 6: Blocks</a></li>
  <li><a href="#puzzle-07" id="toc-puzzle-07" class="nav-link" data-scroll-target="#puzzle-07">Puzzle 7: 2D Blocks</a></li>
  <li><a href="#puzzle-08" id="toc-puzzle-08" class="nav-link" data-scroll-target="#puzzle-08">Puzzle 8: Shared Memory</a></li>
  </ul></li>
  <li><a href="#part-2-gpu-algorithms" id="toc-part-2-gpu-algorithms" class="nav-link" data-scroll-target="#part-2-gpu-algorithms">Part 2: GPU Algorithms</a>
  <ul class="collapse">
  <li><a href="#puzzle-09" id="toc-puzzle-09" class="nav-link" data-scroll-target="#puzzle-09">Puzzle 9: Pooling</a></li>
  <li><a href="#puzzle-10" id="toc-puzzle-10" class="nav-link" data-scroll-target="#puzzle-10">Puzzle 10: Dot Product</a></li>
  <li><a href="#puzzle-11" id="toc-puzzle-11" class="nav-link" data-scroll-target="#puzzle-11">Puzzle 11: 1D Convolution</a></li>
  <li><a href="#bonus-2d-convolution" id="toc-bonus-2d-convolution" class="nav-link" data-scroll-target="#bonus-2d-convolution">Bonus: 2D Convolution</a></li>
  <li><a href="#puzzle-12" id="toc-puzzle-12" class="nav-link" data-scroll-target="#puzzle-12">Puzzle 12: Prefix Sum</a></li>
  </ul></li>
  <li><a href="#citation" id="toc-citation" class="nav-link" data-scroll-target="#citation">Citation</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This blog will be updated with puzzle solutions as they’re released. Stay tuned for more updates!</p>
</div>
</div>
<p>After a super-long break from writing blogs, I’ve decided to get back to it this year.</p>
<p>I’ve always been interested in systems programming, but somehow never <em>really</em> picked it up. The rate of progress in the GenAI space has been exponential recently, with players like Google <span class="citation" data-cites="Google"><a href="#ref-Google" role="doc-biblioref">[1]</a></span> reportedly processing 9.7 trillion tokens a month. Companies are now investing more time and resources interest in making these Large Language Modelsas fast and cheap as possible, by improving training and inference efficiency using “moar” compute.</p>
<p>I briefly spoke about <a href="https://www.figma.com/deck/Sq9frEEoTFgFWthOJ4EM5w/intro_gpu_cuda?node-id=1-37&amp;t=VNzh9p2qKrHNSTJj-1">GPU computing last year</a>, and finally decided to learn it this summer. The goal is to eventually be able to implement kernels for fast matmuls, softmax, and FlashAttention.</p>
<section id="why-mojo" class="level2">
<h2 class="anchored" data-anchor-id="why-mojo">Why Mojo?</h2>
<p>I’ve tried learning Rust <a href="https://github.com/goodhamgupta/rustlings">multiple</a> <a href="https://github.com/goodhamgupta/100-exercises-to-learn-rust/">times</a>, along with a few stints of trying C, C++ and Zig, but I never really felt as comfortable in these languages as I do in Python and Elixir.</p>
<p>In early 2023, Modular announced Mojo🔥, a new systems-programming language promising:</p>
<ul>
<li>Python-like syntax</li>
<li>Support for both CPU and GPU architectures</li>
<li>Kernel autofusion</li>
<li>Builds on MLIR</li>
<li>Traits and bounds checking</li>
<li>Interopeability with PTX, Python, C</li>
</ul>
<p>Modular has since announced Max, their AI inference platform, built on Mojo. The released <a href="https://github.com/modular/modular/tree/main/max/kernels">all kernels</a> available as part of the platform, along with their own version<span class="citation" data-cites="modularpuzzles"><a href="#ref-modularpuzzles" role="doc-biblioref">[2]</a></span> of Sasha Rush’s GPU Puzzles <span class="citation" data-cites="GPUPuzzles"><a href="#ref-GPUPuzzles" role="doc-biblioref">[3]</a></span> in Mojo. IMO, their kernels were much easier to read compared to CUDA/Triton implementations, so I decided to learn a bit more about how to write these kernels.</p>
</section>
<section id="gpu-memory" class="level2">
<h2 class="anchored" data-anchor-id="gpu-memory">GPUs 101</h2>
<p>Not sure what to put in here. Skipping for now.</p>
<p><img src="mojo_gpu_puzzles/gpu_memory.png" class="img-fluid"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="mojo_gpu_puzzles/gpu_flow_hierachy.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p><img src="mojo_gpu_puzzles/program_flow.png" class="img-fluid"></p>
</section>
<section id="infrastructure" class="level2">
<h2 class="anchored" data-anchor-id="infrastructure">Infrastructure</h2>
<p>If you plan on solving these puzzles, remember to pick a <a href="https://docs.modular.com/max/faq/#gpu-requirements">compatible GPU</a> and follow the <a href="https://builds.modular.com/puzzles/howto.html">setup instructions</a></p>
<p>I completed the puzzles on a instance with a RTX4090 Ti chip, rented via <a href="https://www.primeintellect.ai/">Prime Intellect</a> at <strong>0.22 $/hr</strong>!</p>
</section>
<section id="part-1-gpu-fundamentals" class="level2">
<h2 class="anchored" data-anchor-id="part-1-gpu-fundamentals">Part 1: GPU Fundamentals</h2>
<p>The Modular team has created beautiful <a href="https://github.com/ManimCommunity/manim">Manim</a> visualizations for each puzzle, making the concepts much more intuitive. I’ll walk through these visualizations as we tackle each problem.</p>
<section id="puzzle-01" class="level3">
<h3 class="anchored" data-anchor-id="puzzle-01"><a href="https://builds.modular.com/puzzles/puzzle_01/puzzle_01.html">Puzzle 1: Map</a></h3>
<p>In this puzzle, we aim to add a scalar to a vector. Specifically, we want to use a separate thread for each element in the vector, add the scalar, and write the result to the output memory.</p>
<p>When we create the kernel, the scalar will be effectively “broadcast” or expanded to match the shape of the input vector. This allows each element of the vector to be independently added with the scalar value in parallel by its dedicated thread, following the <a href="https://docs.pytorch.org/docs/stable/notes/broadcasting.html">broadcasting rules</a>.</p>
<div class="quarto-figure quarto-figure-middle">
<figure class="figure">
<p><img src="mojo_gpu_puzzles/p01_vector_addition.png" class="img-fluid quarto-figure quarto-figure-middle figure-img"></p>
</figure>
</div>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p01.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb1" data-filename="p01.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> add_10(out: UnsafePointer[Scalar[dtype]], a: UnsafePointer[Scalar[dtype]]):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> thread_idx.x</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    out[i] <span class="op">=</span> a[i] <span class="op">+</span> <span class="dv">10</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p01</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([10.0, 11.0, 12.0, 13.0])</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([10.0, 11.0, 12.0, 13.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
<section id="puzzle-02" class="level3">
<h3 class="anchored" data-anchor-id="puzzle-02"><a href="https://builds.modular.com/puzzles/puzzle_02/puzzle_02.html">Puzzle 2: Zip</a></h3>
<p>This is an extension of the map puzzle. Now, we aim to add 2 tensors together.</p>
<p><img src="mojo_gpu_puzzles/p02.png" class="img-fluid"></p>
<p>As in puzzle 1, the aim is to use one individual thread for elements at a specific index in both vectors.</p>
<p><img src="mojo_gpu_puzzles/p02_thread.png" class="img-fluid"></p>
<p>Note that we assume the entire array will fit within a single block, which is why there is no code for boundary checking, edge cases, etc.</p>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p02.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb3" data-filename="p02.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> add(</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    out: UnsafePointer[Scalar[dtype]],</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    a: UnsafePointer[Scalar[dtype]],</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    b: UnsafePointer[Scalar[dtype]],</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> thread_idx.x</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    out[i] <span class="op">=</span> a[i] <span class="op">+</span> b[i]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p02</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># a: HostBuffer([0.0, 1.0, 2.0, 3.0])</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># b: HostBuffer([0.0, 1.0, 2.0, 3.0])</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([0.0, 2.0, 4.0, 6.0])</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([0.0, 2.0, 4.0, 6.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
<section id="puzzle-03" class="level3">
<h3 class="anchored" data-anchor-id="puzzle-03"><a href="https://builds.modular.com/puzzles/puzzle_03/puzzle_03.html">Puzzle 3: Guards</a></h3>
<p>The only difference between this puzzle and <a href="#puzzle-01">Puzzle 1</a> is that now it’s possible that the size of the GPU block is larger than the given input.</p>
<p>In GPU programming, “guards” refer to conditional statements that check if a thread should perform work based on its index. GPUs launch threads in fixed-size groups (blocks), and often these blocks contain more threads than elements in our array.</p>
<p>In this case, we need to check if the current thread index is valid before applying our computation on the vector. Without this guard, threads with indices beyond our array bounds would cause memory access violations.</p>
<p><img src="mojo_gpu_puzzles/p03.png" class="img-fluid"></p>
<p>The image above illustrates how some threads have indices that exceed the array size and must be prevented from accessing memory.</p>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p03.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb5" data-filename="p03.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> add_10_guard(</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    out: UnsafePointer[Scalar[dtype]],</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    a: UnsafePointer[Scalar[dtype]],</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> thread_idx.x</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">&lt;</span> size:</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        out[i] <span class="op">=</span> a[i] <span class="op">+</span> <span class="dv">10</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that the size of the array is also sent as input to the kernel, as computing it in the kernel would defeat the purpose of parallelisation. While these conditional checks are necessary for correctness, they can introduce some performance overhead due to thread divergence within warps. We’ll cover this in more detail shortly.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p03</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># in: HostBuffer([0.0, 1.0, 2.0, 3.0])</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([10.0, 11.0, 12.0, 13.0])</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([10.0, 11.0, 12.0, 13.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
<section id="puzzle-04" class="level3">
<h3 class="anchored" data-anchor-id="puzzle-04"><a href="https://builds.modular.com/puzzles/puzzle_04/puzzle_04.html">Puzzle 4: 2D Map</a></h3>
<p>Similar to <a href="#puzzle-02">Puzzle 2</a>, instead of operating on scalars with 1D tensors, we will now use 2D tensors.</p>
<p>Mojo, similar to CUDA, typically uses <a href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">row-major</a> order for array storage, meaning data is stored sequentially by rows in memory.</p>
<p><img src="mojo_gpu_puzzles/p04_row_col_major.png" class="img-fluid"></p>
<p>Given the row-major format, the elements are accessed using the formula:</p>
<p><span class="math display">\[
A_{R,C} = R*\text{size\_of\_array} + C
\]</span></p>
<section id="raw-memory-approach" class="level4">
<h4 class="anchored" data-anchor-id="raw-memory-approach">Raw Memory Approach</h4>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p04.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb7" data-filename="p04.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> add_10_2d(</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    out: UnsafePointer[Scalar[dtype]],</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    a: UnsafePointer[Scalar[dtype]],</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> thread_idx.y</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    col <span class="op">=</span> thread_idx.x</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> row <span class="op">&lt;</span> size <span class="kw">and</span> col <span class="op">&lt;</span> size:</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        out[row <span class="op">*</span> size <span class="op">+</span> col] <span class="op">=</span> a[row<span class="op">*</span>size<span class="op">+</span>col] <span class="op">+</span> <span class="dv">10</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p04</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># in: HostBuffer([0.0, 1.0, 2.0, 3.0]) -- shaped as 2x2 row-major</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([10.0, 11.0, 12.0, 13.0])</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([10.0, 11.0, 12.0, 13.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
<section id="layouttensor" class="level4">
<h4 class="anchored" data-anchor-id="layouttensor">LayoutTensor</h4>
<p>LayoutTensor<span class="citation" data-cites="llvmlayouttensor"><a href="#ref-llvmlayouttensor" role="doc-biblioref">[4]</a></span> is Mojo’s abstraction to work on a Tensor.</p>
<p>Specifically, LayoutTensor aims to provide:</p>
<ul>
<li>High level primitive to perform operations on tiles.</li>
<li>Flexible memory layouts, with support for row-based, column-based and tiled organisation of data in memory.</li>
<li>Expose functions/parameters to enable auto-tuning or manual experimentation.</li>
<li>Access to hardware without inline assembly.</li>
</ul>
<p>Mojo(and LayoutTensor) follow this “parameter syntax”<span class="citation" data-cites="mojotalk"><a href="#ref-mojotalk" role="doc-biblioref">[5]</a></span>, which is similar to how C++ templates are defined. This was a bit difficult for me to grasp since I don’t have a C++ background, and caused a few troubles in the upcoming puzzles. I was happy to learn that I’m not the only one struggling with it though!<span class="citation" data-cites="jeffniutriton"><a href="#ref-jeffniutriton" role="doc-biblioref">[6]</a></span> .</p>
<p><img src="mojo_gpu_puzzles/p04_parameter_syntax.png" class="img-fluid"></p>
<p>The features that looked most interesting to me are:</p>
<ul>
<li>Natural Indexing: Index a element using the format <code>A[row, col]</code></li>
<li>Automatic Bounds Checking: I’ve (ab)used this feature in the upcoming puzzles.</li>
</ul>
<p>Some examples of <a href="https://builds.modular.com/puzzles/puzzle_04/introduction_layout_tensor.html#basic-usage-example">LayoutTensor in practice</a>:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>layout_tensor.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb9" data-filename="layout_tensor.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> layout <span class="im">import</span> Layout, LayoutTensor</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define layout</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> HEIGHT <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> WIDTH <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> layout <span class="op">=</span> Layout.row_major(HEIGHT, WIDTH)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create tensor</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> LayoutTensor[dtype, layout](<span class="bu">buffer</span>.unsafe_ptr())</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Access elements naturally</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>tensor[<span class="dv">0</span>, <span class="dv">0</span>] <span class="op">=</span> <span class="fl">1.0</span>  <span class="co"># First element</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>tensor[<span class="dv">1</span>, <span class="dv">2</span>] <span class="op">=</span> <span class="fl">2.0</span>  <span class="co"># Last element</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Column-major layout</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>layout_col <span class="op">=</span> Layout.col_major(HEIGHT, WIDTH)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Tiled layout (for better cache utilization)</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>layout_tiled <span class="op">=</span> tensor.tiled[<span class="dv">4</span>, <span class="dv">4</span>](HEIGHT, WIDTH)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p04.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb10" data-filename="p04.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> add_10_2d(</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    out: LayoutTensor[mut<span class="op">=</span><span class="va">True</span>, dtype, layout],</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">True</span>, dtype, layout],</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> thread_idx.y</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    col <span class="op">=</span> thread_idx.x</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">NOTE</span><span class="co">: With layout tensor, this is not really necessary, but it helps prevent unwanted memory access</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> row <span class="op">&lt;</span> size <span class="kw">and</span> col <span class="op">&lt;</span> size: </span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        out[row, col] <span class="op">=</span> a[row, col] <span class="op">+</span> <span class="fl">10.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p04_layout_tensor</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># in: HostBuffer([0.0, 1.0, 2.0, 3.0])</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># out shape: 2 x 2</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([10.0, 11.0, 12.0, 13.0])</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([10.0, 11.0, 12.0, 13.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
</section>
<section id="puzzle-05" class="level3">
<h3 class="anchored" data-anchor-id="puzzle-05"><a href="https://builds.modular.com/puzzles/puzzle_05/puzzle_05.html">Puzzle 5: Broadcast</a></h3>
<p>We aim to broadcast the addition operation over two vectors. Following the <a href="https://docs.pytorch.org/docs/stable/notes/broadcasting.html">broadcasting rules</a>, the result will be an outer-product of the given vectors.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="mojo_gpu_puzzles/p05_vector_addition.png" class="quarto-figure quarto-figure-center figure-img" height="600"></p>
</figure>
</div>
<section id="raw-memory-version" class="level4">
<h4 class="anchored" data-anchor-id="raw-memory-version">Raw Memory Version</h4>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p05.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb12" data-filename="p05.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> broadcast_add(</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    out: UnsafePointer[Scalar[dtype]],</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    a: UnsafePointer[Scalar[dtype]],</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    b: UnsafePointer[Scalar[dtype]],</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> thread_idx.y</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    col <span class="op">=</span> thread_idx.x</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> row <span class="op">&lt;</span> size <span class="kw">and</span> col <span class="op">&lt;</span> size:</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>        out[row<span class="op">*</span>size <span class="op">+</span> col] <span class="op">=</span> a[row] <span class="op">+</span> b[col]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb13"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p05</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># in a: HostBuffer([0.0, 1.0])</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># in b: HostBuffer([0.0, 1.0])</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([0.0, 1.0, 1.0, 2.0])</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([0.0, 1.0, 1.0, 2.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
<section id="layout-tensor" class="level4">
<h4 class="anchored" data-anchor-id="layout-tensor">Layout Tensor</h4>
<p>Since we know the inputs are 1D vectors, we use only one dimension from each of the vectors, and set the other to 0 i.e the first element.</p>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p05_layout_tensor.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb14" data-filename="p05_layout_tensor.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> broadcast_add[</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    out_layout: Layout,</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    a_layout: Layout,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    b_layout: Layout,</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    out: LayoutTensor[mut<span class="op">=</span><span class="va">True</span>, dtype, out_layout],</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, a_layout],</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    b: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, b_layout],</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> thread_idx.y</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    col <span class="op">=</span> thread_idx.x</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> row <span class="op">&lt;</span> size <span class="kw">and</span> col <span class="op">&lt;</span> size:</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        out[row, col] <span class="op">=</span> a[<span class="dv">0</span>, row] <span class="op">+</span> b[col, <span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb15"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p05_layout_tensor</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># in a: HostBuffer([0.0, 1.0])</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># in b: HostBuffer([0.0, 1.0])</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># out shape: 2 x 2</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([0.0, 1.0, 1.0, 2.0])</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([0.0, 1.0, 1.0, 2.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
</section>
<section id="puzzle-06" class="level3">
<h3 class="anchored" data-anchor-id="puzzle-06"><a href="https://builds.modular.com/puzzles/puzzle_06/puzzle_06.html">Puzzle 6: Blocks</a></h3>
<p>Building on Puzzles 4[#puzzle-04] and 5[#puzzle-5], we now aim to add a scalar to a tensor. We also have the addtional restriction around having fewer threads than the elements in our array, per block. This means that now apart from using the local indices of the current thread(<code>thread_idx.y</code> and <code>thread_idx.x</code>), we now also need to identify the current block, using <code>block_idx.y</code> and <code>block_idx.x</code>. The formula for calculating the index, in row-major format, is:</p>
<p><span class="math display">\[
idx = block\_idx.x * block\_dim.x + thread\_idx.x
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="mojo_gpu_puzzles/p06.png" class="quarto-figure quarto-figure-center figure-img" height="600"></p>
</figure>
</div>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p06.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb16" data-filename="p06.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> SIZE <span class="op">=</span> <span class="dv">9</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID <span class="op">=</span> (<span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK <span class="op">=</span> (<span class="dv">4</span>, <span class="dv">1</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> dtype <span class="op">=</span> DType.float32</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> add_10_blocks(</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    out: UnsafePointer[Scalar[dtype]],</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    a: UnsafePointer[Scalar[dtype]],</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">&lt;</span> size:</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>        out[i] <span class="op">=</span> a[i] <span class="op">+</span> <span class="dv">10</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</details>
</section>
<section id="puzzle-07" class="level3">
<h3 class="anchored" data-anchor-id="puzzle-07"><a href="https://builds.modular.com/puzzles/puzzle_07/puzzle_07.html">Puzzle 7: 2D Blocks</a></h3>
<p>As the title suggests, we now have a 2D structure for both blocks and grids, and the number of threads per block is lesser than the total number of elements in the input tensor.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="mojo_gpu_puzzles/p07.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<section id="raw-memory" class="level4">
<h4 class="anchored" data-anchor-id="raw-memory">Raw Memory</h4>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p07.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb17" data-filename="p07.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> SIZE <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID <span class="op">=</span> (<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK <span class="op">=</span> (<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> dtype <span class="op">=</span> DType.float32</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> add_10_blocks_2d(</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    out: UnsafePointer[Scalar[dtype]],</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    a: UnsafePointer[Scalar[dtype]],</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> block_dim.y <span class="op">*</span> block_idx.y <span class="op">+</span> thread_idx.y</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    col <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> row <span class="op">&lt;</span> size <span class="kw">and</span> col <span class="op">&lt;</span> size:</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>        out[row <span class="op">*</span> size <span class="op">+</span> col] <span class="op">=</span> a[row <span class="op">*</span> size <span class="op">+</span> col] <span class="op">+</span> <span class="fl">10.0</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="st">```bash</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="er">pixi run p07</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>
&lt;/details&gt;

#### Layout Tensor

&lt;details open&gt;
&lt;summary&gt; **Solution** &lt;/summary&gt;

```{.mojo filename=p07.mojo}
alias SIZE = 9
alias BLOCKS_PER_GRID = (3, 1)
alias THREADS_PER_BLOCK = (4, 1)
alias dtype = DType.float32


fn add_10_blocks(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    i = block_dim.x * block_idx.x + thread_idx.x
    if i &lt; size:
        out[i] = a[i] + 10</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p07_layout_tensor</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: 11.0 11.0 11.0 11.0 11.0</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 11.0 11.0 11.0 11.0 11.0</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 11.0 11.0 11.0 11.0 11.0</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 11.0 11.0 11.0 11.0 11.0</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 11.0 11.0 11.0 11.0 11.0</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: 11.0 11.0 11.0 11.0 11.0</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 11.0 11.0 11.0 11.0 11.0</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 11.0 11.0 11.0 11.0 11.0</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 11.0 11.0 11.0 11.0 11.0</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 11.0 11.0 11.0 11.0 11.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
</section>
<section id="puzzle-08" class="level3">
<h3 class="anchored" data-anchor-id="puzzle-08"><a href="https://builds.modular.com/puzzles/puzzle_08/puzzle_08.html">Puzzle 8: Shared Memory</a></h3>
<p>In this puzzle we leverage shared memory (SRAM). Like <a href="#puzzle-07">Puzzle 7</a>, we add a scalar to a 2D tensor, but now each block has fewer threads than there are input elements.</p>
<p>As shown <a href="#gpu-memory">above</a>, SRAM is orders of magnitude faster than DRAM. Accessing global memory directly is slow, so we first load data into shared memory—then perform our computations for much faster access.</p>
<p>Although this input is too small to reveal a noticeable speedup, the advantage of shared memory becomes substantial as array sizes increase.</p>
<p>Now, because our operations depend on all records being available in shared memory, we need to wait for all threads in a block to write data to the shared memory before we can access it. Failure to do this can lead to deadlocks or undefined behaviour. Hence, we need <strong>synchronisation</strong>!</p>
<p>Mojo has support for all the common <a href="https://docs.modular.com/mojo/stdlib/gpu/sync/#functions">synchronisation primitives</a>, similar to <a href="https://nvidia.github.io/cccl/libcudacxx/extended_api/synchronization_primitives.html">CUDA primitives</a>. For this puzzle, we need to use the <code>barrier</code> synchronisation, which is the same as <code>_syncThreads()</code> in CUDA: Ensure all threads within a thread block reach the barrier before any can proceed.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="mojo_gpu_puzzles/p08.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<section id="raw-memory-1" class="level4">
<h4 class="anchored" data-anchor-id="raw-memory-1">Raw memory</h4>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p08.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb20" data-filename="p08.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> TPB <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> SIZE <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID <span class="op">=</span> (<span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK <span class="op">=</span> (TPB, <span class="dv">1</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> dtype <span class="op">=</span> DType.float32</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> add_10_shared(</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    out: UnsafePointer[Scalar[dtype]],</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    a: UnsafePointer[Scalar[dtype]],</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    shared <span class="op">=</span> stack_allocation[</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        TPB,</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>        Scalar[dtype],</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>        address_space <span class="op">=</span> AddressSpace.SHARED,</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>    ]()</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    global_i <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>    local_i <span class="op">=</span> thread_idx.x</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># local data into shared memory</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> size:</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>        shared[local_i] <span class="op">=</span> a[global_i]</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># wait for all threads to complete</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># works within a thread block</span></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> size:</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>        out[global_i] <span class="op">=</span> shared[local_i] <span class="op">+</span> <span class="fl">10.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb21"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p08</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
<section id="layouttensor-1" class="level4">
<h4 class="anchored" data-anchor-id="layouttensor-1">LayoutTensor</h4>
<p>Key difference here is to use <a href="https://builds.modular.com/puzzles/puzzle_08/layout_tensor.html#key-differences-from-raw-approach">LayoutTensorBuild instead of stack_allocation</a> to allocate shared memory.</p>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p08_layout_tensor.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb22" data-filename="p08_layout_tensor.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> TPB <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> SIZE <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID <span class="op">=</span> (<span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK <span class="op">=</span> (TPB, <span class="dv">1</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> dtype <span class="op">=</span> DType.float32</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> layout <span class="op">=</span> Layout.row_major(SIZE)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> add_10_shared_layout_tensor[</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    layout: Layout</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    out: LayoutTensor[mut<span class="op">=</span><span class="va">True</span>, dtype, layout],</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">True</span>, dtype, layout],</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Allocate shared memory using tensor builder</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    shared <span class="op">=</span> tb[dtype]().row_major[TPB]().shared().alloc()</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    global_i <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    local_i <span class="op">=</span> thread_idx.x</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> size:</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>        shared[local_i] <span class="op">=</span> a[global_i]</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> size:</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>        out[global_i] <span class="op">=</span> shared[local_i] <span class="op">+</span> <span class="fl">10.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb23"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p08_layout_tensor</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
</section>
</section>
<section id="part-2-gpu-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="part-2-gpu-algorithms">Part 2: GPU Algorithms</h2>
<p>This section primarily aims to implement basic algorithms used in building models, such as pooling, convolutions, etc.</p>
<section id="puzzle-09" class="level3">
<h3 class="anchored" data-anchor-id="puzzle-09"><a href="https://builds.modular.com/puzzles/puzzle_09/puzzle_09.html">Puzzle 9: Pooling</a></h3>
<p>Pooling is a classic trick in neural networks for shrinking down your data—think of it as a way to “summarize” regions of an image or tensor. Instead of looking at every single pixel, pooling (like max or average pooling) slides a window over your data and grabs just the most important info from each patch. On GPUs, pooling is a perfect fit: each thread can independently process a window, so you get massive parallelism and a big speedup compared to CPUs.</p>
<p>This puzzle is a bit different compared to traditional pooling: Instead of having a “kernel”, each output element is the running sum of the all the elements in the current window.</p>
<p><img src="mojo_gpu_puzzles/p09.png" class="img-fluid"></p>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p09.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb24" data-filename="p09.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> TPB <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> SIZE <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK <span class="op">=</span> (TPB, <span class="dv">1</span>)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> dtype <span class="op">=</span> DType.float32</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> pooling(</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    out: UnsafePointer[Scalar[dtype]],</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    a: UnsafePointer[Scalar[dtype]],</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    shared <span class="op">=</span> stack_allocation[</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        TPB,</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>        Scalar[dtype],</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>        address_space <span class="op">=</span> AddressSpace.SHARED,</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    ]()</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    global_i <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    local_i <span class="op">=</span> thread_idx.x</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> size:</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>        shared[local_i] <span class="op">=</span> a[global_i]</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> size:</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> local_i <span class="op">-</span> <span class="dv">2</span> <span class="op">&gt;=</span> <span class="dv">0</span>:</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>            out[global_i] <span class="op">=</span> (</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>                shared[local_i <span class="op">-</span> <span class="dv">2</span>] <span class="op">+</span> shared[local_i <span class="op">-</span> <span class="dv">1</span>] <span class="op">+</span> shared[local_i]</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> local_i <span class="op">-</span> <span class="dv">1</span> <span class="op">&gt;=</span> <span class="dv">0</span>:</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>            out[global_i] <span class="op">=</span> shared[local_i <span class="op">-</span> <span class="dv">1</span>] <span class="op">+</span> shared[local_i]</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>            out[global_i] <span class="op">=</span> shared[local_i]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb25"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p09</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<p>The LayoutTensor version is nearly identical to the Raw Memory approach, so we’ll omit the code here for brevity.</p>
</section>
<section id="puzzle-10" class="level3">
<h3 class="anchored" data-anchor-id="puzzle-10"><a href="https://builds.modular.com/puzzles/puzzle_10/puzzle_10.html">Puzzle 10: Dot Product</a></h3>
<p>The Dot Product of two vectors <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> is defined as <span class="citation" data-cites="wikipediadotproduct"><a href="#ref-wikipediadotproduct" role="doc-biblioref">[7]</a></span>:</p>
<p><span class="math display">\[
c = a \cdot b = \sum_{i=0}^{n-1} a_i b_i
\]</span></p>
<p>Similar to the previous puzzles, we can implement the dot-product by copying data to the shared memory, and running our operations on it.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="mojo_gpu_puzzles/p10.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>To implement dot product efficiently on a GPU, we will use <strong>parallel reduction</strong>. This is a classic pattern for aggregating values (sum, min, max, etc.) across a large array using many threads. The general flow is:</p>
<p>Picture Zeno’s “half-way” paradox <span class="citation" data-cites="zeno_dichotomy_paradox"><a href="#ref-zeno_dichotomy_paradox" role="doc-biblioref">[8]</a></span>: you keep halving the leftover distance until you’re done. A parallel reduction does the same—each round halves the number of active threads instead of the distance.</p>
<p><img src="mojo_gpu_puzzles/zeno_paradox.png" class="img-fluid"></p>
<ul>
<li>Every thread multiplies its assigned <code>a</code> and <code>b</code> elements and writes the partial product into shared memory.</li>
<li>Each reduction round:
<ul>
<li>The active-thread count is cut in half (<code>stride /= 2</code>).</li>
<li>Each surviving thread adds its value to the partner <code>stride</code> positions away.</li>
<li>A <code>barrier()</code> guarantees all writes land before the next “half-step.”</li>
</ul></li>
<li>After log₂ (n) halvings, Zeno’s finish line is crossed—thread 0 alone holds the final dot-product.</li>
</ul>
<p>This pattern is fast, highly parallel, and used everywhere in GPU programming for reductions (sum, min, max, etc).</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout-nrow="3">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="mojo_gpu_puzzles/pr_p1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="500"></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="mojo_gpu_puzzles/pr_p2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="500"></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="mojo_gpu_puzzles/pr_p3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="500"></p>
</figure>
</div>
</div>
</div>
</div>
<section id="raw-memory-2" class="level4">
<h4 class="anchored" data-anchor-id="raw-memory-2">Raw Memory</h4>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p10.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb26" data-filename="p10.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> dot_product(</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    output: UnsafePointer[Scalar[dtype]],</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    a: UnsafePointer[Scalar[dtype]],</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    b: UnsafePointer[Scalar[dtype]],</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    shared <span class="op">=</span> stack_allocation[</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        TPB, Scalar[dtype], address_space <span class="op">=</span> AddressSpace.SHARED</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    ]()</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    global_idx <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>    local_idx <span class="op">=</span> thread_idx.x</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_idx <span class="op">&lt;</span> size:</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>        shared[local_idx] <span class="op">=</span> a[global_idx] <span class="op">*</span> b[global_idx]</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>    stride <span class="op">=</span> TPB <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span>(stride <span class="op">&gt;</span> <span class="dv">0</span>):</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> local_idx <span class="op">&lt;</span> stride:</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>            shared[local_idx] <span class="op">+=</span> shared[local_idx <span class="op">+</span> stride]</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>        barrier()</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>        stride <span class="op">=</span> stride <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># only allow thread 0 to write result</span></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_idx <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>        output[<span class="dv">0</span>] <span class="op">=</span> shared[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</details>
<p><strong>Note</strong>: Instead of doing the parallel reduction, we could also implement the solution using a loop:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode diff code-with-copy"><code class="sourceCode diff"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="st">-    stride = TPB // 2</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="st">-    while(stride &gt; 0):</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="st">-        if local_idx &lt; stride:</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="st">-            shared[local_idx] += shared[local_idx + stride]</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="st">-        </span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="st">-        barrier()</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="st">-        stride = stride // 2</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="st">-    </span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="st">-    # only allow thread 0 to write result</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="st">-    if local_idx == 0:</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="st">-        output[0] = shared[0]</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="va">+    if global_idx &lt; size:</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="va">+        for idx in range(size):</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="va">+            output[0] = output[0] + shared[idx]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>While this approach also gives the correct answer for this puzzle, it has multiple problems:</p>
<ul>
<li><strong>Race conditions</strong>: Multiple threads would simultaneously try to update output[0] without synchronization, causing lost updates.</li>
<li><strong>Thread divergence</strong>: When threads in a warp take different execution paths (some running the loop, others not), the GPU must serialize execution, destroying parallelism.</li>
<li><strong>Redundant computation</strong>: Every qualifying thread would compute the exact same sum over the entire array, wasting compute resources.</li>
<li><strong>Memory bottleneck</strong>: Repeated atomic operations to the same memory location (output[0]) create severe contention.</li>
</ul>
</section>
<section id="layouttensor-2" class="level4">
<h4 class="anchored" data-anchor-id="layouttensor-2">LayoutTensor</h4>
<p>alias TPB = 8 alias SIZE = 8 alias BLOCKS_PER_GRID = (1, 1) alias THREADS_PER_BLOCK = (SIZE, 1) alias dtype = DType.float32 alias layout = Layout.row_major(SIZE) alias out_layout = Layout.row_major(1)</p>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p10.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb28" data-filename="p10.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> dot_product[</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    in_layout: Layout, out_layout: Layout</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    output: LayoutTensor[mut<span class="op">=</span><span class="va">True</span>, dtype, out_layout],</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">True</span>, dtype, in_layout],</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    b: LayoutTensor[mut<span class="op">=</span><span class="va">True</span>, dtype, in_layout],</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use LayoutTensorBuilder instead of stack_allocation</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    shared <span class="op">=</span> tb[dtype]().row_major[TPB]().shared().alloc()</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    global_idx <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    local_idx <span class="op">=</span> thread_idx.x</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_idx <span class="op">&lt;</span> size:</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>        shared[local_idx] <span class="op">=</span> a[global_idx] <span class="op">*</span> b[global_idx]</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>    stride <span class="op">=</span> TPB <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span>(stride <span class="op">&gt;</span> <span class="dv">0</span>):</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> local_idx <span class="op">&lt;</span> stride:</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>            shared[local_idx] <span class="op">+=</span> shared[local_idx <span class="op">+</span> stride]</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>        barrier()</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>        stride <span class="op">=</span> stride <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># only allow thread 0 to write result</span></span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_idx <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>        output[<span class="dv">0</span>] <span class="op">=</span> shared[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</details>
</section>
</section>
<section id="puzzle-11" class="level3">
<h3 class="anchored" data-anchor-id="puzzle-11"><a href="https://builds.modular.com/puzzles/puzzle_11/puzzle_11.html">Puzzle 11: 1D Convolution</a></h3>
<p>Picture sliding a magnifying glass along a long strip of film. That’s exactly what a 1-D convolution does to any 1-D signal—audio samples, DNA bases, even bytes of log data.</p>
<ul>
<li>The kernel (a small weight vector) glides over the sequence one step at a time (or more if you set stride &gt; 1).</li>
<li>At each stop it multiplies the local window by its weights, sums the result, and drops a single number into the output map.</li>
<li>Stack layers and you grow the “what can I see at once?” window (the receptive field) without blowing up parameters.</li>
</ul>
<p><strong>Why bother?</strong></p>
<ul>
<li><strong>Speed</strong>: A conv layer is just a batched matrix-mul—GPU catnip.</li>
<li><strong>Locality first, context later</strong>: Early layers grab short-range patterns (phonemes, k-mers). Deeper layers stitch them into bigger motifs (words, promoters).</li>
<li><strong>Channels generalize it</strong>: You convolve along length, but for each input channel you keep separate weights, sum across channels, and spit out new feature maps. Same trick as 2-D CNNs, just flattened.</li>
</ul>
<p>For a better picture, see Ayush’s blog<span class="citation" data-cites="thakur_convolutions"><a href="#ref-thakur_convolutions" role="doc-biblioref">[9]</a></span> on convolutions.</p>
<p>The convolution operation can be defined as: <span id="eq-convolution"><span class="math display">\[
    (input\_signal\_a * kernel\_b)[i] = \sum_{j=0}^{\text{kernel\_size}-1} input\_signal\_a[i + j] * kernel\_b[j]
\tag{1}\]</span></span></p>
<section id="simple-single-block-with-shared-memory" class="level4">
<h4 class="anchored" data-anchor-id="simple-single-block-with-shared-memory">Simple: Single Block with Shared Memory</h4>
<p>For this version, we assume that we only have a single block, and both the input data and the kernel fit within a block.</p>
<p><img src="mojo_gpu_puzzles/p11_simple.png" class="img-fluid"></p>
<p>The implementation is:</p>
<ul>
<li>Intialise shared memory for both the input and the kernel</li>
<li>Load data in the shared memory, and use <code>barrier()</code> to sync all threads before performing computations.</li>
<li>In a loop, multiple the value of input and kernel, and add to a local variable.</li>
<li>Assign the local variable to the right output index.</li>
</ul>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p11.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb29" data-filename="p11.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> TPB <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> SIZE <span class="op">=</span> <span class="dv">6</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> CONV <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK <span class="op">=</span> (TPB, <span class="dv">1</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> dtype <span class="op">=</span> DType.float32</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> in_layout <span class="op">=</span> Layout.row_major(SIZE)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> out_layout <span class="op">=</span> Layout.row_major(SIZE)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> conv_layout <span class="op">=</span> Layout.row_major(CONV)</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> conv_1d_simple[</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>    in_layout: Layout, out_layout: Layout, conv_layout: Layout</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>    output: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, out_layout],</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, in_layout],</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>    b: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, conv_layout],</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>    global_i <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>    local_i <span class="op">=</span> thread_idx.x</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This is oversized! I've explained it later :)</span></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>    shared_a <span class="op">=</span> tb[dtype]().row_major[TPB]().shared().alloc()</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>    shared_b <span class="op">=</span> tb[dtype]().row_major[TPB]().shared().alloc()</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This can also be optimised, as shown later.</span></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> SIZE:</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>        shared_a[local_i] <span class="op">=</span> a[global_i]</span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>        shared_b[local_i] <span class="op">=</span> b[global_i]</span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> SIZE:</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ensure the local var has the same type as the output</span></span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># to avoid type casting errors.</span></span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> local_sum: output.element_type <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Perform loop unrolling.</span></span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a>        <span class="at">@parameter</span></span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(CONV):</span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> local_i <span class="op">+</span> j <span class="op">&lt;</span> SIZE:</span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a>                local_sum <span class="op">+=</span> shared_a[local_i <span class="op">+</span> j] <span class="op">*</span> shared_b[j]</span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a>            barrier()</span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a>        output[global_i] <span class="op">=</span> local_sum</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</details>
<p>I deliberately allocate <code>shared_a</code> and <code>shared_b</code> with the block width (<code>TPB</code>) instead of the input length (<code>SIZE</code>) and filter length (<code>CONV</code>). The extra space isn’t needed for correctness—the kernel only touches the first <code>SIZE</code>/<code>CONV</code> elements—but it nicely demonstrates <code>LayoutTensor</code>’s masking: out-of-range indices are silently ignored. This trick keeps the buffer shape uniform across puzzles without cluttering the code with edge-case branches. The flip side is a bit of wasted shared memory, which can pinch if your kernel is already pushing the SRAM limit.</p>
<p>The <em>optimal</em> allocation of shared memory would be:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode diff code-with-copy"><code class="sourceCode diff"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="st">-    shared_a = tb[dtype]().row_major[TPB]().shared().alloc()</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="st">-    shared_b = tb[dtype]().row_major[TPB]().shared().alloc()</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="va">+    # Allocate exactly SIZE elements → smaller shared-mem footprint</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="va">+    shared_a = tb[dtype]().row_major[SIZE]().shared().alloc()</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="va">+    # Allocate exactly CONV elements → smaller shared-mem footprint</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="va">+    shared_b = tb[dtype]().row_major[CONV]().shared().alloc()</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="st">-    if global_i &lt; SIZE:</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="st">-        shared_a[local_i] = a[global_i]</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="st">-        shared_b[local_i] = b[global_i]</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="va">+    if global_i &lt; SIZE:</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="va">+        shared_a[local_i] = a[global_i]</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="va">+    if global_i &lt; CONV:</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="va">+        shared_b[local_i] = b[global_i]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="parameter-loop-unrolling" class="level4">
<h4 class="anchored" data-anchor-id="parameter-loop-unrolling">@parameter : Loop Unrolling</h4>
<p><a href="https://docs.modular.com/mojo/manual/decorators/parameter/"><code>@parameter</code></a> is Mojo’s implementation of <strong>loop unrolling</strong>. This has the same functionality as <code>pragma unroll(N)</code> in CUDA.</p>
<p>When unroll is in effect, the optimizer determines and applies the best unrolling factor for each loop; in some cases, the loop control might be modified to avoid unnecessary branching. The compiler remains the final arbiter of whether the loop is unrolled<span class="citation" data-cites="nvidiapragmaunroll"><a href="#ref-nvidiapragmaunroll" role="doc-biblioref">[10]</a></span>.</p>
<p><code>@parameter</code> isn’t limited to loops/branches—you can slap it on an inner function and Mojo will build a <strong>parametric closure</strong>, defined as<span class="citation" data-cites="mojoparameter"><a href="#ref-mojoparameter" role="doc-biblioref">[11]</a></span>:</p>
<blockquote class="blockquote">
<p>A parametric closure is a nested function decorated with <code>@parameter</code>. Any values it captures from the surrounding scope are treated as compile-time constants. The compiler materialises one specialised version of the closure for every distinct set of captured values</p>
</blockquote>
<p>Example:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>parametric_closure.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb31" data-filename="parametric_closure.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> make_shift(off: Int):</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">@parameter</span>            <span class="co"># ← specialised per ‘off’</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">fn</span> shift(x: Int) <span class="op">-&gt;</span> Int:</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x <span class="op">+</span> off</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> shift</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> s1 <span class="op">=</span> make_shift(<span class="dv">1</span>)    <span class="co"># emits shift-$off=1</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> s4 <span class="op">=</span> make_shift(<span class="dv">4</span>)    <span class="co"># emits shift-$off=4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>No runtime captures, no heap boxing—the constant <code>off</code> is literally spliced into the generated IR, so calls to <code>s1</code>/<code>s4</code> inline like normal code and can be further unrolled or constant-folded.</p>
<p>Why is this safe? Mojo’s <em>origin</em> system<span class="citation" data-cites="mojo_lifetimes"><a href="#ref-mojo_lifetimes" role="doc-biblioref">[12]</a></span> assigns each compile-time constant its own immutable origin. The closure therefore can’t outlive or mutate the thing it captured; once the surrounding scope ends those origins die too, guaranteeing that the specialised code never touches expired storage.</p>
<p><strong>Bottom line</strong>: you get closure ergonomics plus “zero-cost abstraction”<span class="citation" data-cites="zero_cost_abstractions"><a href="#ref-zero_cost_abstractions" role="doc-biblioref">[13]</a></span> performance—ideal for GPU kernels where every cycle and register matters.</p>
</section>
<section id="advanced-block-boundary" class="level4">
<h4 class="anchored" data-anchor-id="advanced-block-boundary">Advanced: Block Boundary</h4>
<p>We now aim to perform convolution over an input that is larger than a single block. Due to the nature of convolution operation, this introduces interesting boundary conditions. Specifically, the output of block N now depends on block N - 1, when N &gt; 1.</p>
<p>The blue cells are the data <em>owned</em> by the current thread-block; the orange cells are the first few elements of the <em>next</em> block that the convolution window will inevitably peek at.</p>
<p><img src="mojo_gpu_puzzles/p11_block_boundary.png" class="img-fluid"></p>
<p><strong>Problem statement</strong></p>
<p>Run a 1-D convolution with a <code>CONV₂</code>-tap kernel over an input that is longer than one block (<code>TPB</code> threads). We want every thread to:</p>
<p>• pull data from <strong>shared memory only</strong> (once it’s loaded, stay in-block)<br>
• avoid divergent branches and random global reads<br>
• keep the load pattern fully coalesced</p>
<p>Naïve global loads meet none of those goals—once a window crosses the block edge the tail threads must issue conditional, <em>straggling</em> reads (i.e.&nbsp;each thread grabs a lone, scattered element from global memory instead of part of one tidy, coalesced burst).</p>
<p><strong>The halo idea</strong></p>
<p>Give each block an in-block “fence extension”:</p>
<pre><code>shared_a = …[TPB + (CONV₂ − 1)]   # main slice + halo</code></pre>
<p>The extra <code>(CONV₂ − 1)</code> slots—the <em>halo</em>—mirror the first <code>(CONV₂ − 1)</code> elements of the next block (or zeros if we’re already at EOF). That single change guarantees that every sliding window lives in one contiguous span of shared memory.</p>
<p>The elements that are involved in multiple tiles and loaded by multiple blocks are commonly referred to as <em>halo cells</em> or <em>skirt cells</em> since they “hang” from the side of the part that is used solely by a single block<span class="citation" data-cites="iitd_parallel_convolution"><a href="#ref-iitd_parallel_convolution" role="doc-biblioref">[14]</a></span>.</p>
<p>Loading recipe (matches the numbered arrows in the figure):</p>
<ol type="1">
<li><strong>Bulk copy</strong> – all <code>TPB</code> threads dump their element:<br>
<code>shared_a[t] = a[blockStart + t]</code></li>
<li><strong>Halo fill</strong> – threads <code>t &lt; (CONV₂ − 1)</code> copy the tail:<br>
<code>shared_a[TPB + t] = (a[blockStart + TPB + t] if in-range else 0)</code></li>
<li><strong>Kernel stash</strong> – threads <code>t &lt; CONV₂</code> cache the weights:<br>
<code>shared_b[t] = b[t]</code></li>
<li><code>barrier()</code> – everyone syncs</li>
</ol>
<p>After step 4 every thread sees:</p>
<pre><code>      main slice              halo
[ … local_i … TPB − 1 | TPB … TPB+CONV₂−2 ]</code></pre>
<p>Code to perform the actual computation is the same as in <a href="#puzzle-10">Puzzle 10</a>.</p>
<p>One barrier, no branches and 100 % shared-memory hits ensure our kernel is fast and efficient!</p>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p11_block_boundary.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb34" data-filename="p11_block_boundary.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> SIZE_2 <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> CONV_2 <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID_2 <span class="op">=</span> (<span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK_2 <span class="op">=</span> (TPB, <span class="dv">1</span>)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> in_2_layout <span class="op">=</span> Layout.row_major(SIZE_2)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> out_2_layout <span class="op">=</span> Layout.row_major(SIZE_2)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> conv_2_layout <span class="op">=</span> Layout.row_major(CONV_2)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> conv_1d_block_boundary[</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>    in_layout: Layout, out_layout: Layout, conv_layout: Layout, dtype: DType</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>    output: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, out_layout],</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, in_layout],</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>    b: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, conv_layout],</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>    global_i <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>    local_i  <span class="op">=</span> thread_idx.x</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># input slice + halo</span></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a>    shared_a <span class="op">=</span> tb[dtype]().row_major[TPB <span class="op">+</span> CONV_2 <span class="op">-</span> <span class="dv">1</span>]().shared().alloc()</span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># load kernel</span></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>    shared_b <span class="op">=</span> tb[dtype]().row_major[CONV_2]().shared().alloc()</span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> SIZE_2:</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># coalesced load of main slice</span></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a>        shared_a[local_i] <span class="op">=</span> a[global_i]                  </span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># only first CONV_2 threads participate</span></span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_i <span class="op">&lt;</span> CONV_2:</span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># load kernel into shared memory</span></span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a>        shared_b[local_i] <span class="op">=</span> b[local_i]                   </span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># threads responsible for halo load</span></span>
<span id="cb34-35"><a href="#cb34-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_i <span class="op">&lt;</span> CONV_2 <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb34-36"><a href="#cb34-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># element that lives in next block</span></span>
<span id="cb34-37"><a href="#cb34-37" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> next_idx <span class="op">=</span> global_i <span class="op">+</span> TPB                    </span>
<span id="cb34-38"><a href="#cb34-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># pad with zeros</span></span>
<span id="cb34-39"><a href="#cb34-39" aria-hidden="true" tabindex="-1"></a>        shared_a[local_i <span class="op">+</span> TPB] <span class="op">=</span> a[next_idx] <span class="cf">if</span> next_idx <span class="op">&lt;</span> SIZE_2 <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb34-40"><a href="#cb34-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-41"><a href="#cb34-41" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb34-42"><a href="#cb34-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-43"><a href="#cb34-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># skip threads mapping past the end</span></span>
<span id="cb34-44"><a href="#cb34-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> SIZE_2:</span>
<span id="cb34-45"><a href="#cb34-45" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> local_sum: output.element_type <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb34-46"><a href="#cb34-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-47"><a href="#cb34-47" aria-hidden="true" tabindex="-1"></a>        <span class="at">@parameter</span>                                       </span>
<span id="cb34-48"><a href="#cb34-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(CONV_2):                          </span>
<span id="cb34-49"><a href="#cb34-49" aria-hidden="true" tabindex="-1"></a>            <span class="co"># dot product of window &amp; kernel</span></span>
<span id="cb34-50"><a href="#cb34-50" aria-hidden="true" tabindex="-1"></a>            local_sum <span class="op">+=</span> shared_a[local_i <span class="op">+</span> j] <span class="op">*</span> shared_b[j]</span>
<span id="cb34-51"><a href="#cb34-51" aria-hidden="true" tabindex="-1"></a>        output[global_i] <span class="op">=</span> local_sum</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb35"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p11 <span class="at">--block-boundary</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([14.0, 20.0, 26.0, 32.0, 38.0, 44.0, 50.0, 56.0, 62.0, 68.0, 74.0, 80.0, 41.0, 14.0, 0.0])</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([14.0, 20.0, 26.0, 32.0, 38.0, 44.0, 50.0, 56.0, 62.0, 68.0, 74.0, 80.0, 41.0, 14.0, 0.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
</section>
<section id="bonus-2d-convolution" class="level3">
<h3 class="anchored" data-anchor-id="bonus-2d-convolution">Bonus: 2D Convolution</h3>
<p>We can extend our implementation for 1D convolution to a 2D convolution.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="mojo_gpu_puzzles/2d_convolution.gif" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
<figcaption>Source: <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p1.2-web/Project%201.2%20-%20Computer%20Architecture%20I%20-%20ShanghaiTech%20University.html">Toast Lab</a></figcaption>
</figure>
</div>
<p>Everything is exactly the same idea as 1-D, only now we have two spatial dims:</p>
<ul>
<li>We launch a 2D grid of <code>(ceildiv(WIDTH,TPB_X), ceildiv(HEIGHT,TPB_Y))</code> blocks of TPB_X×TPB_Y threads.</li>
<li>Each block allocates a shared tile of size <code>(TPB_Y+K−1)×(TPB_X+K−1)</code> to hold its “main” patch plus a one‐pixel halo on the bottom/right.</li>
<li>We also stash the full <code>K×K</code> kernel into shared_k.</li>
<li>After a single barrier(), each thread does two nested <code>@parameter</code> loops over <code>ky,kx∈[0,K)</code> to compute a dot‐product.</li>
</ul>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p11_conv_2d.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb36" data-filename="p11_conv_2d.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> math <span class="im">import</span> ceildiv</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> TPB_X <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> TPB_Y <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> WIDTH <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> HEIGHT <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> K     <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID_2D  <span class="op">=</span> (ceildiv(WIDTH, TPB_X),  ceildiv(HEIGHT, TPB_Y))</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK_2D <span class="op">=</span> (TPB_X, TPB_Y)</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> conv_2d_halo[</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>    in_layout : Layout, out_layout : Layout,</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>    k_layout  : Layout, dtype : DType</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>    output : LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, out_layout],</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>    inp    : LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, in_layout],</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>    kernel : LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, k_layout],</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> gx <span class="op">=</span> block_idx.x <span class="op">*</span> block_dim.x <span class="op">+</span> thread_idx.x</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> gy <span class="op">=</span> block_idx.y <span class="op">*</span> block_dim.y <span class="op">+</span> thread_idx.y</span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> lx <span class="op">=</span> thread_idx.x</span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> ly <span class="op">=</span> thread_idx.y</span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>    const TILE_W <span class="op">=</span> TPB_X <span class="op">+</span> K <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>    const TILE_H <span class="op">=</span> TPB_Y <span class="op">+</span> K <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># allocate (main + halo) + kernel</span></span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>    shared_img <span class="op">=</span> tb[dtype]().row_major[TILE_H, TILE_W]().shared().alloc()</span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>    shared_k   <span class="op">=</span> tb[dtype]().row_major[K,K]().shared().alloc()</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1) bulk copy</span></span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> gx <span class="op">&lt;</span> WIDTH <span class="op">&amp;&amp;</span> gy <span class="op">&lt;</span> HEIGHT:</span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a>        shared_img[ly, lx] <span class="op">=</span> inp[gy, gx]</span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a>        shared_img[ly, lx] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2) halo copy (strided so we cover the whole TILE_H/TILE_W)</span></span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">var</span> hy <span class="op">=</span> ly</span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> hy <span class="op">&lt;</span> TILE_H:</span>
<span id="cb36-41"><a href="#cb36-41" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> hx <span class="op">=</span> lx</span>
<span id="cb36-42"><a href="#cb36-42" aria-hidden="true" tabindex="-1"></a>        <span class="kw">let</span> gy2 <span class="op">=</span> block_idx.y <span class="op">*</span> block_dim.y <span class="op">+</span> hy</span>
<span id="cb36-43"><a href="#cb36-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> hx <span class="op">&lt;</span> TILE_W:</span>
<span id="cb36-44"><a href="#cb36-44" aria-hidden="true" tabindex="-1"></a>            <span class="kw">let</span> gx2 <span class="op">=</span> block_idx.x <span class="op">*</span> block_dim.x <span class="op">+</span> hx</span>
<span id="cb36-45"><a href="#cb36-45" aria-hidden="true" tabindex="-1"></a>            shared_img[hy, hx] <span class="op">=</span> (</span>
<span id="cb36-46"><a href="#cb36-46" aria-hidden="true" tabindex="-1"></a>                inp[gy2, gx2] <span class="cf">if</span> (gy2 <span class="op">&lt;</span> HEIGHT <span class="op">&amp;&amp;</span> gx2 <span class="op">&lt;</span> WIDTH) <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb36-47"><a href="#cb36-47" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb36-48"><a href="#cb36-48" aria-hidden="true" tabindex="-1"></a>            hx <span class="op">+=</span> TPB_X</span>
<span id="cb36-49"><a href="#cb36-49" aria-hidden="true" tabindex="-1"></a>        hy <span class="op">+=</span> TPB_Y</span>
<span id="cb36-50"><a href="#cb36-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-51"><a href="#cb36-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3) stash the kernel</span></span>
<span id="cb36-52"><a href="#cb36-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ly <span class="op">&lt;</span> K <span class="op">&amp;&amp;</span> lx <span class="op">&lt;</span> K:</span>
<span id="cb36-53"><a href="#cb36-53" aria-hidden="true" tabindex="-1"></a>        shared_k[ly, lx] <span class="op">=</span> kernel[ly, lx]</span>
<span id="cb36-54"><a href="#cb36-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-55"><a href="#cb36-55" aria-hidden="true" tabindex="-1"></a>    barrier()  <span class="co"># sync both shared buffers</span></span>
<span id="cb36-56"><a href="#cb36-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-57"><a href="#cb36-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4) compute 3×3 dot‐product</span></span>
<span id="cb36-58"><a href="#cb36-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> gx <span class="op">&lt;</span> WIDTH <span class="op">&amp;&amp;</span> gy <span class="op">&lt;</span> HEIGHT:</span>
<span id="cb36-59"><a href="#cb36-59" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> <span class="bu">sum</span>: Float32 <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb36-60"><a href="#cb36-60" aria-hidden="true" tabindex="-1"></a>        <span class="at">@parameter</span> </span>
<span id="cb36-61"><a href="#cb36-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> ky <span class="kw">in</span> <span class="bu">range</span>(K):</span>
<span id="cb36-62"><a href="#cb36-62" aria-hidden="true" tabindex="-1"></a>            <span class="at">@parameter</span> </span>
<span id="cb36-63"><a href="#cb36-63" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> kx <span class="kw">in</span> <span class="bu">range</span>(K):</span>
<span id="cb36-64"><a href="#cb36-64" aria-hidden="true" tabindex="-1"></a>                <span class="bu">sum</span> <span class="op">+=</span> shared_img[ly <span class="op">+</span> ky, lx <span class="op">+</span> kx] <span class="op">*</span> shared_k[ky, kx]</span>
<span id="cb36-65"><a href="#cb36-65" aria-hidden="true" tabindex="-1"></a>        output[gy, gx] <span class="op">=</span> <span class="bu">sum</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</details>
<p>After making a <a href="https://github.com/goodhamgupta/mojo-gpu-puzzles/commit/b7961ce0e5ea8753a866cbf671881ac1bdf4acd9">few changes</a> to the test harness, we get the following result:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p11 <span class="at">--conv-2d</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([9.0, 9.0, 9.0, 9.0, 9.0,...,6.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0])</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([9.0, 9.0, 9.0, 9.0, 9.0,..., 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="puzzle-12" class="level3">
<h3 class="anchored" data-anchor-id="puzzle-12"><a href="https://builds.modular.com/puzzles/puzzle_12/puzzle_12.html">Puzzle 12: Prefix Sum</a></h3>
<p>The <strong>prefix sum</strong> (or <em>scan</em>) problem takes an input array <code>[a₀, a₁, …, aₙ₋₁]</code> and produces the running totals</p>
<pre class="text"><code>[a₀, (a₀ ⊕ a₁), …, (a₀ ⊕ a₁ ⊕ … ⊕ aₙ₋₁)]</code></pre>
<p>It’s a foundational primitive in parallel computing—used for stream compaction, sorting, histograms, and more. At first glance, prefix sum looks inherently serial (each output depends on all previous inputs), but clever algorithms can parallelize it efficiently.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="mojo_gpu_puzzles/p12_prefix_scan.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
<figcaption>Prefix‐Sum Illustration</figcaption>
</figure>
</div>

<section id="hillissteele-algorithm" class="level4">
<h4 class="anchored" data-anchor-id="hillissteele-algorithm">Hillis–Steele Algorithm</h4>
<p>A straightforward parallel scan is the <em>Hillis–Steele</em> approach: at each distance <code>d = 1, 2, 4, …</code> every element adds in the value from <code>d</code> positions back. This is the same as the method shown in <a href="#puzzle-10">Puzzle 10</a></p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># inclusive scan, power-of-two length</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> hillis_steele_scan(a, ⊕):</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(a)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    temp <span class="op">=</span> a.copy()</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> d <span class="op">&lt;</span> n:</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>            temp[i] <span class="op">=</span> a[i] <span class="cf">if</span> i <span class="op">&lt;</span> d <span class="cf">else</span> a[i <span class="op">-</span> d] ⊕ a[i]</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>        a, temp <span class="op">=</span> temp, a</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>        d <span class="op">*=</span> <span class="dv">2</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In Mojo, this looks as follows:</p>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p12_simple.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb40" data-filename="p12_simple.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> prefix_sum_simple[</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    layout: Layout</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    output: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    global_i <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>    local_i <span class="op">=</span> thread_idx.x</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(Int(log2(Scalar[dtype](TPB)))):</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> local_i <span class="op">&gt;=</span> offset <span class="kw">and</span> local_i <span class="op">&lt;</span> SIZE:</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>            shared[local_i] <span class="op">+=</span> shared[local_i <span class="op">-</span> offset]</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>        barrier()</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>        offset <span class="op">*=</span> <span class="dv">2</span></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> SIZE:</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>        output[global_i] <span class="op">=</span> shared[local_i]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb41"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p12 <span class="at">--simple</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Each of the log₂(n) rounds does up to n parallel additions (one per active element), so total work is <span class="math inline">\(\sum_k n = nlog(n)\)</span>. Because rounds are serialized by barriers, the longest dependency chain is one add per round i.e <span class="math inline">\(O(log n)\)</span>.</p>
</details></section>
<section id="blellochs-twopass-algorithm" class="level4">
<h4 class="anchored" data-anchor-id="blellochs-twopass-algorithm">Blelloch’s Two‐Pass Algorithm</h4>
<p>Blelloch’s variant achieves Θ(n) work by splitting the scan into an <strong>up-sweep</strong> and a <strong>down-sweep</strong> <span class="citation" data-cites="blelloch_prefix_sum"><a href="#ref-blelloch_prefix_sum" role="doc-biblioref">[15]</a></span>:</p>
<ol type="1">
<li><p><strong>Up-sweep (reduce)</strong><br>
We build a reduction tree by summing pairs of elements in log₂(n) rounds. At each round, threads work on chunks of size <code>2*step</code>:</p>
<p>For <code>step = 1; step &lt; n; step *= 2</code>:<br>
For <code>i</code> in <code>0, 2*step, 4*step, …, n-1</code>:<br>
<code>a[i + 2*step - 1] = a[i + step - 1] ⊕ a[i + 2*step - 1]</code></p>
<ul>
<li><strong>step=1</strong>: sum adjacent pairs → partial sums at indices 1, 3, 5, …<br>
</li>
<li><strong>step=2</strong>: combine 4-element blocks, accumulating into indices 3, 7, …<br>
</li>
<li>Continue until <strong>step = n/2</strong>; now <code>a[n-1]</code> holds the overall reduction.</li>
</ul>
<p><img src="mojo_gpu_puzzles/p12_up.gif" class="img-fluid"> <em>Up-Sweep: combining elements in a binary-tree fashion—build partial sums until the final element holds the total.</em></p></li>
<li><p><strong>Down-sweep (propagate)</strong><br>
After the up-sweep leaves <code>a[n-1]</code> containing the overall sum, we walk the tree top-down to scatter prefix sums into every slot:</p>
<ul>
<li>Initialize <code>step = n/2</code>.<br>
</li>
<li>Repeat while <code>step &gt;= 1</code>:
<ul>
<li><p>For each <code>i</code> in <code>0, 2*step, 4*step, …, n-1</code>:</p>
<pre><code>t                   = a[i + step - 1]        # save left subtree total
a[i + step - 1]     = a[i + 2*step - 1]      # overwrite left with right subtotal
a[i + 2*step - 1]   = t ⊕ a[i + 2*step - 1]  # combine for right‐child prefix</code></pre></li>
<li><p><code>barrier()</code> to sync threads<br>
</p></li>
<li><p><code>step //= 2</code></p></li>
</ul></li>
</ul>
<p>In each round, partial sums flow down one level of the binary tree. After log₂(n) rounds, every index holds the sum of all elements before it.</p>
<p><img src="mojo_gpu_puzzles/p12_down.gif" class="img-fluid quarto-figure quarto-figure-center"><br>
<em>Down Sweep: siblings swap and accumulate, driving the scan from root back to leaves.</em></p></li>
</ol>
<p>Time Complexity: Θ(log₂ n) parallel steps, Work: Θ(n) total operations.</p>
<p>We coalesce-load the input into shared memory, then execute the Blelloch scan in two synchronized phases:</p>
<ol type="1">
<li>Up-sweep (reduce) – in log₂ n rounds each thread builds partial sums into a binary tree.</li>
<li>barrier() – sync all threads and reset the root to zero (for an exclusive scan).</li>
<li>Down-sweep (propagate) – in log₂ n rounds threads walk the tree top-down, scattering prefix sums.</li>
<li>Coalesced write – flush the computed prefixes from shared memory back to global memory.</li>
</ol>
<p>This two-pass design leverages shared memory and barriers to minimize global-memory traffic, enforce correct dependencies, and achieve Θ(n) work with Θ(log n) depth on the GPU.</p>
<details open="">
<summary>
<strong>Solution (Blelloch up-sweep + down-sweep)</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p12_blelloch.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb43" data-filename="p12_blelloch.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> prefix_sum_blelloch[</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    layout: Layout</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>    out:   LayoutTensor[mut<span class="op">=</span><span class="va">True</span>, dtype, layout],</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>    a:     LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>    size:  Int,</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> global_idx <span class="op">=</span> block_idx.x<span class="op">*</span>block_dim.x <span class="op">+</span> thread_idx.x</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> local_idx <span class="op">=</span> thread_idx.x</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>    shared <span class="op">=</span> tb[dtype]().row_major[SIZE]().shared().alloc()</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>    <span class="op">//</span> load</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_idx <span class="op">&lt;</span> size:</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>        shared[local_idx] <span class="op">=</span> a[global_idx]</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>    <span class="op">//</span> Up<span class="op">-</span>sweep (<span class="bu">reduce</span>)</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">var</span> stride <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> stride <span class="op">&lt;</span> size:</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>        <span class="kw">let</span> step <span class="op">=</span> stride <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (local_idx <span class="op">%</span> step <span class="op">==</span> step <span class="op">-</span> <span class="dv">1</span>) <span class="op">&amp;&amp;</span> (local_idx <span class="op">&lt;</span> size):</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>            shared[local_idx] <span class="op">+=</span> shared[local_idx <span class="op">-</span> stride]</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>        barrier()</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>        stride <span class="op">=</span> step</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>    <span class="op">//</span> Down<span class="op">-</span>sweep (propagate)</span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_idx <span class="op">==</span> size <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>        shared[local_idx] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">var</span> half <span class="op">=</span> stride <span class="op">&gt;&gt;</span> <span class="dv">1</span></span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> half <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>        <span class="kw">let</span> step <span class="op">=</span> half <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (local_idx <span class="op">%</span> step <span class="op">==</span> step <span class="op">-</span> <span class="dv">1</span>) <span class="op">&amp;&amp;</span> (local_idx <span class="op">&lt;</span> size):</span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>            <span class="kw">let</span> t <span class="op">=</span> shared[local_idx <span class="op">-</span> half]</span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a>            shared[local_idx <span class="op">-</span> half] <span class="op">=</span> shared[local_idx]</span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a>            shared[local_idx] <span class="op">+=</span> t</span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a>        barrier()</span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a>        half <span class="op">=</span> half <span class="op">&gt;&gt;</span> <span class="dv">1</span></span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a>    <span class="op">//</span> write</span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_idx <span class="op">&lt;</span> size:</span>
<span id="cb43-43"><a href="#cb43-43" aria-hidden="true" tabindex="-1"></a>        out[global_idx] <span class="op">=</span> shared[local_idx]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb44"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p12 <span class="at">--blelloch</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
</section>
</section>
<section id="citation" class="level2">
<h2 class="anchored" data-anchor-id="citation">Citation</h2>
<p>Original puzzles by the <a href="https://www.modular.com/">Modular</a> team; this blog provides personal explanations and solutions.</p>
<p>Please cite this work as:</p>
<pre><code>Gupta, Shubham. “Mojo GPU Puzzles — Solutions &amp; Explanations”. shubhamg.in (June 2025). https://shubhamg.in/posts/mojo-gpu-puzzles</code></pre>
<p>Or use the BibTeX citation:</p>
<pre><code>@article{sguptamojopuzzles,
  title   = {Mojo GPU Puzzles — Solutions \&amp; Explanations},
  author  = {Gupta, Shubham},
  journal = {shubhamg.in},
  year    = {2025},
  url     = {https://shubhamg.in/posts/mojo-gpu-puzzles},
}</code></pre>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list">
<div id="ref-Google" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">Google, <span>“<span>I/O 2025 Keynote</span>.”</span> 2025. Available: <a href="https://blog.google/technology/ai/io-2025-keynote/">https://blog.google/technology/ai/io-2025-keynote/</a></div>
</div>
<div id="ref-modularpuzzles" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">Modular, <span>“<span class="nocase">GPU Puzzles in Mojo</span>.”</span> 2025. Available: <a href="https://builds.modular.com/puzzles/introduction.html">https://builds.modular.com/puzzles/introduction.html</a></div>
</div>
<div id="ref-GPUPuzzles" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">S. Rush, <span>“<span>GPU Puzzles</span>.”</span> 2023. Available: <a href="https://github.com/srush/GPU-Puzzles">https://github.com/srush/GPU-Puzzles</a></div>
</div>
<div id="ref-llvmlayouttensor" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">Taei, <span>“<span class="nocase">Simplifying GPU Programming with Parametric Tile-Level Tensors In Mojo</span>.”</span> 2024. Available: <a href="https://llvm.org/devmtg/2024-10/slides/techtalk/Taei-Simplifying-GPU-Programming-with-Parametric-Tile-Level-Tensors-In-Mojo.pdf">https://llvm.org/devmtg/2024-10/slides/techtalk/Taei-Simplifying-GPU-Programming-with-Parametric-Tile-Level-Tensors-In-Mojo.pdf</a></div>
</div>
<div id="ref-mojotalk" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">Modular, <span>“<span class="nocase">Mojo: The Future of Systems Programming</span>.”</span> 2025. Available: <a href="https://youtu.be/5gPG7SXoBag?si=H_kbkzbqfZHvNQSy&amp;t=1731">https://youtu.be/5gPG7SXoBag?si=H_kbkzbqfZHvNQSy&amp;t=1731</a></div>
</div>
<div id="ref-jeffniutriton" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">J. Niu, <span>“<span class="nocase">Triton Clone in Mojo</span>.”</span> 2025. Available: <a href="https://youtu.be/zUwyO2PZisw?si=QLdX_cAXDBcJH4mu">https://youtu.be/zUwyO2PZisw?si=QLdX_cAXDBcJH4mu</a></div>
</div>
<div id="ref-wikipediadotproduct" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">Wikipedia, <span>“Dot product.”</span> <a href="https://en.wikipedia.org/wiki/Dot_product" class="uri">https://en.wikipedia.org/wiki/Dot_product</a>, 2024.</div>
</div>
<div id="ref-zeno_dichotomy_paradox" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">Wikipedia, <span>“Zeno’s paradoxes — dichotomy paradox.”</span> <a href="https://en.wikipedia.org/wiki/Zeno%27s_paradoxes#Dichotomy_paradox" class="uri">https://en.wikipedia.org/wiki/Zeno%27s_paradoxes#Dichotomy_paradox</a>, 2024.</div>
</div>
<div id="ref-thakur_convolutions" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">A. Thakur, <span>“Intuitive understanding of 1D, 2D, and 3D convolutions in convolutional neural networks.”</span> 2020. Available: <a href="https://wandb.ai/ayush-thakur/dl-question-bank/reports/Intuitive-understanding-of-1D-2D-and-3D-convolutions-in-convolutional-neural-networks---VmlldzoxOTk2MDA">https://wandb.ai/ayush-thakur/dl-question-bank/reports/Intuitive-understanding-of-1D-2D-and-3D-convolutions-in-convolutional-neural-networks---VmlldzoxOTk2MDA</a></div>
</div>
<div id="ref-nvidiapragmaunroll" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">NVIDIA, <span>“<span class="nocase">#pragma unroll Compiler Directive (CUDA C Programming Guide)</span>.”</span> 2025. Available: <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html?highlight=unroll#pragma-unroll">https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html?highlight=unroll#pragma-unroll</a></div>
</div>
<div id="ref-mojoparameter" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">Modular, <span>“Parametric closure (<code>@parameter</code>) in mojo.”</span> 2025. Available: <a href="https://docs.modular.com/mojo/manual/decorators/parameter/#parametric-closure">https://docs.modular.com/mojo/manual/decorators/parameter/#parametric-closure</a></div>
</div>
<div id="ref-mojo_lifetimes" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">Modular, <span>“Lifetimes in mojo.”</span> 2025. Available: <a href="https://docs.modular.com/mojo/manual/values/lifetimes/">https://docs.modular.com/mojo/manual/values/lifetimes/</a></div>
</div>
<div id="ref-zero_cost_abstractions" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">saoirse, <span>“Zero cost abstractions.”</span> 2019. Available: <a href="https://without.boats/blog/zero-cost-abstractions/">https://without.boats/blog/zero-cost-abstractions/</a></div>
</div>
<div id="ref-iitd_parallel_convolution" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">R. Sen, <span>“Parallel convolution.”</span> 2022. Available: <a href="https://www.cse.iitd.ac.in/~rijurekha/col730_2022/parallelconvolution_aug29.pdf">https://www.cse.iitd.ac.in/~rijurekha/col730_2022/parallelconvolution_aug29.pdf</a></div>
</div>
<div id="ref-blelloch_prefix_sum" class="csl-entry" role="listitem">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">G. E. Blelloch, <span>“Prefix sums and their applications,”</span> in <em>Synthesis of parallel algorithms</em>, 1993, pp. 35–60. Available: <a href="https://www.cs.cmu.edu/~guyb/papers/Ble93.pdf">https://www.cs.cmu.edu/~guyb/papers/Ble93.pdf</a></div>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="goodhamgupta/personal_blog" data-repo-id="R_kgDOLXv-xA" data-category="General" data-category-id="DIC_kwDOLXv-xM4Cdogy" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
</div> <!-- /content -->




</body></html>