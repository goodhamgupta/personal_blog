<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Shubham Gupta">
<meta name="dcterms.date" content="2025-07-20">
<meta name="description" content="Moar GPU puzzles with slide-n-sum pooling, tile-flipping convs &amp; warp-speed scans">

<title>Shubham Gupta - GPUs go brrr with Mojo: Algorithms</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<script src="../site_libs/quarto-search/autocomplete-preset-algolia.umd.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "algolia": {
    "application-id": "HR1HJNZUVY",
    "search-only-api-key": "3326e8971e20d27e2dd21591d6a24656",
    "index-name": "blog_pages",
    "index-fields": {
      "href": "url",
      "section": "sec",
      "text": "body"
    },
    "analytics-events": true,
    "show-logo": false,
    "libDir": "site_libs"
  },
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/algoliasearch@4.5.1/dist/algoliasearch-lite.umd.js"></script>


<script type="text/javascript">
var ALGOLIA_INSIGHTS_SRC = "https://cdn.jsdelivr.net/npm/search-insights/dist/search-insights.iife.min.js";
!function(e,a,t,n,s,i,c){e.AlgoliaAnalyticsObject=s,e[s]=e[s]||function(){
(e[s].queue=e[s].queue||[]).push(arguments)},i=a.createElement(t),c=a.getElementsByTagName(t)[0],
i.async=1,i.src=n,c.parentNode.insertBefore(i,c)
}(window,document,"script",ALGOLIA_INSIGHTS_SRC,"aa");
</script>

<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@algolia/autocomplete-plugin-algolia-insights">

</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-CLKTGRWBQT"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-CLKTGRWBQT', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="Shubham Gupta - GPUs go brrr with Mojo: Algorithms">
<meta property="og:description" content="Moar GPU puzzles with slide-n-sum pooling, tile-flipping convs &amp; warp-speed scans">
<meta property="og:image" content="https://shubhamg.in/posts/mojo_gpu_puzzles/p11_block_boundary.png">
<meta property="og:site_name" content="Shubham Gupta">
<meta property="og:image:height" content="1432">
<meta property="og:image:width" content="3172">
<meta name="twitter:title" content="Shubham Gupta - GPUs go brrr with Mojo: Algorithms">
<meta name="twitter:description" content="Moar GPU puzzles with slide-n-sum pooling, tile-flipping convs &amp; warp-speed scans">
<meta name="twitter:image" content="https://shubhamg.in/posts/mojo_gpu_puzzles/p11_block_boundary.png">
<meta name="twitter:creator" content="@shubhamg2208">
<meta name="twitter:image-height" content="1432">
<meta name="twitter:image-width" content="3172">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Shubham Gupta</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/goodhamgupta"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">GPUs go brrr with Mojo: Algorithms</h1>
                  <div>
        <div class="description">
          Moar GPU puzzles with slide-n-sum pooling, tile-flipping convs &amp; warp-speed scans
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Shubham Gupta </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 20, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#puzzle-09" id="toc-puzzle-09" class="nav-link active" data-scroll-target="#puzzle-09">Puzzle 9: Pooling</a></li>
  <li><a href="#puzzle-10" id="toc-puzzle-10" class="nav-link" data-scroll-target="#puzzle-10">Puzzle 10: Dot Product</a>
  <ul class="collapse">
  <li><a href="#raw-memory" id="toc-raw-memory" class="nav-link" data-scroll-target="#raw-memory">Raw Memory</a></li>
  <li><a href="#layouttensor" id="toc-layouttensor" class="nav-link" data-scroll-target="#layouttensor">LayoutTensor</a></li>
  </ul></li>
  <li><a href="#puzzle-11" id="toc-puzzle-11" class="nav-link" data-scroll-target="#puzzle-11">Puzzle 11: 1D Convolution</a>
  <ul class="collapse">
  <li><a href="#single-block-with-shared-memory" id="toc-single-block-with-shared-memory" class="nav-link" data-scroll-target="#single-block-with-shared-memory">Single Block with Shared Memory</a>
  <ul class="collapse">
  <li><a href="#loop-unrolling" id="toc-loop-unrolling" class="nav-link" data-scroll-target="#loop-unrolling">Loop Unrolling</a></li>
  </ul></li>
  <li><a href="#block-boundary" id="toc-block-boundary" class="nav-link" data-scroll-target="#block-boundary">Block Boundary</a>
  <ul class="collapse">
  <li><a href="#problem-statement" id="toc-problem-statement" class="nav-link" data-scroll-target="#problem-statement">Problem statement</a></li>
  <li><a href="#the-halo-idea" id="toc-the-halo-idea" class="nav-link" data-scroll-target="#the-halo-idea">The halo idea</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#indexing" id="toc-indexing" class="nav-link" data-scroll-target="#indexing">From 1D Strips to 2D Tiles</a>
  <ul class="collapse">
  <li><a href="#thread-hierarchy-in-2d" id="toc-thread-hierarchy-in-2d" class="nav-link" data-scroll-target="#thread-hierarchy-in-2d">Thread Hierarchy in 2D</a></li>
  <li><a href="#warp" id="toc-warp" class="nav-link" data-scroll-target="#warp">What’s a Warp?</a></li>
  <li><a href="#computing-global-matrix-indices" id="toc-computing-global-matrix-indices" class="nav-link" data-scroll-target="#computing-global-matrix-indices">Computing Global Matrix Indices</a></li>
  <li><a href="#choosing-tile-size" id="toc-choosing-tile-size" class="nav-link" data-scroll-target="#choosing-tile-size">Choosing Tile Size</a></li>
  <li><a href="#bounds-checking" id="toc-bounds-checking" class="nav-link" data-scroll-target="#bounds-checking">Bounds Checking</a></li>
  <li><a href="#indexing-pattern-template" id="toc-indexing-pattern-template" class="nav-link" data-scroll-target="#indexing-pattern-template">Indexing Pattern Template</a></li>
  </ul></li>
  <li><a href="#bonus-2d-convolution" id="toc-bonus-2d-convolution" class="nav-link" data-scroll-target="#bonus-2d-convolution">Bonus: 2D Convolution</a></li>
  <li><a href="#puzzle-12" id="toc-puzzle-12" class="nav-link" data-scroll-target="#puzzle-12">Puzzle 12: Prefix Sum</a>
  <ul class="collapse">
  <li><a href="#hillis-steele-algorithm" id="toc-hillis-steele-algorithm" class="nav-link" data-scroll-target="#hillis-steele-algorithm">Hillis-Steele Algorithm</a></li>
  <li><a href="#blellochs-twopass-algorithm" id="toc-blellochs-twopass-algorithm" class="nav-link" data-scroll-target="#blellochs-twopass-algorithm">Blelloch’s Two‐Pass Algorithm</a>
  <ul class="collapse">
  <li><a href="#up-sweep-reduce" id="toc-up-sweep-reduce" class="nav-link" data-scroll-target="#up-sweep-reduce">Up-sweep (reduce)</a></li>
  <li><a href="#down-sweep-propagate" id="toc-down-sweep-propagate" class="nav-link" data-scroll-target="#down-sweep-propagate">Down-sweep (propagate)</a></li>
  </ul></li>
  <li><a href="#block-boundary-1" id="toc-block-boundary-1" class="nav-link" data-scroll-target="#block-boundary-1">Block Boundary</a>
  <ul class="collapse">
  <li><a href="#phase-1---local-scan" id="toc-phase-1---local-scan" class="nav-link" data-scroll-target="#phase-1---local-scan">Phase 1 - Local Scan</a></li>
  <li><a href="#phase-2---propagate-block-totals" id="toc-phase-2---propagate-block-totals" class="nav-link" data-scroll-target="#phase-2---propagate-block-totals">Phase 2 - Propagate block totals</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#puzzle-13-axis-sum" id="toc-puzzle-13-axis-sum" class="nav-link" data-scroll-target="#puzzle-13-axis-sum">Puzzle 13: Axis Sum</a></li>
  <li><a href="#puzzle-14-matmul" id="toc-puzzle-14-matmul" class="nav-link" data-scroll-target="#puzzle-14-matmul">Puzzle 14: Matmul</a>
  <ul class="collapse">
  <li><a href="#global-memory-version" id="toc-global-memory-version" class="nav-link" data-scroll-target="#global-memory-version">Global Memory Version</a></li>
  <li><a href="#shared-memory-version" id="toc-shared-memory-version" class="nav-link" data-scroll-target="#shared-memory-version">Shared Memory Version</a></li>
  <li><a href="#roofline-model" id="toc-roofline-model" class="nav-link" data-scroll-target="#roofline-model">Roofline Model</a>
  <ul class="collapse">
  <li><a href="#hardware-model" id="toc-hardware-model" class="nav-link" data-scroll-target="#hardware-model">Hardware Model</a></li>
  <li><a href="#software-model" id="toc-software-model" class="nav-link" data-scroll-target="#software-model">Software Model</a></li>
  <li><a href="#naive-roofline-model" id="toc-naive-roofline-model" class="nav-link" data-scroll-target="#naive-roofline-model">Naive Roofline Model</a></li>
  <li><a href="#where-the-roofline-model-fails" id="toc-where-the-roofline-model-fails" class="nav-link" data-scroll-target="#where-the-roofline-model-fails">Where the Roofline Model Fails</a></li>
  </ul></li>
  <li><a href="#roofline-estimation" id="toc-roofline-estimation" class="nav-link" data-scroll-target="#roofline-estimation">Roofline Estimation</a>
  <ul class="collapse">
  <li><a href="#naive-matmul-analysis" id="toc-naive-matmul-analysis" class="nav-link" data-scroll-target="#naive-matmul-analysis">Naive MatMul Analysis</a></li>
  <li><a href="#shared-memory-optimization" id="toc-shared-memory-optimization" class="nav-link" data-scroll-target="#shared-memory-optimization">Shared Memory Optimization</a></li>
  <li><a href="#key-insights" id="toc-key-insights" class="nav-link" data-scroll-target="#key-insights">Key Insights</a></li>
  </ul></li>
  <li><a href="#tiled-matrix-multiplication-gemm" id="toc-tiled-matrix-multiplication-gemm" class="nav-link" data-scroll-target="#tiled-matrix-multiplication-gemm">Tiled Matrix-Multiplication (GEMM)</a>
  <ul class="collapse">
  <li><a href="#tile" id="toc-tile" class="nav-link" data-scroll-target="#tile">Tile?</a></li>
  <li><a href="#memory-mapping-for-tiled-gemm" id="toc-memory-mapping-for-tiled-gemm" class="nav-link" data-scroll-target="#memory-mapping-for-tiled-gemm">Memory mapping for tiled GEMM</a></li>
  <li><a href="#raw-memory-1" id="toc-raw-memory-1" class="nav-link" data-scroll-target="#raw-memory-1">Raw Memory</a></li>
  <li><a href="#layouttensor-1" id="toc-layouttensor-1" class="nav-link" data-scroll-target="#layouttensor-1">LayoutTensor</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/goodhamgupta/personal_blog/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>Picking up right where the the <a href="../posts/2025-07-06-gpu-puzzles-p1.html">last post</a> left off, this follow-up dives into the bread-and-butter building blocks of deep-learning kernels. We’ll implement and benchmark core algorithms-sliding-window pools, tile-wise convolutions, warp-level scans, and more.</p>
<section id="puzzle-09" class="level1">
<h1><a href="https://builds.modular.com/puzzles/puzzle_09/puzzle_09.html">Puzzle 9: Pooling</a></h1>
<p>Pooling is a classic trick in neural networks for shrinking down your data-think of it as a way to “summarize” regions of an image or tensor. Instead of looking at every single pixel, pooling (like max or average pooling) slides a window over your data and grabs just the most important info from each patch. On GPUs, pooling is a perfect fit: each thread can independently process a window, so you get massive parallelism and a big speedup compared to CPUs.</p>
<p>This puzzle is a bit different compared to traditional pooling: Instead of having a “kernel”, each output element is the running sum of the all the elements in the current window.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" data-glightbox="description: .lightbox-desc-1" title="Pooling"><img src="mojo_gpu_puzzles/p09.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Pooling"></a></p>
<figcaption>Pooling</figcaption>
</figure>
</div>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p09.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb1" data-filename="p09.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> TPB <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> SIZE <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK <span class="op">=</span> (TPB, <span class="dv">1</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> dtype <span class="op">=</span> DType.float32</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> pooling(</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    out: UnsafePointer[Scalar[dtype]],</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    a: UnsafePointer[Scalar[dtype]],</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    shared <span class="op">=</span> stack_allocation[</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        TPB,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        Scalar[dtype],</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        address_space <span class="op">=</span> AddressSpace.SHARED,</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    ]()</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    global_i <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    local_i <span class="op">=</span> thread_idx.x</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> size:</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        shared[local_i] <span class="op">=</span> a[global_i]</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> size:</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> local_i <span class="op">-</span> <span class="dv">2</span> <span class="op">&gt;=</span> <span class="dv">0</span>:</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>            out[global_i] <span class="op">=</span> (</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>                shared[local_i <span class="op">-</span> <span class="dv">2</span>] <span class="op">+</span> shared[local_i <span class="op">-</span> <span class="dv">1</span>] <span class="op">+</span> shared[local_i]</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> local_i <span class="op">-</span> <span class="dv">1</span> <span class="op">&gt;=</span> <span class="dv">0</span>:</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>            out[global_i] <span class="op">=</span> shared[local_i <span class="op">-</span> <span class="dv">1</span>] <span class="op">+</span> shared[local_i]</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>            out[global_i] <span class="op">=</span> shared[local_i]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p09</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<p>The LayoutTensor version is nearly identical to the Raw Memory approach, so we’ll omit the code here for brevity.</p>
</section>
<section id="puzzle-10" class="level1">
<h1><a href="https://builds.modular.com/puzzles/puzzle_10/puzzle_10.html">Puzzle 10: Dot Product</a></h1>
<p>The Dot Product of two vectors <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> is defined as <span class="citation" data-cites="wikipediadotproduct"><a href="#ref-wikipediadotproduct" role="doc-biblioref">[1]</a></span>:</p>
<p><span class="math display">\[
c = a \cdot b = \sum_{i=0}^{n-1} a_i b_i
\]</span></p>
<p>Similar to the previous puzzles, we can implement the dot-product by copying data to the shared memory, and running our operations on it.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" data-glightbox="description: .lightbox-desc-2" title="Dot Product"><img src="mojo_gpu_puzzles/p10.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Dot Product"></a></p>
<figcaption>Dot Product</figcaption>
</figure>
</div>
<p>To implement dot product efficiently on a GPU, we will use <strong>parallel reduction</strong>. This is a classic pattern for aggregating values (sum, min, max, etc.) across a large array using many threads.</p>
<p>Picture Zeno’s “half-way” paradox <span class="citation" data-cites="zeno_dichotomy_paradox"><a href="#ref-zeno_dichotomy_paradox" role="doc-biblioref">[2]</a></span>: you keep halving the leftover distance until you’re done. A parallel reduction does the same-each round halves the number of active threads instead of the distance. <strong>Unlike Zeno’s infinite halvings though</strong>, we stop at a concrete point: when only thread 0 remains active (<code>stride</code> becomes 0).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/zeno_paradox.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" data-glightbox="description: .lightbox-desc-3" title="Zeno Paradox"><img src="mojo_gpu_puzzles/zeno_paradox.png" class="img-fluid figure-img" alt="Zeno Paradox"></a></p>
<figcaption>Zeno Paradox</figcaption>
</figure>
</div>
<ul>
<li>Every thread multiplies its assigned <code>a</code> and <code>b</code> elements and writes the partial product into shared memory.</li>
<li>Each reduction round:
<ul>
<li>The active-thread count is cut in half (<code>stride /= 2</code>).</li>
<li>Each surviving thread adds its value to the partner <code>stride</code> positions away.</li>
<li>A <code>barrier()</code> guarantees all writes land before the next “half-step.”</li>
</ul></li>
<li>After log₂ (n) halvings, Zeno’s finish line is crossed-thread 0 alone holds the final dot-product.</li>
</ul>
<p>This pattern is fast, highly parallel, and used everywhere in GPU programming for reductions (sum, min, max, etc).</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout-nrow="3">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/pr_p1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="mojo_gpu_puzzles/pr_p1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="500"></a></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/pr_p2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="mojo_gpu_puzzles/pr_p2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="500"></a></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/pr_p3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="mojo_gpu_puzzles/pr_p3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="500"></a></p>
</figure>
</div>
</div>
</div>
</div>
<section id="raw-memory" class="level2">
<h2 class="anchored" data-anchor-id="raw-memory">Raw Memory</h2>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p10.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb3" data-filename="p10.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> dot_product(</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    output: UnsafePointer[Scalar[dtype]],</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    a: UnsafePointer[Scalar[dtype]],</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    b: UnsafePointer[Scalar[dtype]],</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    global_idx <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    local_idx <span class="op">=</span> thread_idx.x</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_idx <span class="op">&lt;</span> size:</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        shared[local_idx] <span class="op">=</span> a[global_idx] <span class="op">*</span> b[global_idx]</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    stride <span class="op">=</span> TPB <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span>(stride <span class="op">&gt;</span> <span class="dv">0</span>):</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> local_idx <span class="op">&lt;</span> stride:</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>            shared[local_idx] <span class="op">+=</span> shared[local_idx <span class="op">+</span> stride]</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        barrier()</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        stride <span class="op">=</span> stride <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># only allow thread 0 to write result</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_idx <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        output[<span class="dv">0</span>] <span class="op">=</span> shared[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</details>
<p><strong>Note</strong>: Instead of doing the parallel reduction, we could also implement the solution using a loop:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode diff code-with-copy"><code class="sourceCode diff"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="st">-    stride = TPB // 2</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="st">-    while(stride &gt; 0):</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="st">-        if local_idx &lt; stride:</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="st">-            shared[local_idx] += shared[local_idx + stride]</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="st">-        </span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="st">-        barrier()</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="st">-        stride = stride // 2</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="st">-    </span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="st">-    # only allow thread 0 to write result</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="st">-    if local_idx == 0:</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="st">-        output[0] = shared[0]</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="va">+    if global_idx &lt; size:</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="va">+        for idx in range(size):</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="va">+            output[0] = output[0] + shared[idx]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>While this approach also gives the correct answer for this puzzle, it has multiple problems:</p>
<ul>
<li><strong>Race conditions</strong>: Multiple threads would simultaneously try to update output[0] without synchronization, causing lost updates.</li>
<li><strong>Thread divergence</strong>: When threads in a warp take different execution paths (some running the loop, others not), the GPU must serialize execution, destroying parallelism.</li>
<li><strong>Redundant computation</strong>: Every qualifying thread would compute the exact same sum over the entire array, wasting compute resources.</li>
<li><strong>Memory bottleneck</strong>: Repeated atomic operations to the same memory location (output[0]) create severe contention.</li>
</ul>
</section>
<section id="layouttensor" class="level2">
<h2 class="anchored" data-anchor-id="layouttensor">LayoutTensor</h2>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p10.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb5" data-filename="p10.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> TPB <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> SIZE <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK <span class="op">=</span> (SIZE, <span class="dv">1</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> dtype <span class="op">=</span> DType.float32</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> layout <span class="op">=</span> Layout.row_major(SIZE)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> out_layout <span class="op">=</span> Layout.row_major(<span class="dv">1</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> dot_product[</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    in_layout: Layout, out_layout: Layout</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    output: LayoutTensor[mut<span class="op">=</span><span class="va">True</span>, dtype, out_layout],</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">True</span>, dtype, in_layout],</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    b: LayoutTensor[mut<span class="op">=</span><span class="va">True</span>, dtype, in_layout],</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use LayoutTensorBuilder instead of stack_allocation</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    shared <span class="op">=</span> tb[dtype]().row_major[TPB]().shared().alloc()</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    global_idx <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    local_idx <span class="op">=</span> thread_idx.x</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_idx <span class="op">&lt;</span> size:</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        shared[local_idx] <span class="op">=</span> a[global_idx] <span class="op">*</span> b[global_idx]</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    stride <span class="op">=</span> TPB <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span>(stride <span class="op">&gt;</span> <span class="dv">0</span>):</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> local_idx <span class="op">&lt;</span> stride:</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>            shared[local_idx] <span class="op">+=</span> shared[local_idx <span class="op">+</span> stride]</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>        barrier()</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>        stride <span class="op">=</span> stride <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># only allow thread 0 to write result</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_idx <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>        output[<span class="dv">0</span>] <span class="op">=</span> shared[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</details>
</section>
</section>
<section id="puzzle-11" class="level1">
<h1><a href="https://builds.modular.com/puzzles/puzzle_11/puzzle_11.html">Puzzle 11: 1D Convolution</a></h1>
<p>Picture sliding a magnifying glass along a long strip of film. That’s exactly what a 1-D convolution does to any 1-D signal-audio samples, DNA bases, even bytes of log data.</p>
<ul>
<li>The kernel (a small weight vector) glides over the sequence one step at a time (or more if you set stride &gt; 1).</li>
<li>At each stop it multiplies the local window by its weights, sums the result, and drops a single number into the output map.</li>
<li>Stack layers and you grow the “what can I see at once?” window (the receptive field) without blowing up parameters.</li>
</ul>
<p><strong>Why bother?</strong></p>
<ul>
<li><strong>Speed</strong>: A conv layer is just a batched matrix-mul-GPU catnip.</li>
<li><strong>Locality first, context later</strong>: Early layers grab short-range patterns (phonemes, k-mers). Deeper layers stitch them into bigger motifs (words, promoters).</li>
<li><strong>Channels generalize it</strong>: You convolve along length, but for each input channel you keep separate weights, sum across channels, and spit out new feature maps. Same trick as 2-D CNNs, just flattened.</li>
</ul>
<p>For a better picture, see Ayush’s blog<span class="citation" data-cites="thakur_convolutions"><a href="#ref-thakur_convolutions" role="doc-biblioref">[3]</a></span> on convolutions.</p>
<p>The convolution operation can be defined as: <span id="eq-convolution"><span class="math display">\[
    (input\_signal\_a * kernel\_b)[i] = \sum_{j=0}^{\text{kernel\_size}-1} input\_signal\_a[i + j] * kernel\_b[j]
\tag{1}\]</span></span></p>
<section id="single-block-with-shared-memory" class="level2">
<h2 class="anchored" data-anchor-id="single-block-with-shared-memory">Single Block with Shared Memory</h2>
<p>For this version, we assume that we only have a single block, and both the input data and the kernel fit within a block.</p>
<p><a href="mojo_gpu_puzzles/p11_simple.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="mojo_gpu_puzzles/p11_simple.png" class="img-fluid"></a></p>
<p>The implementation is:</p>
<ul>
<li>Intialise shared memory for both the input and the kernel</li>
<li>Load data in the shared memory, and use <code>barrier()</code> to sync all threads before performing computations.</li>
<li>In a loop, multiple the value of input and kernel, and add to a local variable.</li>
<li>Assign the local variable to the right output index.</li>
</ul>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p11.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb6" data-filename="p11.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> TPB <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> SIZE <span class="op">=</span> <span class="dv">6</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> CONV <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK <span class="op">=</span> (TPB, <span class="dv">1</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> dtype <span class="op">=</span> DType.float32</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> in_layout <span class="op">=</span> Layout.row_major(SIZE)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> out_layout <span class="op">=</span> Layout.row_major(SIZE)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> conv_layout <span class="op">=</span> Layout.row_major(CONV)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> conv_1d_simple[</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    in_layout: Layout, out_layout: Layout, conv_layout: Layout</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    output: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, out_layout],</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, in_layout],</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    b: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, conv_layout],</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    global_i <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    local_i <span class="op">=</span> thread_idx.x</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This is oversized! I've explained it later :)</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    shared_a <span class="op">=</span> tb[dtype]().row_major[TPB]().shared().alloc()</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    shared_b <span class="op">=</span> tb[dtype]().row_major[TPB]().shared().alloc()</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This can also be optimised, as shown later.</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> SIZE:</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        shared_a[local_i] <span class="op">=</span> a[global_i]</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>        shared_b[local_i] <span class="op">=</span> b[global_i]</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> SIZE:</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ensure the local var has the same type as the output</span></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># to avoid type casting errors.</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> local_sum: output.element_type <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Perform loop unrolling.</span></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>        <span class="at">@parameter</span></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(CONV):</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> local_i <span class="op">+</span> j <span class="op">&lt;</span> SIZE:</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>                local_sum <span class="op">+=</span> shared_a[local_i <span class="op">+</span> j] <span class="op">*</span> shared_b[j]</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>        output[global_i] <span class="op">=</span> local_sum</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</details>
<p>I deliberately allocate <code>shared_a</code> and <code>shared_b</code> with the block width (<code>TPB</code>) instead of the input length (<code>SIZE</code>) and filter length (<code>CONV</code>). The extra space isn’t needed for correctness-the kernel only touches the first <code>SIZE</code>/<code>CONV</code> elements-but it nicely demonstrates <code>LayoutTensor</code>’s masking: out-of-range indices are silently ignored. This trick keeps the buffer shape uniform across puzzles without cluttering the code with edge-case branches. The flip side is a bit of wasted shared memory, which can pinch if your kernel is already pushing the SRAM limit.</p>
<p>The <em>optimal</em> allocation of shared memory would be:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode diff code-with-copy"><code class="sourceCode diff"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="st">-    shared_a = tb[dtype]().row_major[TPB]().shared().alloc()</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="st">-    shared_b = tb[dtype]().row_major[TPB]().shared().alloc()</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="va">+    # Allocate exactly SIZE elements -&gt; smaller shared-mem footprint</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="va">+    shared_a = tb[dtype]().row_major[SIZE]().shared().alloc()</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="va">+    # Allocate exactly CONV elements -&gt; smaller shared-mem footprint</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="va">+    shared_b = tb[dtype]().row_major[CONV]().shared().alloc()</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="st">-    if global_i &lt; SIZE:</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="st">-        shared_a[local_i] = a[global_i]</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="st">-        shared_b[local_i] = b[global_i]</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="va">+    if global_i &lt; SIZE:</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="va">+        shared_a[local_i] = a[global_i]</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="va">+    if global_i &lt; CONV:</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="va">+        shared_b[local_i] = b[global_i]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="loop-unrolling" class="level3">
<h3 class="anchored" data-anchor-id="loop-unrolling">Loop Unrolling</h3>
<p><a href="https://docs.modular.com/mojo/manual/decorators/parameter/"><code>@parameter</code></a> is Mojo’s implementation of <strong>loop unrolling</strong>. This has the same functionality as <code>pragma unroll(N)</code> in CUDA.</p>
<p>When unroll is in effect, the optimizer determines and applies the best unrolling factor for each loop; in some cases, the loop control might be modified to avoid unnecessary branching. The compiler remains the final arbiter of whether the loop is unrolled<span class="citation" data-cites="nvidiapragmaunroll"><a href="#ref-nvidiapragmaunroll" role="doc-biblioref">[4]</a></span>.</p>
<p><code>@parameter</code> isn’t limited to loops/branches-you can slap it on an inner function and Mojo will build a <strong>parametric closure</strong>, defined as<span class="citation" data-cites="mojoparameter"><a href="#ref-mojoparameter" role="doc-biblioref">[5]</a></span>:</p>
<blockquote class="blockquote">
<p>A parametric closure is a nested function decorated with <code>@parameter</code>. Any values it captures from the surrounding scope are treated as compile-time constants. The compiler materialises one specialised version of the closure for every distinct set of captured values</p>
</blockquote>
<p>Example:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>parametric_closure.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb8" data-filename="parametric_closure.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> make_shift(off: Int):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">@parameter</span>            <span class="co"># ← specialised per ‘off'</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">fn</span> shift(x: Int) <span class="op">-&gt;</span> Int:</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x <span class="op">+</span> off</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> shift</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> s1 <span class="op">=</span> make_shift(<span class="dv">1</span>)    <span class="co"># emits shift-$off=1</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> s4 <span class="op">=</span> make_shift(<span class="dv">4</span>)    <span class="co"># emits shift-$off=4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>No runtime captures, no heap boxing-the constant <code>off</code> is literally spliced into the generated IR, so calls to <code>s1</code>/<code>s4</code> inline like normal code and can be further unrolled or constant-folded.</p>
<p>Why is this safe? Mojo’s <em>origin</em> system<span class="citation" data-cites="mojo_lifetimes"><a href="#ref-mojo_lifetimes" role="doc-biblioref">[6]</a></span> assigns each compile-time constant its own immutable origin. The closure therefore can’t outlive or mutate the thing it captured; once the surrounding scope ends those origins die too, guaranteeing that the specialised code never touches expired storage.</p>
<p>In summary, you get closure ergonomics plus “zero-cost abstraction”<span class="citation" data-cites="zero_cost_abstractions"><a href="#ref-zero_cost_abstractions" role="doc-biblioref">[7]</a></span> performance-ideal for GPU kernels where every cycle and register matters.</p>
</section>
</section>
<section id="block-boundary" class="level2">
<h2 class="anchored" data-anchor-id="block-boundary">Block Boundary</h2>
<p>We now aim to perform convolution over an input that is larger than a single block. Due to the nature of convolution operation, this introduces interesting boundary conditions. Specifically, the output of block N now depends on block N - 1, when N &gt; 1.</p>
<p>The blue cells are the data <em>owned</em> by the current thread-block. The orange cells are the first few elements of the <em>next</em> block that the convolution window will inevitably peek at.</p>
<p><a href="mojo_gpu_puzzles/p11_block_boundary.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="mojo_gpu_puzzles/p11_block_boundary.png" class="img-fluid"></a></p>
<section id="problem-statement" class="level3">
<h3 class="anchored" data-anchor-id="problem-statement">Problem statement</h3>
<p>Run a 1-D convolution with a <code>CONV₂</code>-tap kernel over an input that is longer than one block (<code>TPB</code> threads). We want every thread to:</p>
<ul>
<li>Pull data from <strong>shared memory only</strong> (once it’s loaded, stay in-block)<br>
</li>
<li>Avoid divergent branches and random global reads<br>
</li>
<li>Keep the load pattern fully coalesced</li>
</ul>
<p>Naïve global loads meet none of those goals-once a window crosses the block edge the tail threads must issue conditional, <em>straggling</em> reads (i.e.&nbsp;each thread grabs a lone, scattered element from global memory instead of part of one tidy, coalesced burst).</p>
</section>
<section id="the-halo-idea" class="level3">
<h3 class="anchored" data-anchor-id="the-halo-idea">The halo idea</h3>
<p>Give each block an in-block “fence extension”:</p>
<pre><code>shared_a = …[TPB + (CONV₂ − 1)]   # main slice + halo</code></pre>
<p>The extra <code>(CONV₂ − 1)</code> slots-the <em>halo</em>-mirror the first <code>(CONV₂ − 1)</code> elements of the next block (or zeros if we’re already at EOF). That single change guarantees that every sliding window lives in one contiguous span of shared memory.</p>
<p>The elements that are involved in multiple tiles and loaded by multiple blocks are commonly referred to as <em>halo cells</em> or <em>skirt cells</em> since they “hang” from the side of the part that is used solely by a single block<span class="citation" data-cites="iitd_parallel_convolution"><a href="#ref-iitd_parallel_convolution" role="doc-biblioref">[8]</a></span>.</p>
<p>Loading recipe (matches the numbered arrows in the figure):</p>
<ol type="1">
<li><strong>Bulk copy</strong> - all <code>TPB</code> threads dump their element:<br>
<code>shared_a[t] = a[blockStart + t]</code></li>
<li><strong>Halo fill</strong> - threads <code>t &lt; (CONV₂ − 1)</code> copy the tail:<br>
<code>shared_a[TPB + t] = (a[blockStart + TPB + t] if in-range else 0)</code></li>
<li><strong>Kernel stash</strong> - threads <code>t &lt; CONV₂</code> cache the weights:<br>
<code>shared_b[t] = b[t]</code></li>
<li><code>barrier()</code> - everyone syncs</li>
</ol>
<p>After step 4 every thread sees:</p>
<pre><code>      main slice              halo
[ … local_i … TPB − 1 | TPB … TPB+CONV₂−2 ]</code></pre>
<p>Code to perform the actual computation is the same as in <a href="#puzzle-10">Puzzle 10</a>.</p>
<p>One barrier, no branches and 100 % shared-memory hits ensure our kernel is fast and efficient!</p>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p11_block_boundary.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb11" data-filename="p11_block_boundary.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> SIZE_2 <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> CONV_2 <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID_2 <span class="op">=</span> (<span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK_2 <span class="op">=</span> (TPB, <span class="dv">1</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> in_2_layout <span class="op">=</span> Layout.row_major(SIZE_2)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> out_2_layout <span class="op">=</span> Layout.row_major(SIZE_2)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> conv_2_layout <span class="op">=</span> Layout.row_major(CONV_2)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> conv_1d_block_boundary[</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    in_layout: Layout, out_layout: Layout, conv_layout: Layout, dtype: DType</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    output: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, out_layout],</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, in_layout],</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    b: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, conv_layout],</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    global_i <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    local_i  <span class="op">=</span> thread_idx.x</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># input slice + halo</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    shared_a <span class="op">=</span> tb[dtype]().row_major[TPB <span class="op">+</span> CONV_2 <span class="op">-</span> <span class="dv">1</span>]().shared().alloc()</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># load kernel</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    shared_b <span class="op">=</span> tb[dtype]().row_major[CONV_2]().shared().alloc()</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> SIZE_2:</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># coalesced load of main slice</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>        shared_a[local_i] <span class="op">=</span> a[global_i]                  </span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># only first CONV_2 threads participate</span></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_i <span class="op">&lt;</span> CONV_2:</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># load kernel into shared memory</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>        shared_b[local_i] <span class="op">=</span> b[local_i]                   </span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># threads responsible for halo load</span></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_i <span class="op">&lt;</span> CONV_2 <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># element that lives in next block</span></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> next_idx <span class="op">=</span> global_i <span class="op">+</span> TPB                    </span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># pad with zeros</span></span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>        shared_a[local_i <span class="op">+</span> TPB] <span class="op">=</span> a[next_idx] <span class="cf">if</span> next_idx <span class="op">&lt;</span> SIZE_2 <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># skip threads mapping past the end</span></span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> SIZE_2:</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> local_sum: output.element_type <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>        <span class="at">@parameter</span>                                       </span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(CONV_2):                          </span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>            <span class="co"># dot product of window &amp; kernel</span></span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>            local_sum <span class="op">+=</span> shared_a[local_i <span class="op">+</span> j] <span class="op">*</span> shared_b[j]</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>        output[global_i] <span class="op">=</span> local_sum</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb12"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p11 <span class="at">--block-boundary</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([14.0, 20.0, 26.0, 32.0, 38.0, 44.0, 50.0, 56.0, 62.0, 68.0, 74.0, 80.0, 41.0, 14.0, 0.0])</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([14.0, 20.0, 26.0, 32.0, 38.0, 44.0, 50.0, 56.0, 62.0, 68.0, 74.0, 80.0, 41.0, 14.0, 0.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
</section>
</section>
<section id="indexing" class="level1">
<h1>From 1D Strips to 2D Tiles</h1>
<p>Sliding a 1D window over an audio buffer was straightforward: one axis, one index. Images and matrices, however, live on chessboards, not lines. To convolve or multiply them efficiently we need to map <strong>two spatial dimensions</strong> onto the GPU’s grid-block-thread hierarchy.</p>
<section id="thread-hierarchy-in-2d" class="level3">
<h3 class="anchored" data-anchor-id="thread-hierarchy-in-2d">Thread Hierarchy in 2D</h3>
<p>The GPU execution model extends naturally to 2D with a three-level hierarchy:</p>
<table class="table">
<thead>
<tr class="header">
<th>Level</th>
<th>Analogy</th>
<th>Coordinates</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Grid</strong></td>
<td>City</td>
<td><code>(blockIdx.x, blockIdx.y)</code></td>
</tr>
<tr class="even">
<td><strong>Block</strong></td>
<td>City block</td>
<td><code>(threadIdx.x, threadIdx.y)</code></td>
</tr>
<tr class="odd">
<td><strong>Thread</strong></td>
<td>House</td>
<td>computed from block + thread IDs</td>
</tr>
</tbody>
</table>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p13_block.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" data-glightbox="description: .lightbox-desc-9" title="2D Block Layout"><img src="mojo_gpu_puzzles/p13_block.png" class="img-fluid quarto-figure quarto-figure-left figure-img" alt="2D Block Layout"></a></p>
<figcaption>2D Block Layout</figcaption>
</figure>
</div>
<p>Within each block, you choose the thread footprint at kernel launch with <code>THREADS_PER_BLOCK = (blockDim.x, blockDim.y)</code>, giving <code>blockDim.x * blockDim.y</code> total threads per block.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p13_thread.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" data-glightbox="description: .lightbox-desc-10" title="2D Thread Layout"><img src="mojo_gpu_puzzles/p13_thread.png" class="img-fluid figure-img" alt="2D Thread Layout"></a></p>
<figcaption>2D Thread Layout</figcaption>
</figure>
</div>
</section>
<section id="warp" class="level3">
<h3 class="anchored" data-anchor-id="warp">What’s a Warp?</h3>
<p>Under the hood, the GPU executes <strong>32 threads at once</strong> in groups called <strong>warps</strong> (AMD calls them <em>wavefronts</em><span class="citation" data-cites="amd_gpu_basics"><a href="#ref-amd_gpu_basics" role="doc-biblioref">[9]</a></span>). All 32 lanes run the same instruction each cycle (SIMT). Thread divergence or uncoalesced memory access forces the warp to serialize, so we design our 2D tiles around these 32-lane chunks.</p>
<p><strong>Hardware facts:</strong></p>
<ul>
<li><strong>SIMT execution</strong>: All 32 threads in a warp execute the same instruction. Branching splits the warp and runs paths serially.</li>
<li><strong>Memory coalescing</strong>: A warp performs one 32-lane memory request when threads access consecutive addresses.</li>
<li><strong>Occupancy</strong>: The number of warps that can run simultaneously on a streaming multiprocessor, limited by registers and shared memory per block.</li>
</ul>
<p>Grids and blocks are a programmer-friendly abstraction. Warps are what the hardware actually schedules.</p>
</section>
<section id="computing-global-matrix-indices" class="level3">
<h3 class="anchored" data-anchor-id="computing-global-matrix-indices">Computing Global Matrix Indices</h3>
<p>The key insight is that every thread computes its global position using the same formula:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> col <span class="op">=</span> block_idx.x <span class="op">*</span> block_dim.x <span class="op">+</span> thread_idx.x  <span class="co"># column index</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> row <span class="op">=</span> block_idx.y <span class="op">*</span> block_dim.y <span class="op">+</span> thread_idx.y  <span class="co"># row index</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This maps the thread hierarchy directly to matrix coordinates:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p13_matrix_position.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" data-glightbox="description: .lightbox-desc-11" title="Matrix Indexing"><img src="mojo_gpu_puzzles/p13_matrix_position.png" class="img-fluid figure-img" alt="Matrix Indexing"></a></p>
<figcaption>Matrix Indexing</figcaption>
</figure>
</div>
<p>For an M×N output matrix, you typically launch:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> TILE_X <span class="op">=</span> <span class="dv">16</span>  <span class="co"># threads per block in x dimension</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> TILE_Y <span class="op">=</span> <span class="dv">16</span>  <span class="co"># threads per block in y dimension</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_X <span class="op">=</span> ceildiv(N, TILE_X)  <span class="co"># columns</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_Y <span class="op">=</span> ceildiv(M, TILE_Y)  <span class="co"># rows</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID <span class="op">=</span> (BLOCKS_X, BLOCKS_Y)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK <span class="op">=</span> (TILE_Y, TILE_X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="choosing-tile-size" class="level3">
<h3 class="anchored" data-anchor-id="choosing-tile-size">Choosing Tile Size</h3>
<p><a href="#warp">As shown earlier</a>, because a warp wants contiguous addresses, we’ll carve the matrix into 16×16 tiles. Here’s how the hardware facts translate to design choices:</p>
<ul>
<li><strong>Warp-aligned rows</strong>: Make tile width a multiple of 32 (warp size) so each row loads as a single coalesced burst.</li>
<li><strong>Shared memory reuse</strong>: Square tiles minimize the halo-to-area ratio, so each global load gets reused ~K times across the convolution window.</li>
<li><strong>Resource budgeting</strong>: 256-512 threads per block (8-16 warps) keeps enough warps resident for latency hiding without exhausting registers or shared memory.</li>
</ul>
<p>A 16×16 tile gives 256 threads = 8 warps, hitting the sweet spot for most GPUs.</p>
</section>
<section id="bounds-checking" class="level3">
<h3 class="anchored" data-anchor-id="bounds-checking">Bounds Checking</h3>
<p>Since matrix dimensions are rarely exact multiples of tile size, always guard against out-of-bounds access:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> row <span class="op">&lt;</span> M <span class="kw">and</span> col <span class="op">&lt;</span> N:</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># safe to access matrix[row, col]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Mojo doesn’t provide automatic bound checking when writing to shared memory <span class="citation" data-cites="mojo_layouttensor_setitem"><a href="#ref-mojo_layouttensor_setitem" role="doc-biblioref">[10]</a></span>.</p>
<details>
<summary>
<strong>Worked Example: 40×50 Matrix with 16×16 Tiles</strong>
</summary>
<p>For a 40×50 matrix with 16×16 tiles:</p>
<pre><code>        col 0……15 16……31 32……47
 row
 0…15    Blk(0,0)  Blk(1,0)  Blk(2,0)
16…31    Blk(0,1)  Blk(1,1)  Blk(2,1)
32…39    Blk(0,2)  Blk(1,2)  Blk(2,2)</code></pre>
<p>Each thread in Block(1,1) computes one element where row ∈ [16,31] and col ∈ [16,31]. Note that Block(2,2) only processes 8×16 elements due to the matrix boundaries.</p>
</details>
</section>
<section id="indexing-pattern-template" class="level3">
<h3 class="anchored" data-anchor-id="indexing-pattern-template">Indexing Pattern Template</h3>
<div class="sourceCode" id="cb17"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> row <span class="op">=</span> block_idx.y <span class="op">*</span> block_dim.y <span class="op">+</span> thread_idx.y</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> col <span class="op">=</span> block_idx.x <span class="op">*</span> block_dim.x <span class="op">+</span> thread_idx.x</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> row <span class="op">&lt;</span> M <span class="kw">and</span> col <span class="op">&lt;</span> N:</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Process matrix[row, col]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This indexing pattern appears in every 2D GPU kernel-matrix multiplication, 2D convolution, transpose, etc.</p>
<blockquote class="blockquote">
<p><strong>Note</strong>: Mojo/CUDA grids and blocks can also have a third dimension (<code>block_idx.z</code>, <code>thread_idx.z</code>) for problems like 3D volume processing or batch operations. We’ll cover that when we encounter 3D kernels.</p>
</blockquote>
</section>
</section>
<section id="bonus-2d-convolution" class="level1">
<h1>Bonus: 2D Convolution</h1>
<p>We can extend our implementation for 1D convolution to a 2D convolution.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/2d_convolution.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-12" data-glightbox="description: .lightbox-desc-12" title="Source: Toast Lab"><img src="mojo_gpu_puzzles/2d_convolution.gif" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Source: Toast Lab"></a></p>
<figcaption>Source: <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p1.2-web/Project%201.2%20-%20Computer%20Architecture%20I%20-%20ShanghaiTech%20University.html">Toast Lab</a></figcaption>
</figure>
</div>
<p>Everything is exactly the same idea as 1-D, only now we have two spatial dims:</p>
<ul>
<li>We launch a 2D grid of <code>(ceildiv(WIDTH,TPB_Y), ceildiv(HEIGHT,TPB_X))</code> blocks of <code>TPB_Y×TPB_X</code> threads.</li>
<li>Each block allocates a shared tile of size <code>(TPB_Y+K−1)×(TPB_X+K−1)</code> to hold its “main” patch plus a one‐pixel halo on the bottom/right.</li>
<li>We also stash the full <code>K×K</code> kernel into shared_k.</li>
<li>After a single barrier(), each thread does two nested <code>@parameter</code> loops over <code>ky,kx∈[0,K)</code> to compute a dot‐product.</li>
</ul>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p11_conv_2d.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb18" data-filename="p11_conv_2d.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> math <span class="im">import</span> ceildiv</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> TPB_X <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> TPB_Y <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> WIDTH <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> HEIGHT <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> K     <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID_2D  <span class="op">=</span> (ceildiv(WIDTH, TPB_Y),  ceildiv(HEIGHT, TPB_X))</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK_2D <span class="op">=</span> (TPB_Y, TPB_X)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> conv_2d_halo[</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    in_layout : Layout, out_layout : Layout,</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    k_layout  : Layout, dtype : DType</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    output : LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, out_layout],</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    inp    : LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, in_layout],</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    kernel : LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, k_layout],</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> gx <span class="op">=</span> block_idx.x <span class="op">*</span> block_dim.x <span class="op">+</span> thread_idx.x</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> gy <span class="op">=</span> block_idx.y <span class="op">*</span> block_dim.y <span class="op">+</span> thread_idx.y</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> lx <span class="op">=</span> thread_idx.x</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> ly <span class="op">=</span> thread_idx.y</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>    const TILE_W <span class="op">=</span> TPB_X <span class="op">+</span> K <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>    const TILE_H <span class="op">=</span> TPB_Y <span class="op">+</span> K <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># allocate (main + halo) + kernel</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>    shared_img <span class="op">=</span> tb[dtype]().row_major[TILE_H, TILE_W]().shared().alloc()</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>    shared_k   <span class="op">=</span> tb[dtype]().row_major[K,K]().shared().alloc()</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1) bulk copy</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> gx <span class="op">&lt;</span> WIDTH <span class="op">&amp;&amp;</span> gy <span class="op">&lt;</span> HEIGHT:</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>        shared_img[ly, lx] <span class="op">=</span> inp[gy, gx]</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>        shared_img[ly, lx] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2) halo copy (strided so we cover the whole TILE_H/TILE_W)</span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">var</span> hy <span class="op">=</span> ly</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> hy <span class="op">&lt;</span> TILE_H:</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> hx <span class="op">=</span> lx</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>        <span class="kw">let</span> gy2 <span class="op">=</span> block_idx.y <span class="op">*</span> block_dim.y <span class="op">+</span> hy</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> hx <span class="op">&lt;</span> TILE_W:</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>            <span class="kw">let</span> gx2 <span class="op">=</span> block_idx.x <span class="op">*</span> block_dim.x <span class="op">+</span> hx</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>            shared_img[hy, hx] <span class="op">=</span> (</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>                inp[gy2, gx2] <span class="cf">if</span> (gy2 <span class="op">&lt;</span> HEIGHT <span class="op">&amp;&amp;</span> gx2 <span class="op">&lt;</span> WIDTH) <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>            hx <span class="op">+=</span> TPB_X</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>        hy <span class="op">+=</span> TPB_Y</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3) stash the kernel</span></span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ly <span class="op">&lt;</span> K <span class="op">&amp;&amp;</span> lx <span class="op">&lt;</span> K:</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>        shared_k[ly, lx] <span class="op">=</span> kernel[ly, lx]</span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>    barrier()  <span class="co"># sync both shared buffers</span></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4) compute 3×3 dot‐product</span></span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> gx <span class="op">&lt;</span> WIDTH <span class="op">&amp;&amp;</span> gy <span class="op">&lt;</span> HEIGHT:</span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> local_sum: Float32 <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>        <span class="at">@parameter</span> </span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> ky <span class="kw">in</span> <span class="bu">range</span>(K):</span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a>            <span class="at">@parameter</span> </span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> kx <span class="kw">in</span> <span class="bu">range</span>(K):</span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a>                local_sum <span class="op">+=</span> shared_img[ly <span class="op">+</span> ky, lx <span class="op">+</span> kx] <span class="op">*</span> shared_k[ky, kx]</span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a>        output[gy, gx] <span class="op">=</span> local_sum</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</details>
<p>After making a <a href="https://github.com/goodhamgupta/mojo-gpu-puzzles/commit/b7961ce0e5ea8753a866cbf671881ac1bdf4acd9">few changes</a> to the test harness, we get the following result:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p11 <span class="at">--conv-2d</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([9.0, 9.0, 9.0, 9.0, 9.0,...,6.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0])</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([9.0, 9.0, 9.0, 9.0, 9.0,..., 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We’ll dive into the shared memory tricks like parking partial results, handling 2-D thread and block indexing, and performing halo copies when we get to matrix multiply in <a href="@puzzle-14">Puzzle 14</a>.</p>
</section>
<section id="puzzle-12" class="level1">
<h1><a href="https://builds.modular.com/puzzles/puzzle_12/puzzle_12.html">Puzzle 12: Prefix Sum</a></h1>
<p>The <strong>prefix sum</strong> (or <em>scan</em>) problem takes an input array <code>[a₀, a₁, …, aₙ₋₁]</code> and produces the running totals</p>
<pre class="text"><code>[a₀, (a₀ ⊕ a₁), …, (a₀ ⊕ a₁ ⊕ … ⊕ aₙ₋₁)]</code></pre>
<p>It’s a foundational primitive in parallel computing-used for stream compaction, sorting, histograms, and more. At first glance, prefix sum looks inherently serial (each output depends on all previous inputs), but clever algorithms can parallelize it efficiently.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p12_prefix_scan.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" data-glightbox="description: .lightbox-desc-13" title="Prefix‐Sum Illustration"><img src="mojo_gpu_puzzles/p12_prefix_scan.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Prefix‐Sum Illustration"></a></p>
<figcaption>Prefix‐Sum Illustration</figcaption>
</figure>
</div>

<section id="hillis-steele-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="hillis-steele-algorithm">Hillis-Steele Algorithm</h2>
<p>A straightforward parallel scan is the <em>Hillis-Steele</em> approach: at each distance <code>d = 1, 2, 4, …</code> every element adds in the value from <code>d</code> positions back. This is the same as the method shown in <a href="#puzzle-10">Puzzle 10</a></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># inclusive scan, power-of-two length</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> hillis_steele_scan(a, ⊕):</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(a)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    temp <span class="op">=</span> a.copy()</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> d <span class="op">&lt;</span> n:</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>            temp[i] <span class="op">=</span> a[i] <span class="cf">if</span> i <span class="op">&lt;</span> d <span class="cf">else</span> a[i <span class="op">-</span> d] ⊕ a[i]</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        a, temp <span class="op">=</span> temp, a</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>        d <span class="op">*=</span> <span class="dv">2</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In Mojo, this looks as follows:</p>
<details open="">
<summary>
<strong>Solution</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p12_simple.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb22" data-filename="p12_simple.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> prefix_sum_simple[</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    layout: Layout</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    output: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    global_i <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    local_i <span class="op">=</span> thread_idx.x</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(Int(log2(Scalar[dtype](TPB)))):</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> local_i <span class="op">&gt;=</span> offset <span class="kw">and</span> local_i <span class="op">&lt;</span> SIZE:</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>            shared[local_i] <span class="op">+=</span> shared[local_i <span class="op">-</span> offset]</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>        barrier()</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>        offset <span class="op">*=</span> <span class="dv">2</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> SIZE:</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>        output[global_i] <span class="op">=</span> shared[local_i]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb23"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p12 <span class="at">--simple</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([0.0, 1.0, 3.0, 6.0, 10.0, 15.0, 21.0, 28.0])</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([0.0, 1.0, 3.0, 6.0, 10.0, 15.0, 21.0, 28.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Each of the log₂(n) rounds does up to n parallel additions (one per active element), so total work is <span class="math inline">\(\sum_k n = nlog(n)\)</span>. Because rounds are serialized by barriers, the longest dependency chain is one add per round i.e <span class="math inline">\(O(log n)\)</span>.</p>
</details></section>
<section id="blellochs-twopass-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="blellochs-twopass-algorithm">Blelloch’s Two‐Pass Algorithm</h2>
<p>Blelloch’s two-pass scan does Θ(n) work by splitting the job into an <strong>up-sweep</strong> (build a reduction tree) and a <strong>down-sweep</strong> (propagate prefixes) <span class="citation" data-cites="blelloch_prefix_sum"><a href="#ref-blelloch_prefix_sum" role="doc-biblioref">[11]</a></span>.</p>
<p>Why prefer it over the classic Hillis-Steele (Algorithm 1)?</p>
<ol type="1">
<li><p>Hardware constraints: Hillis-Steele assumes one processor per element and updates the array <em>in-place</em> every round. A real GPU doesn’t grant that luxury: a “1024-thread” block actually runs in 32-thread warps that time-slice on the same SM. When warp 0 pauses and warp 1 resumes, in-place writes from one warp can overwrite data the other still needs.</p></li>
<li><p>Synchronisation cost: Avoiding the overwrite requires a barrier after <strong>every</strong> addition - log₂(n) rounds × n threads ⇒ Θ(n log n) operations plus all those barriers.</p></li>
</ol>
<p>Blelloch’s fix to these problems is to break the up-sweep and down-sweep into separate phases:</p>
<ul>
<li>Up-sweep and down-sweep touch disjoint tree levels, so threads never trample each other within a phase.</li>
<li>Only two global barriers are needed (one between the phases, one at the end).</li>
<li>Now you get Θ(n) work and correctness, even for arrays much bigger than a warp.</li>
</ul>
<p>The result is a scan that is both faster and safer on modern GPUs.</p>
<section id="up-sweep-reduce" class="level3">
<h3 class="anchored" data-anchor-id="up-sweep-reduce">Up-sweep (reduce)</h3>
<ul>
<li>Build a binary reduction tree over log₂(n) rounds:
<ul>
<li>Round 1 (step=1): sum each adjacent pair, storing results at indices 1, 3, 5, …</li>
<li>Round 2 (step=2): merge those partial sums into blocks of 4, writing into indices 3, 7, 11, …</li>
<li>Continue doubling the span each round until step = n/2</li>
</ul></li>
<li>After the final round, a[n-1] holds the overall total</li>
</ul>
<p><img src="mojo_gpu_puzzles/p12_up.gif" class="img-fluid"> <em>Up-Sweep: combining elements in a binary-tree fashion-build partial sums until the final element holds the total.</em></p>
</section>
<section id="down-sweep-propagate" class="level3">
<h3 class="anchored" data-anchor-id="down-sweep-propagate">Down-sweep (propagate)</h3>
<p>After the up-sweep leaves <code>a[n-1]</code> containing the overall sum, we walk the tree top-down to scatter prefix sums into every slot:</p>
<ul>
<li>Initialize the down-sweep with a window size of <code>step = n/2</code>.<br>
</li>
<li>Loop as long as <code>step &gt;= 1</code>:
<ul>
<li>Partition the array into blocks of size <code>2*step</code>. For each block starting at index <code>i</code>:
<ul>
<li>Temporarily store the left-child total from <code>a[i + step - 1]</code>.<br>
</li>
<li>Overwrite that left slot with the right-child subtotal from <code>a[i + 2*step - 1]</code>.<br>
</li>
<li>Add the saved left-child total to the right slot, giving the correct prefix for that subtree.<br>
</li>
</ul></li>
<li>Issue a <code>barrier()</code> so all threads sync before shrinking the window.<br>
</li>
<li>Halve the window: <code>step = step / 2</code>.<br>
</li>
</ul></li>
<li>With each pass, the partial sums trickle down one level of the binary tree; after log₂(n) iterations every element holds its exclusive prefix sum.</li>
</ul>
<p><img src="mojo_gpu_puzzles/p12_down.gif" class="img-fluid quarto-figure quarto-figure-center"><br>
<em>Down Sweep: siblings swap and accumulate, driving the scan from root back to leaves.</em></p>
<p>Total Operations: <span class="math inline">\(\Theta(n)\)</span>, parallel depth: <span class="math inline">\(\Theta(\log_2 n)\)</span>.</p>
<details open="">
<summary>
<strong>Solution (Blelloch up-sweep + down-sweep)</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p12_blelloch.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb24" data-filename="p12_blelloch.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> prefix_sum_blelloch[</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    layout: Layout</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    output:   LayoutTensor[mut<span class="op">=</span><span class="va">True</span>, dtype, layout],</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    a:     LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    size:  Int,</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    global_idx <span class="op">=</span> block_idx.x<span class="op">*</span>block_dim.x <span class="op">+</span> thread_idx.x</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    local_idx <span class="op">=</span> thread_idx.x</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    shared <span class="op">=</span> tb[dtype]().row_major[SIZE]().shared().alloc()</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_idx <span class="op">&lt;</span> size:</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>        shared[local_idx] <span class="op">=</span> a[global_idx]</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Up-sweep</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">var</span> stride <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> stride <span class="op">&lt;</span> size:</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>        step <span class="op">=</span> stride <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (local_idx <span class="op">%</span> step <span class="op">==</span> step <span class="op">-</span> <span class="dv">1</span>) <span class="kw">and</span> (local_idx <span class="op">&lt;</span> size):</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>            shared[local_idx] <span class="op">+=</span> shared[local_idx <span class="op">-</span> stride]</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>        barrier()</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>        stride <span class="op">=</span> step</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Down-sweep</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_idx <span class="op">==</span> size <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>        shared[local_idx] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">var</span> half <span class="op">=</span> stride <span class="op">&gt;&gt;</span> <span class="dv">1</span></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> half <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>        step <span class="op">=</span> half <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (local_idx <span class="op">%</span> step <span class="op">==</span> step <span class="op">-</span> <span class="dv">1</span>) <span class="kw">and</span> (local_idx <span class="op">&lt;</span> size):</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>            t <span class="op">=</span> shared[local_idx <span class="op">-</span> half]</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>            shared[local_idx <span class="op">-</span> half] <span class="op">=</span> shared[local_idx]</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>            shared[local_idx] <span class="op">+=</span> t</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>        barrier()</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>        half <span class="op">=</span> half <span class="op">&gt;&gt;</span> <span class="dv">1</span></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_idx <span class="op">&lt;</span> size:</span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>        output[global_idx] <span class="op">=</span> shared[local_idx] <span class="op">+</span> a[global_idx]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb25"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p12 <span class="at">--blelloch</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([0.0, 1.0, 3.0, 6.0, 10.0, 15.0, 21.0, 28.0])</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([0.0, 1.0, 3.0, 6.0, 10.0, 15.0, 21.0, 28.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<p>This is not the most efficient implementation, but I hope this provides some intuition about the algorithm!</p>
</section>
</section>
<section id="block-boundary-1" class="level2">
<h2 class="anchored" data-anchor-id="block-boundary-1">Block Boundary</h2>
<p>The key difference in this version is that now we have an input array that is larger than the size of a single block.</p>
<p>We split the global scan into two bite-sized passes:</p>
<section id="phase-1---local-scan" class="level3">
<h3 class="anchored" data-anchor-id="phase-1---local-scan">Phase 1 - Local Scan</h3>
<ol type="1">
<li><p>Each block copies its slice into shared memory.<br>
</p></li>
<li><p>Perform an in-block naive scan/Blelloch scan exactly as in the single-block case.<br>
</p></li>
<li><p>The last thread of the block stashes the block’s total <strong>after</strong> the scan into an auxiliary slot at the tail of <code>output</code>:</p>
<pre><code>#  |&lt;---  SIZE_2  ---&gt;|&lt;-- #blocks --&gt;|
#  [   prefix sums   ][ block totals ]</code></pre></li>
</ol>
</section>
<section id="phase-2---propagate-block-totals" class="level3">
<h3 class="anchored" data-anchor-id="phase-2---propagate-block-totals">Phase 2 - Propagate block totals</h3>
<ol type="1">
<li>Every thread grabs the aggregate from the <em>previous</em> block (<code>totals[block_id-1]</code>) and adds it to its own prefix.<br>
Now every element holds the inclusive scan over the <em>whole</em> array.</li>
</ol>
<p><a href="mojo_gpu_puzzles/p12_block_boundary.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="mojo_gpu_puzzles/p12_block_boundary.png" class="img-fluid"></a></p>
<p>We launch the above phases as two separate kernels.</p>
<p><strong>A host-side synchronisation sits between the launches</strong>. That call flushes the work queue and waits until Phase 1 has fully committed its writes to global memory, ensuring the per-block totals are complete and visible before Phase 2 starts consuming them. Skip the sync and the driver is free to overlap or reorder the kernels, letting Phase 2 read garbage.</p>
<details open="">
<summary>
<strong>Solution (Block Boundary Version)</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p12_block_boundary.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb27" data-filename="p12_block_boundary.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> prefix_sum_local_phase[</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    out_layout: Layout, in_layout: Layout</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    output: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, out_layout],</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, in_layout],</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    global_i <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    local_i <span class="op">=</span> thread_idx.x</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    shared <span class="op">=</span> tb[dtype]().row_major[EXTENDED_SIZE]().shared().alloc()</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> SIZE_2:</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>        shared[local_i] <span class="op">=</span> a[global_i]</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>    offset <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(Int(log2(Scalar[dtype](TPB)))):</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> local_i <span class="op">&gt;=</span> offset <span class="kw">and</span> local_i <span class="op">&lt;</span> SIZE_2:</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>            shared[local_i] <span class="op">+=</span> shared[local_i <span class="op">-</span> offset]</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>        barrier()</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>        offset <span class="op">*=</span> <span class="dv">2</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> global_i <span class="op">&lt;</span> SIZE_2:</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>        output[global_i] <span class="op">=</span> shared[local_i]</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_i <span class="op">==</span> TPB <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>        output[size <span class="op">+</span> block_idx.x] <span class="op">+=</span> shared[local_i]</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Kernel 2: Add block sums to their respective blocks</span></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> prefix_sum_block_sum_phase[</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>    layout: Layout</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>](output: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout], size: Int):</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>    global_i <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># FILL ME IN (roughly 3 lines)</span></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> block_idx.x <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> global_i <span class="op">&lt;</span> size:</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>        prev_block_sum <span class="op">=</span> output[SIZE_2 <span class="op">+</span> block_idx.x <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>        output[global_i] <span class="op">+=</span> prev_block_sum</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb28"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p12</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([0.0, 1.0, 3.0, 6.0, 10.0, 15.0, 21.0, 28.0, 36.0, 45.0, 55.0, 66.0, 78.0, 91.0, 105.0, 28.0, 77.0]) # last 2 elements are the block sums</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([0.0, 1.0, 3.0, 6.0, 10.0, 15.0, 21.0, 28.0, 36.0, 45.0, 55.0, 66.0, 78.0, 91.0, 105.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
</section>
</section>
<section id="puzzle-13-axis-sum" class="level1">
<h1><a href="https://puzzles.modular.com/puzzle_13/puzzle_13.html" id="puzzle-13">Puzzle 13: Axis Sum</a></h1>
<p>Axis sum is the 2-D sibling of the dot‐product/prefix puzzles: take a matrix <code>A</code> and collapse one dimension by summing over it.</p>
<p><span class="math display">\[
\begin{aligned}
\text{axis}=0 &amp;\;\Longrightarrow\;
\text{column-sum:}\;\;
out[j] &amp; = \sum_{k} A_{k,j}, \qquad j = 0,\dots,N-1 \\[4pt]
\text{axis}=1 &amp;\;\Longrightarrow\;
\text{row-sum:}\;\;
out[i] &amp; = \sum_{k} A_{i,k}, \qquad i = 0,\dots,M-1
\end{aligned}
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p13_intro.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15" data-glightbox="description: .lightbox-desc-15" title="Axis Sum"><img src="mojo_gpu_puzzles/p13_intro.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%" alt="Axis Sum"></a></p>
<figcaption>Axis Sum</figcaption>
</figure>
</div>
<p>Each row/column is an embarrassingly-parallel reduction, so the GPU kernel just assigns one warp (or block) per slice and performs a standard shared-memory reduction inside the slice.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p13_row_sum.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16" data-glightbox="description: .lightbox-desc-16" title="Row Sum"><img src="mojo_gpu_puzzles/p13_row_sum.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Row Sum"></a></p>
<figcaption>Row Sum</figcaption>
</figure>
</div>
<details open="">
<summary>
Solution
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p13.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb29" data-filename="p13.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> axis_sum[</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    in_layout: Layout, out_layout: Layout</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    output: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, out_layout],</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, in_layout],</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    size: Int,</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    local_i <span class="op">=</span> thread_idx.x</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    batch <span class="op">=</span> block_idx.y</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    shared <span class="op">=</span> tb[dtype]().row_major[TPB]().shared().alloc()</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_i <span class="op">&lt;</span> SIZE:</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>        shared[local_i] <span class="op">=</span> a[batch, local_i]</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">var</span> stride <span class="op">=</span> TPB <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> stride <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> local_i <span class="op">&lt;</span> stride <span class="kw">and</span> local_i <span class="op">+</span> stride <span class="op">&lt;</span> SIZE:</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>            shared[local_i] <span class="op">+=</span> shared[local_i <span class="op">+</span> stride]</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>        barrier()</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>        stride <span class="op">//=</span> <span class="dv">2</span></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use first thread to write result</span></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_i <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Output shape is [batch_size, 1]</span></span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># which we why we need the last dimension</span></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>        output[batch, <span class="dv">0</span>] <span class="op">=</span> shared[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb30"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p13</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<p>We can also perform column-sum(axis=0) with a trivial change:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode diff code-with-copy"><code class="sourceCode diff"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="st">-    if local_i &lt; SIZE:</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="st">-        shared[local_i] = a[batch, local_i]</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="va">+    if local_i &lt; SIZE:</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="va">+        shared[local_i] = a[local_i, batch]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="puzzle-14-matmul" class="level1">
<h1><a href="https://puzzles.modular.com/puzzle_14/puzzle_14.html" id="puzzle-14">Puzzle 14: Matmul</a></h1>
<p>Arguably the single most important operation in GPU computing, the humble General Matrix Multiplication (GEMM) operation is the computational workhorse behind literally all deep learning models-from simple linear layers to massive transformer architectures.</p>
<p><span class="math display">\[
C_{i,j} = \sum_{k=1}^{K} A_{i,k} \cdot B_{k,j}
\]</span></p>
<blockquote class="blockquote">
<p><strong>Requirement:</strong> For matrix multiplication <span class="math inline">\(C = AB\)</span> to be valid, the number of columns in <span class="math inline">\(A\)</span> must equal the number of rows in <span class="math inline">\(B\)</span>.<br>
That is, if <span class="math inline">\(A\)</span> is shape <span class="math inline">\((M, K)\)</span> and <span class="math inline">\(B\)</span> is shape <span class="math inline">\((K, N)\)</span>, then <span class="math inline">\(C\)</span> will be shape <span class="math inline">\((M, N)\)</span>.</p>
</blockquote>
<p>GEMM’s ubiquity stems from its perfect match with GPU architecture: thousands of independent multiply-add operations that can be parallelized across thousands of cores. Yet this apparent simplicity masks a deep optimization challenge. Memory bandwidth, cache hierarchies, and thread synchronization all conspire to make naive implementations crawl while hand-tuned libraries like cuBLAS achieve near-theoretical peak performance.</p>
<p>Matmul tuning is a rabbit hole - see Simon Boehm’s fantastic deep-dive <span class="citation" data-cites="siboehm_cuda_mmm"><a href="#ref-siboehm_cuda_mmm" role="doc-biblioref">[12]</a></span> for how wild it gets.</p>
<p>For now, we’ll focus on the core techniques demonstrated by the official puzzle-shared memory tiling and thread cooperation-to build intuition for how high-performance GEMM kernels actually work.</p>
<section id="global-memory-version" class="level2">
<h2 class="anchored" data-anchor-id="global-memory-version">Global Memory Version</h2>
<p>Based on the <a href="#indexing">2D indexing</a> section, each thread computes one C[row, col] by loading A[row, k] and B[k, col] from global memory, multiplying and accumulating over k. We unroll the k‐loop to cut loop overhead and boost throughput.</p>
<details open="">
<summary>
Solution
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p14_naive.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb32" data-filename="p14_naive.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> naive_matmul[</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    layout: Layout, size: Int</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    output: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    b: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> block_dim.y <span class="op">*</span> block_idx.y <span class="op">+</span> thread_idx.y</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>    col <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> row <span class="op">&lt;</span> SIZE <span class="kw">and</span> col <span class="op">&lt;</span> SIZE:</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Need this to ensure the mojo compiler knows</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the type of `running_sum`, otherwise it will</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># complain</span></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> running_sum: output.element_type <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>        <span class="at">@parameter</span></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(SIZE):</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>            running_sum <span class="op">+=</span> a[row, k] <span class="op">*</span> b[k, col]</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>        output[row, col] <span class="op">=</span> running_sum</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb33"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p14 <span class="at">--naive</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([4.0, 6.0, 12.0, 22.0])</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([4.0, 6.0, 12.0, 22.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
<section id="shared-memory-version" class="level2">
<h2 class="anchored" data-anchor-id="shared-memory-version">Shared Memory Version</h2>
<p>The previous version suffers from repeated global memory reads. We can optimize this using shared memory:</p>
<ul>
<li>Load matrix tiles once</li>
<li>Synchronize threads</li>
<li>Compute using the cached data.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p14_shared_mem.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17" data-glightbox="description: .lightbox-desc-17" title="Matmul with shared memory"><img src="mojo_gpu_puzzles/p14_shared_mem.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Matmul with shared memory"></a></p>
<figcaption>Matmul with shared memory</figcaption>
</figure>
</div>
<details open="">
<summary>
Solution
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p14_shared.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb34" data-filename="p14_shared.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> single_block_matmul[</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>    layout: Layout, size: Int</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    output: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>    b: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> block_dim.y <span class="op">*</span> block_idx.y <span class="op">+</span> thread_idx.y</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>    col <span class="op">=</span> block_dim.x <span class="op">*</span> block_idx.x <span class="op">+</span> thread_idx.x</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>    local_row <span class="op">=</span> thread_idx.y</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>    local_col <span class="op">=</span> thread_idx.x</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>    shared_a <span class="op">=</span> tb[dtype]().row_major[TPB, TPB]().shared().alloc()</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>    shared_b <span class="op">=</span> tb[dtype]().row_major[TPB, TPB]().shared().alloc()</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> row <span class="op">&lt;</span> size <span class="kw">and</span> col <span class="op">&lt;</span> size <span class="kw">and</span> local_row <span class="op">&lt;</span> size <span class="kw">and</span> local_col <span class="op">&lt;</span> size:</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>        shared_a[local_row, local_col] <span class="op">=</span> a[row, col]</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>        shared_b[local_row, local_col] <span class="op">=</span> b[row, col]</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>    barrier()</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> row <span class="op">&lt;</span> size <span class="kw">and</span> col <span class="op">&lt;</span> size <span class="kw">and</span> local_row <span class="op">&lt;</span> size <span class="kw">and</span> local_col <span class="op">&lt;</span> size:</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> running_sum: output.element_type <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>        <span class="at">@parameter</span></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(size):</span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>            running_sum <span class="op">+=</span> a[local_row, k] <span class="op">*</span> b[k, local_col]</span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a>        output[row, col] <span class="op">=</span> running_sum</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb35"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p14 <span class="at">--naive</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([4.0, 6.0, 12.0, 22.0])</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([4.0, 6.0, 12.0, 22.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The Roofline Model offers a first-order answer to a GPU performance question: is my kernel limited by arithmetic throughput or by memory bandwidth?<br>
It does so by plotting operational intensity (FLOPs per byte) against two ceilings - the hardware’s peak FLOP/s and peak DRAM bandwidth—so you can see at a glance which resource is the bottleneck.</p>
</details></section>
<section id="roofline-model" class="level2">
<h2 class="anchored" data-anchor-id="roofline-model"><a href="https://builds.modular.com/puzzles/puzzle_14/roofline.html">Roofline Model</a></h2>
<blockquote class="blockquote">
<p>Note: The Modular GPU Puzzles <a href="https://builds.modular.com/puzzles/puzzle_14/roofline.html">guide</a> already walks through the full roofline derivation, but we’ll repeat it here so that you can follow along without leaving this post.</p>
</blockquote>
<p>The first step is abstracting the hardware-software complexity into a tractable model.</p>
<section id="hardware-model" class="level3">
<h3 class="anchored" data-anchor-id="hardware-model">Hardware Model</h3>
<p>Classic roofline assumes ideal hardware with perfect overlap:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p14_hardware.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18" data-glightbox="description: .lightbox-desc-18" title="Source: NHR at FAU[@nhrfau_roofline_model]"><img src="mojo_gpu_puzzles/p14_hardware.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%" alt="Source: NHR at FAU[13]"></a></p>
<figcaption>Source: NHR at FAU<span class="citation" data-cites="nhrfau_roofline_model"><a href="#ref-nhrfau_roofline_model" role="doc-biblioref">[13]</a></span></figcaption>
</figure>
</div>
<p>The cartoon GPU has only two levers:</p>
<ul>
<li><strong>Compute engine</strong> — peak rate <span class="math inline">\(P_{peak}\)</span> (FLOP/s, integer ops/s, etc.)</li>
<li><strong>Memory datapath</strong> — peak bandwidth <span class="math inline">\(b_s\)</span> (bytes/s)</li>
</ul>
</section>
<section id="software-model" class="level3">
<h3 class="anchored" data-anchor-id="software-model">Software Model</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p14_software.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19" data-glightbox="description: .lightbox-desc-19" title="Software abstraction: complex GPU kernel simplified to steady-state loop with N flops and V bytes per iteration. Credits: NHR at FAU[@nhrfau_roofline_model]"><img src="mojo_gpu_puzzles/p14_software.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%" alt="Software abstraction: complex GPU kernel simplified to steady-state loop with N flops and V bytes per iteration. Credits: NHR at FAU[13]"></a></p>
<figcaption>Software abstraction: complex GPU kernel simplified to steady-state loop with N flops and V bytes per iteration. Credits: NHR at FAU<span class="citation" data-cites="nhrfau_roofline_model"><a href="#ref-nhrfau_roofline_model" role="doc-biblioref">[13]</a></span></figcaption>
</figure>
</div>
<p>We collapse the kernel’s steady-state loop to:</p>
<ul>
<li><span class="math inline">\(N\)</span> floating-point operations per iteration</li>
<li><span class="math inline">\(V\)</span> bytes moved per iteration</li>
</ul>
<p>The <strong>operational intensity</strong> is defined as:</p>
<p><span class="math display">\[I = \frac{N}{V} \text{ flop/byte}\]</span></p>
<p>This ratio is all that survives of the algorithm - prologue/epilogue work, control flow, and synchronizations are swept aside.</p>
<p><strong>Hardware Assumptions:</strong></p>
<table class="table">
<colgroup>
<col style="width: 5%">
<col style="width: 22%">
<col style="width: 29%">
<col style="width: 16%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>#</th>
<th>Assumption</th>
<th>Works because…</th>
<th>Reality</th>
<th>Breaks when…</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>H1</td>
<td>Peak DRAM bandwidth is reachable</td>
<td>Ideal streaming</td>
<td>Requires 100% streaming, &gt;1MB tiles</td>
<td>Strided or tiny tiles</td>
</tr>
<tr class="even">
<td>H2</td>
<td>Peak FLOP/s reachable</td>
<td>Full FMA rate</td>
<td>All ALUs busy every cycle</td>
<td>Divergence, low occupancy</td>
</tr>
<tr class="odd">
<td>H3</td>
<td>One bandwidth number is enough</td>
<td>DRAM dominates</td>
<td>L1/L2/SMEM add separate roofs</td>
<td>Lower-level choke points</td>
</tr>
</tbody>
</table>
<p><strong>Software Assumptions:</strong></p>
<table class="table">
<colgroup>
<col style="width: 5%">
<col style="width: 22%">
<col style="width: 29%">
<col style="width: 16%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>#</th>
<th>Assumption</th>
<th>Works because…</th>
<th>Reality</th>
<th>Breaks when…</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>S1</td>
<td>Loads fully hide latency</td>
<td>1000s inflight warps</td>
<td>Requires deep pipelining</td>
<td>Short kernels, frequent syncs</td>
</tr>
<tr class="even">
<td>S2</td>
<td>Single operational intensity</td>
<td>Steady-state loop</td>
<td>Real kernels mix phases</td>
<td>Gather/scatter, epilogue code</td>
</tr>
<tr class="odd">
<td>S3</td>
<td>Launch/transfer overhead small</td>
<td>Long kernel runs</td>
<td>Amortised over many iterations</td>
<td>Micro-benchmarks, chaining</td>
</tr>
</tbody>
</table>
</section>
<section id="naive-roofline-model" class="level3">
<h3 class="anchored" data-anchor-id="naive-roofline-model">Naive Roofline Model</h3>
<p>With these assumptions, hardware and software collapse to one parameter—the operational intensity <span class="math inline">\(I\)</span>—and attainable performance becomes</p>
<p><span class="math display">\[
\begin{aligned}
P(I) &amp;= \min\!\bigl(P_{\text{peak}},\, I\,b_s\bigr) \\
I_{\text{crit}} &amp;= \frac{P_{\text{peak}}}{b_s}
\end{aligned}
\]</span></p>
<p>At the critical intensity <span class="math inline">\(I_{crit}\)</span>, the bandwidth and compute roofs intersect, splitting kernels into two classes:</p>
<ul>
<li><strong>Memory-bound</strong> (<span class="math inline">\(I &lt; I_{crit}\)</span>) -&gt; Performance rises linearly with <span class="math inline">\(I\)</span></li>
<li><strong>Compute-bound</strong> (<span class="math inline">\(I \geq I_{crit}\)</span>) -&gt; Performance plateaus at <span class="math inline">\(P_{peak}\)</span></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p14_roofline.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20" data-glightbox="description: .lightbox-desc-20" title="Roofline model: sloped red line shows memory bandwidth limit, flat blue line is compute peak, kernel’s operational intensity marked as a dot."><img src="mojo_gpu_puzzles/p14_roofline.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%" alt="Roofline model: sloped red line shows memory bandwidth limit, flat blue line is compute peak, kernel’s operational intensity marked as a dot."></a></p>
<figcaption>Roofline model: sloped red line shows memory bandwidth limit, flat blue line is compute peak, kernel’s operational intensity marked as a dot.</figcaption>
</figure>
</div>
</section>
<section id="where-the-roofline-model-fails" class="level3">
<h3 class="anchored" data-anchor-id="where-the-roofline-model-fails">Where the Roofline Model Fails</h3>
<p>Even in small puzzle kernels, these assumptions falter. In real workloads, they break down completely.</p>
<p>What actually works:</p>
<ol type="1">
<li><strong>Measure real limits</strong> with tools like Nsight or rocprof</li>
<li><strong>Redraw the roofline</strong> using measured ceilings—L2 roof, Tensor-core roof, not just DRAM and peak FLOPs</li>
<li><strong>Adjust your kernel</strong>: boost <span class="math inline">\(I\)</span> (tiling, shared memory, tensor ops) or raise the ceilings (improve occupancy, reduce stalls)</li>
</ol>
<blockquote class="blockquote">
<p>Unfortunately no Nsight eye-candy as of yet - my <code>ncu</code> setup hit a <a href="https://developer.nvidia.com/nvidia-development-tools-solutions-err_nvgpuctrperm-permission-issue-ters">permissions wall</a>. I’ll fix it and share a profiler deep-dive soon. Stay tuned!</p>
</blockquote>
<p>The textbook roofline is a guide, not reality. Measure, adapt, and push your kernel as close to the real limits as you can.</p>
</section>
</section>
<section id="roofline-estimation" class="level2">
<h2 class="anchored" data-anchor-id="roofline-estimation">Roofline Estimation</h2>
<p>Let’s apply the roofline model to a 3×3 matrix multiplication, which is still small enough to hand-calculate.</p>
<p>The RTX 4000 Ada provides<span class="citation" data-cites="rtx_ada_specs"><a href="#ref-rtx_ada_specs" role="doc-biblioref">[14]</a></span>:</p>
<ul>
<li><strong>Peak compute</strong>: 26.7 TFLOPS (single-precision)<br>
</li>
<li><strong>Peak DRAM bandwidth</strong>: 360 GB/s<br>
</li>
<li><strong>Critical intensity</strong>: <span class="math inline">\(I_{crit} = \frac{26.7 \times 10^{12}}{360 \times 10^9} = 74.2\)</span> FLOP/byte</li>
</ul>
<section id="naive-matmul-analysis" class="level3">
<h3 class="anchored" data-anchor-id="naive-matmul-analysis">Naive MatMul Analysis</h3>
<p>For <span class="math inline">\(C = A \times B\)</span> where all matrices are 3×3:</p>
<section id="compute-work" class="level4">
<h4 class="anchored" data-anchor-id="compute-work">Compute work</h4>
<ul>
<li>Each output element is a dot product of length 3</li>
<li>3 fused multiply-adds -&gt; 3 FLOPs per output element</li>
<li>9 elements -&gt; 27 FLOPs total</li>
</ul>
</section>
<section id="dram-traffic" class="level4">
<h4 class="anchored" data-anchor-id="dram-traffic">DRAM traffic</h4>
<ul>
<li>Load matrix A: 9 floats × 4 bytes = 36 bytes</li>
<li>Load matrix B: 9 floats × 4 bytes = 36 bytes<br>
</li>
<li>Store matrix C: 9 floats × 4 bytes = 36 bytes</li>
<li>Total: <strong>108 bytes</strong></li>
</ul>
</section>
<section id="operational-intensity" class="level4">
<h4 class="anchored" data-anchor-id="operational-intensity">Operational intensity:</h4>
<p><span class="math display">\[I_{naive} = \frac{27 \text{ FLOPs}}{108 \text{ bytes}} = 0.25 \text{ FLOP/byte}\]</span></p>
<p>Since <span class="math inline">\(I_{naive} = 0.25 \ll I_{crit} = 74.2\)</span>, this kernel is <strong>memory-bound</strong>.</p>
</section>
<section id="predicted-performance" class="level4">
<h4 class="anchored" data-anchor-id="predicted-performance">Predicted performance</h4>
<p><span class="math display">\[
\begin{aligned}
P_{naive} \;\; &amp; = \min(26.7~\text{TFLOPS},\; 0.25 \times 360~\text{GB/s}) \\
               &amp; = \min(26.7~\text{TFLOPS},\; 90~\text{GFLOPS}) \\
               &amp; = \boxed{90~\text{GFLOPS}}
\end{aligned}
\]</span></p>
</section>
</section>
<section id="shared-memory-optimization" class="level3">
<h3 class="anchored" data-anchor-id="shared-memory-optimization">Shared Memory Optimization</h3>
<p>By staging 3×3 tiles of A and B in shared memory, each element feeds all three required dot products instead of being fetched repeatedly from DRAM.</p>
<section id="improved-traffic-pattern" class="level4">
<h4 class="anchored" data-anchor-id="improved-traffic-pattern">Improved traffic pattern</h4>
<ul>
<li>DRAM loads for A and B drop by ~3×</li>
<li>Stores remain unchanged (36 bytes)</li>
<li>Approximate traffic: <span class="math inline">\((36+36)/3 + 36 = 60\)</span> bytes</li>
</ul>
</section>
<section id="new-operational-intensity" class="level4">
<h4 class="anchored" data-anchor-id="new-operational-intensity">New operational intensity</h4>
<p><span class="math display">\[I_{shared} = \frac{27 \text{ FLOPs}}{60 \text{ bytes}} = 0.45 \text{ FLOP/byte}\]</span></p>
</section>
<section id="predicted-performance-1" class="level4">
<h4 class="anchored" data-anchor-id="predicted-performance-1">Predicted performance</h4>
<p><span class="math display">\[
\begin{aligned}
P_{shared} \;\; &amp; = \min(26.7~\text{TFLOPS},\; 0.45 \times 360~\text{GB/s}) \\
                &amp; = \min(26.7~\text{TFLOPS},\; 162~\text{GFLOPS}) \\
                &amp; = \boxed{162~\text{GFLOPS}}
\end{aligned}
\]</span></p>
<p>This gives us a <strong>1.8× speedup</strong> from shared memory optimization, but we’re still memory-bound.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p14_roofline_naive_and_shared.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21" data-glightbox="description: .lightbox-desc-21" title="RTX 4000 Ada Roofline for Matmul"><img src="mojo_gpu_puzzles/p14_roofline_naive_and_shared.png" class="img-fluid figure-img" alt="RTX 4000 Ada Roofline for Matmul"></a></p>
<figcaption>RTX 4000 Ada Roofline for Matmul</figcaption>
</figure>
</div>
<details closed="">
<summary>
<strong>Plot Code</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>roofline_plot.py</strong></pre>
</div>
<div class="sourceCode" id="cb36" data-filename="roofline_plot.py"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># /// script</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="co"># dependencies = [</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co">#   "matplotlib",</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   "numpy",</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ]</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ///</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Run using uv run roofline_plot.py</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>peak_compute <span class="op">=</span> <span class="fl">26.7</span> <span class="op">*</span> <span class="dv">1000</span>  <span class="co"># Convert to GFLOPS</span></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>peak_bandwidth <span class="op">=</span> <span class="dv">360</span>  <span class="co"># GB/s</span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>critical_intensity <span class="op">=</span> peak_compute <span class="op">/</span> peak_bandwidth</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>kernels <span class="op">=</span> [</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"name"</span>: <span class="st">"Naive 3×3"</span>, <span class="st">"intensity"</span>: <span class="fl">0.25</span>, <span class="st">"performance"</span>: <span class="dv">90</span>, <span class="st">"color"</span>: <span class="st">"#f39c12"</span>},</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"name"</span>: <span class="st">"Shared 3×3"</span>, <span class="st">"intensity"</span>: <span class="fl">0.45</span>, <span class="st">"performance"</span>: <span class="dv">162</span>, <span class="st">"color"</span>: <span class="st">"#27ae60"</span>}</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_roofline_data():</span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Memory-bound region</span></span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>    memory_intensities <span class="op">=</span> np.arange(<span class="fl">0.01</span>, critical_intensity, <span class="fl">0.05</span>)</span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>    memory_performance <span class="op">=</span> memory_intensities <span class="op">*</span> peak_bandwidth</span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute-bound region</span></span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>    compute_intensities <span class="op">=</span> np.arange(critical_intensity, <span class="dv">1000</span>, <span class="dv">5</span>)</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>    compute_performance <span class="op">=</span> np.full_like(compute_intensities, peak_compute)</span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> memory_intensities, memory_performance, compute_intensities, compute_performance</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="fl">6.5</span>))</span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a>ax.set_xscale(<span class="st">'log'</span>, base<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a>ax.set_yscale(<span class="st">'log'</span>, base<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a>mem_i, mem_p, comp_i, comp_p <span class="op">=</span> generate_roofline_data()</span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a>ax.loglog(mem_i, mem_p, color<span class="op">=</span><span class="st">"#e74c3c"</span>, linewidth<span class="op">=</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">"Memory-bound"</span>)</span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a>ax.loglog(comp_i, comp_p, color<span class="op">=</span><span class="st">"#3498db"</span>, linewidth<span class="op">=</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">"Compute-bound"</span>)</span>
<span id="cb36-41"><a href="#cb36-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-42"><a href="#cb36-42" aria-hidden="true" tabindex="-1"></a>ax.axhline(y<span class="op">=</span>peak_compute, color<span class="op">=</span><span class="st">"#3498db"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-43"><a href="#cb36-43" aria-hidden="true" tabindex="-1"></a>ax.axvline(x<span class="op">=</span>critical_intensity, color<span class="op">=</span><span class="st">"#999"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-44"><a href="#cb36-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-45"><a href="#cb36-45" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> kernel <span class="kw">in</span> kernels:</span>
<span id="cb36-46"><a href="#cb36-46" aria-hidden="true" tabindex="-1"></a>    ax.loglog(kernel[<span class="st">"intensity"</span>], kernel[<span class="st">"performance"</span>],</span>
<span id="cb36-47"><a href="#cb36-47" aria-hidden="true" tabindex="-1"></a>             <span class="st">'o'</span>, color<span class="op">=</span>kernel[<span class="st">"color"</span>], markersize<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb36-48"><a href="#cb36-48" aria-hidden="true" tabindex="-1"></a>             markeredgecolor<span class="op">=</span><span class="st">"#333"</span>, markeredgewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb36-49"><a href="#cb36-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-50"><a href="#cb36-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add kernel labels with better positioning to avoid overlap</span></span>
<span id="cb36-51"><a href="#cb36-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> kernel[<span class="st">"name"</span>] <span class="op">==</span> <span class="st">"Naive 3×3"</span>:</span>
<span id="cb36-52"><a href="#cb36-52" aria-hidden="true" tabindex="-1"></a>        offset_x <span class="op">=</span> kernel[<span class="st">"intensity"</span>] <span class="op">*</span> <span class="fl">0.7</span>  <span class="co"># Move left</span></span>
<span id="cb36-53"><a href="#cb36-53" aria-hidden="true" tabindex="-1"></a>        offset_y <span class="op">=</span> kernel[<span class="st">"performance"</span>] <span class="op">*</span> <span class="fl">0.65</span>  <span class="co"># Move down</span></span>
<span id="cb36-54"><a href="#cb36-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:  <span class="co"># Shared 3×3</span></span>
<span id="cb36-55"><a href="#cb36-55" aria-hidden="true" tabindex="-1"></a>        offset_x <span class="op">=</span> kernel[<span class="st">"intensity"</span>] <span class="op">*</span> <span class="fl">1.4</span>  <span class="co"># Move right</span></span>
<span id="cb36-56"><a href="#cb36-56" aria-hidden="true" tabindex="-1"></a>        offset_y <span class="op">=</span> kernel[<span class="st">"performance"</span>] <span class="op">*</span> <span class="fl">1.3</span>  <span class="co"># Move up</span></span>
<span id="cb36-57"><a href="#cb36-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-58"><a href="#cb36-58" aria-hidden="true" tabindex="-1"></a>    ax.annotate(kernel[<span class="st">"name"</span>],</span>
<span id="cb36-59"><a href="#cb36-59" aria-hidden="true" tabindex="-1"></a>               (kernel[<span class="st">"intensity"</span>], kernel[<span class="st">"performance"</span>]),</span>
<span id="cb36-60"><a href="#cb36-60" aria-hidden="true" tabindex="-1"></a>               xytext<span class="op">=</span>(offset_x, offset_y),</span>
<span id="cb36-61"><a href="#cb36-61" aria-hidden="true" tabindex="-1"></a>               fontsize<span class="op">=</span><span class="dv">11</span>, fontweight<span class="op">=</span><span class="st">"bold"</span>, ha<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb36-62"><a href="#cb36-62" aria-hidden="true" tabindex="-1"></a>               bbox<span class="op">=</span><span class="bu">dict</span>(boxstyle<span class="op">=</span><span class="st">"round,pad=0.3"</span>, facecolor<span class="op">=</span><span class="st">"white"</span>, alpha<span class="op">=</span><span class="fl">0.8</span>))</span>
<span id="cb36-63"><a href="#cb36-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-64"><a href="#cb36-64" aria-hidden="true" tabindex="-1"></a>ax.text(<span class="fl">1.5</span>, peak_bandwidth <span class="op">*</span> <span class="fl">1.5</span>, <span class="st">"Memory-bound"</span>,</span>
<span id="cb36-65"><a href="#cb36-65" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="st">"#e74c3c"</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">"bold"</span>, ha<span class="op">=</span><span class="st">"center"</span>)</span>
<span id="cb36-66"><a href="#cb36-66" aria-hidden="true" tabindex="-1"></a>ax.text(<span class="dv">200</span>, peak_compute <span class="op">*</span> <span class="fl">0.8</span>, <span class="st">"Compute-bound"</span>,</span>
<span id="cb36-67"><a href="#cb36-67" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="st">"#3498db"</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb36-68"><a href="#cb36-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-69"><a href="#cb36-69" aria-hidden="true" tabindex="-1"></a>ax.text(critical_intensity <span class="op">*</span> <span class="fl">1.3</span>, peak_compute <span class="op">*</span> <span class="fl">1.1</span>,</span>
<span id="cb36-70"><a href="#cb36-70" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"I_crit = </span><span class="sc">{</span>critical_intensity<span class="sc">:.1f}</span><span class="ss">"</span>,</span>
<span id="cb36-71"><a href="#cb36-71" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="st">"#f39c12"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb36-72"><a href="#cb36-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-73"><a href="#cb36-73" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="fl">0.1</span>, <span class="dv">1000</span>)</span>
<span id="cb36-74"><a href="#cb36-74" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="dv">10</span>, <span class="dv">30000</span>)</span>
<span id="cb36-75"><a href="#cb36-75" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Operational Intensity (FLOP/byte) - Log_10 Scale"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb36-76"><a href="#cb36-76" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Performance (GFLOP/s) - Log_10 Scale"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb36-77"><a href="#cb36-77" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb36-78"><a href="#cb36-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-79"><a href="#cb36-79" aria-hidden="true" tabindex="-1"></a>legend_elements <span class="op">=</span> [plt.Line2D([<span class="dv">0</span>], [<span class="dv">0</span>], marker<span class="op">=</span><span class="st">'o'</span>, color<span class="op">=</span><span class="st">'w'</span>,</span>
<span id="cb36-80"><a href="#cb36-80" aria-hidden="true" tabindex="-1"></a>                             markerfacecolor<span class="op">=</span>k[<span class="st">"color"</span>], markersize<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb36-81"><a href="#cb36-81" aria-hidden="true" tabindex="-1"></a>                             label<span class="op">=</span>k[<span class="st">"name"</span>], markeredgecolor<span class="op">=</span><span class="st">"#333"</span>)</span>
<span id="cb36-82"><a href="#cb36-82" aria-hidden="true" tabindex="-1"></a>                  <span class="cf">for</span> k <span class="kw">in</span> kernels]</span>
<span id="cb36-83"><a href="#cb36-83" aria-hidden="true" tabindex="-1"></a>ax.legend(handles<span class="op">=</span>legend_elements, loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb36-84"><a href="#cb36-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-85"><a href="#cb36-85" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb36-86"><a href="#cb36-86" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'./mojo_gpu_puzzles/p14_roofline_naive_and_shared.png'</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb36-87"><a href="#cb36-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-88"><a href="#cb36-88" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Performance Analysis:"</span>)</span>
<span id="cb36-89"><a href="#cb36-89" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb36-90"><a href="#cb36-90" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> kernel <span class="kw">in</span> kernels:</span>
<span id="cb36-91"><a href="#cb36-91" aria-hidden="true" tabindex="-1"></a>    efficiency <span class="op">=</span> (kernel[<span class="st">"performance"</span>] <span class="op">/</span> peak_compute) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb36-92"><a href="#cb36-92" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>kernel[<span class="st">'name'</span>]<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb36-93"><a href="#cb36-93" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Intensity: </span><span class="sc">{</span>kernel[<span class="st">'intensity'</span>]<span class="sc">}</span><span class="ss"> FLOP/byte"</span>)</span>
<span id="cb36-94"><a href="#cb36-94" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Performance: </span><span class="sc">{</span>kernel[<span class="st">'performance'</span>]<span class="sc">}</span><span class="ss"> GFLOP/s"</span>)</span>
<span id="cb36-95"><a href="#cb36-95" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Efficiency: </span><span class="sc">{</span>efficiency<span class="sc">:.1f}</span><span class="ss">% of peak"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</details>
</section>
</section>
<section id="key-insights" class="level3">
<h3 class="anchored" data-anchor-id="key-insights">Key Insights</h3>
<ul>
<li><strong>Intensity grows with matrix size</strong> - For naive <span class="math inline">\(N \times N\)</span> GEMM: <span class="math inline">\(I = \frac{N^3}{4N^2} = \frac{N}{4}\)</span> FLOP/byte</li>
<li><strong>Small kernels are bandwidth-bound</strong> - Even perfect caching can’t reach the 74 FLOP/byte crossover until <span class="math inline">\(N \approx 300\)</span></li>
<li><strong>Shared memory helps, but only up to the ridge</strong> - Further speedups require compute-side tuning (tensor cores, ILP, etc.)</li>
</ul>
<p>Next, we’ll look at one specific optimisation for Matmul: Tile-based GEMM!</p>
</section>
</section>
<section id="tiled-matrix-multiplication-gemm" class="level2">
<h2 class="anchored" data-anchor-id="tiled-matrix-multiplication-gemm">Tiled Matrix-Multiplication (GEMM)</h2>
<p>Our <em>shared-memory</em> kernel already cut global-DRAM traffic by loading each <code>A[i,k]</code> / <code>B[k,j]</code> element once per thread <em>row/column</em> instead of once per <em>output multiply</em>.<br>
For large matrices, however, even that version still:</p>
<ul>
<li>Brings the <em>entire</em> row of <code>A</code> and column of <code>B</code> into shared SRAM, quickly exhausting the 48–112 KiB available per SM.</li>
<li>Leaves many threads idle while others finish their portion of the dot-product.</li>
<li>Misses an opportunity to keep a hot, register-resident accumulator and hide global-latency behind computation.</li>
</ul>
<p>Enter <strong>tiling / blocking</strong> — the canonical GPU GEMM strategy.</p>
<section id="tile" class="level3">
<h3 class="anchored" data-anchor-id="tile">Tile?</h3>
<p>Think of an <code>N×N</code> matmul as a chessboard. Instead of letting every thread wander across the whole board, we slice it into <code>T×T</code> sub-squares (<strong>tiles</strong>).</p>
<p>A <em>thread-block</em> is assigned one output tile, and:</p>
<ul>
<li>Cooperatively loads the matching <code>T×T</code> <em>A-tile</em> and <em>B-tile</em> from global DRAM to <em>shared memory</em> (two coalesced 2-D memcpy’s).</li>
<li>Performs <code>T</code> fused-multiply-add sweeps of that data, each thread keeping its running sum in a <em>register</em>.</li>
<li>Barriers, slides the tile window by <code>T</code> along the inner-<code>k</code> dimension, and repeats until the dot-product is complete.</li>
<li>Finally writes the <code>T×T</code> block of <code>C</code> back to DRAM.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p14_tiled_matmul.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-22" data-glightbox="description: .lightbox-desc-22" title="Matmul Operation for a 4x4 Matrix, computing the first 4 output elements. Credits: Simon Oz"><img src="mojo_gpu_puzzles/p14_tiled_matmul.gif" class="img-fluid figure-img" alt="Matmul Operation for a 4x4 Matrix, computing the first 4 output elements. Credits: Simon Oz"></a></p>
<figcaption>Matmul Operation for a 4x4 Matrix, computing the first 4 output elements. Credits: <a href="https://www.youtube.com/watch?v=ccHyFnEZt7M&amp;ab_channel=SimonOz">Simon Oz</a></figcaption>
</figure>
</div>
<p>Each element of <code>A</code>/<code>B</code> is now read <em>once per tile</em> - independent of <code>N</code>, and re-used <code>T</code> times, boosting arithmetic intensity from <code>O(1)</code> to <code>O(T)</code> FLOP/B.</p>
</section>
<section id="memory-mapping-for-tiled-gemm" class="level3">
<h3 class="anchored" data-anchor-id="memory-mapping-for-tiled-gemm">Memory mapping for tiled GEMM</h3>
<p>The memory hierachy(discussed <a href="../posts/2025-07-06-gpu-puzzles-p1.html#gpu-memory">in the previous post</a>), is utilised as follows:</p>
<ul>
<li><strong>Registers</strong>: per-thread accumulators that hold partial <code>C</code> values across all tile iterations</li>
<li><strong>Shared SRAM</strong>: the current <code>A_tile</code> and <code>B_tile</code>, cooperatively loaded once and reused T times<br>
</li>
<li><strong>Global HBM</strong>: original A, B matrices and final C; each element touched once per tile load/store</li>
</ul>
</section>
<section id="raw-memory-1" class="level3">
<h3 class="anchored" data-anchor-id="raw-memory-1">Raw Memory</h3>
<details open="">
<summary>
<strong>Manual Indexing Tiled Matmul</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p14_matmul_tiled_manual.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb37" data-filename="p14_matmul_tiled_manual.mojo"><pre class="sourceCode mojo code-overflow-wrap code-with-copy"><code class="sourceCode mojo"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> SIZE_TILED <span class="op">=</span> <span class="dv">8</span> <span class="co"># Size of the matrix we are multiplying, NOT the size of a tile</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID_TILED <span class="op">=</span> (<span class="dv">3</span>, <span class="dv">3</span>)  <span class="co"># each block convers 3x3 elements</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK_TILED <span class="op">=</span> (TPB, TPB)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> layout_tiled <span class="op">=</span> Layout.row_major(SIZE_TILED, SIZE_TILED)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> matmul_tiled[</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    layout: Layout, size: Int</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    output: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>    b: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    local_row <span class="op">=</span> thread_idx.y</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>    local_col <span class="op">=</span> thread_idx.x</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>    global_row <span class="op">=</span> block_idx.y <span class="op">*</span> TPB <span class="op">+</span> local_row</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>    global_col <span class="op">=</span> block_idx.x <span class="op">*</span> TPB <span class="op">+</span> local_col</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>    shared_a <span class="op">=</span> tb[dtype]().row_major[TPB, TPB]().shared().alloc()</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>    shared_b <span class="op">=</span> tb[dtype]().row_major[TPB, TPB]().shared().alloc()</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">var</span> local_sum: output.element_type <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">@parameter</span></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># (size + TPB - 1) // TPB == ceil(size / TPB) -&gt; number of tile-steps we need</span></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tile <span class="kw">in</span> <span class="bu">range</span>((size <span class="op">+</span> TPB <span class="op">-</span> <span class="dv">1</span>) <span class="op">//</span> TPB):</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Load elements of A into shared mem</span></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> global_row <span class="op">&lt;</span> size <span class="kw">and</span> (tile <span class="op">*</span> TPB <span class="op">+</span> local_col) <span class="op">&lt;</span> size:</span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a>            shared_a[local_row, local_col] <span class="op">=</span> a[</span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>                global_row, tile <span class="op">*</span> TPB <span class="op">+</span> local_col</span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Load elements of B into shared mem</span></span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> global_col <span class="op">&lt;</span> size <span class="kw">and</span> (tile <span class="op">*</span> TPB <span class="op">+</span> local_row) <span class="op">&lt;</span> size:</span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a>            shared_b[local_row, local_col] <span class="op">=</span> b[</span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a>                tile <span class="op">*</span> TPB <span class="op">+</span> local_row, global_col</span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-40"><a href="#cb37-40" aria-hidden="true" tabindex="-1"></a>        barrier()</span>
<span id="cb37-41"><a href="#cb37-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-42"><a href="#cb37-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Perform matmul</span></span>
<span id="cb37-43"><a href="#cb37-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> global_row <span class="op">&lt;</span> size <span class="kw">and</span> global_col <span class="op">&lt;</span> size:</span>
<span id="cb37-44"><a href="#cb37-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-45"><a href="#cb37-45" aria-hidden="true" tabindex="-1"></a>            <span class="at">@parameter</span></span>
<span id="cb37-46"><a href="#cb37-46" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(TPB, size <span class="op">-</span> tile <span class="op">*</span> TPB)):</span>
<span id="cb37-47"><a href="#cb37-47" aria-hidden="true" tabindex="-1"></a>                local_sum <span class="op">+=</span> shared_a[local_row, k] <span class="op">*</span> shared_b[k, local_col]</span>
<span id="cb37-48"><a href="#cb37-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-49"><a href="#cb37-49" aria-hidden="true" tabindex="-1"></a>            barrier()</span>
<span id="cb37-50"><a href="#cb37-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-51"><a href="#cb37-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> global_row <span class="op">&lt;</span> size <span class="kw">and</span> global_col <span class="op">&lt;</span> size:</span>
<span id="cb37-52"><a href="#cb37-52" aria-hidden="true" tabindex="-1"></a>            output[global_row, global_col] <span class="op">=</span> local_sum</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb38"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pixi</span> run p14 <span class="at">--tiled</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="co"># out: HostBuffer([2240.0, 2296.0, 2352.0, 2408.0, 2464.0, 2520.0, 2576.0, 2632.0, 5824.0, 6008.0, 6192.0, 6376.0, 6560.0, 6744.0, 6928.0, 7112.0, 9408.0, 9720.0, 10032.0, 10344.0, 10656.0, 10968.0, 11280.0, 11592.0, 12992.0, 13432.0, 13872.0, 14312.0, 14752.0, 15192.0, 15632.0, 16072.0, 16576.0, 17144.0, 17712.0, 18280.0, 18848.0, 19416.0, 19984.0, 20552.0, 20160.0, 20856.0, 21552.0, 22248.0, 22944.0, 23640.0, 24336.0, 25032.0, 23744.0, 24568.0, 25392.0, 26216.0, 27040.0, 27864.0, 28688.0, 29512.0, 27328.0, 28280.0, 29232.0, 30184.0, 31136.0, 32088.0, 33040.0, 33992.0])</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co"># expected: HostBuffer([2240.0, 2296.0, 2352.0, 2408.0, 2464.0, 2520.0, 2576.0, 2632.0, 5824.0, 6008.0, 6192.0, 6376.0, 6560.0, 6744.0, 6928.0, 7112.0, 9408.0, 9720.0, 10032.0, 10344.0, 10656.0, 10968.0, 11280.0, 11592.0, 12992.0, 13432.0, 13872.0, 14312.0, 14752.0, 15192.0, 15632.0, 16072.0, 16576.0, 17144.0, 17712.0, 18280.0, 18848.0, 19416.0, 19984.0, 20552.0, 20160.0, 20856.0, 21552.0, 22248.0, 22944.0, 23640.0, 24336.0, 25032.0, 23744.0, 24568.0, 25392.0, 26216.0, 27040.0, 27864.0, 28688.0, 29512.0, 27328.0, 28280.0, 29232.0, 30184.0, 31136.0, 32088.0, 33040.0, 33992.0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<p>The new formulas in the tiling implementation deserve explanation. Let’s break them down into key concepts:</p>
<section id="how-many-tiles-are-needed" class="level4">
<h4 class="anchored" data-anchor-id="how-many-tiles-are-needed">How many Tiles are needed?</h4>
<p>This is the expression: <code>range((size + TPB - 1) // TPB)</code></p>
<p>The key idea here is: Step through k by TPB each time; if there’s a leftover chunk, do one last tile for it.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p14_tile.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23" data-glightbox="description: .lightbox-desc-23" title="Mapping of elements to tiles when size=17 and TPB=8"><img src="mojo_gpu_puzzles/p14_tile.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Mapping of elements to tiles when size=17 and TPB=8"></a></p>
<figcaption>Mapping of elements to tiles when size=17 and TPB=8</figcaption>
</figure>
</div>
<p>The above example needs 3 tiles. Ceiling division captures this with a simple formula: <span class="math display">\[
\lceil\frac{size}{TPB}\rceil = \lfloor\frac{size + TPB - 1}{TPB}\rfloor
\]</span></p>
</section>
<section id="which-element-does-a-thread-fetch-in-this-tile" class="level4">
<h4 class="anchored" data-anchor-id="which-element-does-a-thread-fetch-in-this-tile">Which element does a thread fetch in this tile?</h4>
<p>Each thread snags two scalars—one from A, one from B.</p>
<p><code>tile</code> is simply “which chunk of k are we on?”</p>
<p>Inside a block, a thread owns a single output cell <code>C[global_row, global_col]</code>. To finish that cell it must walk k, multiplying aligned pairs (A[row, k], B[k, col]).</p>
<p>On tile <code>t</code> the fetches are</p>
<pre><code>A = a[global_row, t*TPB + local_col]
B = b[t*TPB + local_row, global_col]</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p14_tiled_matmul_annotated.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24" data-glightbox="description: .lightbox-desc-24" title="Tiled 9×9 matmul: Each thread loads 3x3 A and 3x3 B elements per tile, computes a partial sum, then syncs. Tile size = 3×3, 9 threads per block."><img src="mojo_gpu_puzzles/p14_tiled_matmul_annotated.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Tiled 9×9 matmul: Each thread loads 3x3 A and 3x3 B elements per tile, computes a partial sum, then syncs. Tile size = 3×3, 9 threads per block."></a></p>
<figcaption>Tiled 9×9 matmul: Each thread loads 3x3 A and 3x3 B elements per tile, computes a partial sum, then syncs. Tile size = 3×3, 9 threads per block.</figcaption>
</figure>
</div>
<p>Both reads cover the same k-slice (<code>t*TPB … t*TPB+TPB-1</code>), so every multiply in this round lives entirely in shared memory.</p>
</section>
<section id="why-do-we-swap-local_row-and-local_col-for-b" class="level4">
<h4 class="anchored" data-anchor-id="why-do-we-swap-local_row-and-local_col-for-b">Why do we swap <code>local_row</code> and <code>local_col</code> for B?</h4>
<p>GPUs coalesce global memory when <em>adjacent threads read adjacent addresses</em>. With the swap:</p>
<ul>
<li><strong>For A</strong>: neighboring threads in x-direction (<code>local_col</code>) read consecutive k’s ⇒ coalesced</li>
<li><strong>For B</strong>: neighboring threads in y-direction (<code>local_row</code>) read consecutive k’s ⇒ also coalesced</li>
</ul>
<p>Without the swap, one matrix would be fetched “strided” collapsing into 32 separate memory transactions per warp - a 32× slowdown on bandwidth-bound kernels.</p>
<p><strong>Quick primer</strong>: Shared memory isn’t one monolithic block. It’s chopped into 32 independent “banks”<span class="citation" data-cites="nvidia_shared_memory_stats"><a href="#ref-nvidia_shared_memory_stats" role="doc-biblioref">[15]</a></span> <span class="citation" data-cites="leimao_cuda_shared_memory_bank"><a href="#ref-leimao_cuda_shared_memory_bank" role="doc-biblioref">[16]</a></span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="mojo_gpu_puzzles/p14_shared_memory_bank.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25" data-glightbox="description: .lightbox-desc-25" title="Shared memory banking: conflict-free access (left) vs bank conflicts (right). When multiple threads access different addresses in the same bank, hardware serializes the requests. Source: CUDA Programming Blogspot"><img src="mojo_gpu_puzzles/p14_shared_memory_bank.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Shared memory banking: conflict-free access (left) vs bank conflicts (right). When multiple threads access different addresses in the same bank, hardware serializes the requests. Source: CUDA Programming Blogspot"></a></p>
<figcaption>Shared memory banking: conflict-free access (left) vs bank conflicts (right). When multiple threads access different addresses in the same bank, hardware serializes the requests. Source: <a href="https://cuda-programming.blogspot.com/2013/02/bank-conflicts-in-shared-memory-in-cuda.html">CUDA Programming Blogspot</a></figcaption>
</figure>
</div>
<p>Each is a tiny SRAM with its own read/write port that can service one request (or one 32-bit access per cycle). A warp hits peak bandwidth <em>only when</em> every thread lands in a different bank (or all hit the same address, which hardware can broadcast). If two threads target different addresses inside the same bank during the same cycle, the hardware must serialize them, referred to as a <strong>bank conflict</strong>.</p>
<p>Beyond coalescing, our tile layout also sidesteps these conflicts. Because <code>b_shared[k, threadIdx.x]</code> maps each thread to a distinct bank (while <code>a_shared[threadIdx.y, k]</code> is broadcast-friendly), all 32 memory ports stay busy with zero serialization.</p>
</section>
<section id="choosing-the-right-tile-size" class="level4">
<h4 class="anchored" data-anchor-id="choosing-the-right-tile-size">Choosing the Right Tile Size</h4>
<p>While the current puzzle selects <span class="math inline">\(TPB=3\)</span> with tile size <span class="math inline">\(TPBxTPB\)</span>, choosing the tile size is a balancing act.</p>
<p>Exact numbers vary with GPU, kernel, and precision [<span class="citation" data-cites="nvidia_ampere_unified_shared_memory"><a href="#ref-nvidia_ampere_unified_shared_memory" role="doc-biblioref">[17]</a></span>]<span class="citation" data-cites="nvidia_blackwell_unified_shared_memory"><a href="#ref-nvidia_blackwell_unified_shared_memory" role="doc-biblioref">[18]</a></span>.</p>
<p>I’m still learning the dark art of GPU perf tuning, so I’ll save the details for a future post once I’ve had more time to experiment.</p>
<p><strong>TLDR:</strong> For each tile, we will sync (barrier), compute, shift to next tile, repeat. But this is just the baseline - there’s always a deeper optimization rabbit hole!</p>
</section>
</section>
<section id="layouttensor-1" class="level3">
<h3 class="anchored" data-anchor-id="layouttensor-1">LayoutTensor</h3>
<p>While the manual tiling approach works, it suffers from indexing complexity that obscures the algorithm’s intent and creates opportunities for bugs. Mojo’s LayoutTensor API provides an elegant solution that maintains performance while dramatically improving code clarity.</p>
<section id="the-pain-of-manual-indexing" class="level4">
<h4 class="anchored" data-anchor-id="the-pain-of-manual-indexing">The Pain of Manual Indexing</h4>
<p>The manual implementation requires careful coordinate arithmetic:</p>
<ul>
<li>Nested index calculations like <code>tile * TPB + local_col</code> that can easily introduce off-by-one errors</li>
<li>Separate bounds checking for each matrix load operation</li>
<li>Explicit management of tile boundaries and edge cases</li>
<li>Code that prioritizes performance over readability</li>
</ul>
<p>LayoutTensor provides a <strong>tile()</strong> method that creates zero-copy <span class="citation" data-cites="zero_cost_abstractions"><a href="#ref-zero_cost_abstractions" role="doc-biblioref">[7]</a></span> views into sub-regions of tensors <span class="citation" data-cites="mojo_layouttensor_tile"><a href="#ref-mojo_layouttensor_tile" role="doc-biblioref">[19]</a></span>. This eliminates manual indexing gymnastics while keeping identical performance.</p>
<p>A <code>LayoutTensor.tile[tile_height, tile_width](block_row, block_col)</code> call returns a view of the specified tile without copying data, at no cost!</p>
<p>The transformation from manual indexing to LayoutTensor simplifies the loading logic:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode diff code-with-copy"><code class="sourceCode diff"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a># Load elements of A into shared mem</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="st">- if global_row &lt; size and (tile * TPB + local_col) &lt; size:</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="st">-     shared_a[local_row, local_col] = a[</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="st">-         global_row, tile * TPB + local_col</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="st">-     ]</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="st">- </span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="st">- # Load elements of B into shared mem  </span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="st">- if global_col &lt; size and (tile * TPB + local_row) &lt; size:</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="st">-     shared_b[local_row, local_col] = b[</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="st">-         tile * TPB + local_row, global_col</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="st">-     ]</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a># Create tile views (zero-copy)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="va">+ a_tile = a.tile[TPB, TPB](block_idx.y, idx)</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="va">+ b_tile = b.tile[TPB, TPB](idx, block_idx.x)</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a># Asynchronous copy to shared memory</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a><span class="va">+ copy_dram_to_sram_async[thread_layout=load_a_layout](a_shared, a_tile)</span></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a><span class="va">+ copy_dram_to_sram_async[thread_layout=load_b_layout](b_shared, b_tile)</span></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a># Synchronize all async copies</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a><span class="va">+ async_copy_wait_all()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Full solution looks as follows:</p>
<details closed="">
<summary>
<strong>LayoutTensor Tiled Matmul</strong>
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>p14_matmul_layout_tensor.mojo</strong></pre>
</div>
<div class="sourceCode" id="cb41" data-filename="p14_matmul_layout_tensor.mojo"><pre class="sourceCode mojo code-with-copy"><code class="sourceCode mojo"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> SIZE_TILED <span class="op">=</span> <span class="dv">9</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> BLOCKS_PER_GRID_TILED <span class="op">=</span> (<span class="dv">3</span>, <span class="dv">3</span>)  <span class="co"># each block covers 3x3 elements</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> THREADS_PER_BLOCK_TILED <span class="op">=</span> (TPB, TPB)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="kw">alias</span> layout_tiled <span class="op">=</span> Layout.row_major(SIZE_TILED, SIZE_TILED)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> matmul_tiled[</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>    layout: Layout, size: Int</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>](</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>    output: LayoutTensor[mut<span class="op">=</span><span class="va">True</span>, dtype, layout],</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>    a: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>    b: LayoutTensor[mut<span class="op">=</span><span class="va">False</span>, dtype, layout],</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># LayoutTensor APIs</span></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>    out_tile <span class="op">=</span> output.tile[TPB, TPB](block_idx.y, block_idx.x)</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>    a_shared <span class="op">=</span> tb[dtype]().row_major[TPB, TPB]().shared().alloc()</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>    b_shared <span class="op">=</span> tb[dtype]().row_major[TPB, TPB]().shared().alloc()</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>    local_row <span class="op">=</span> thread_idx.y</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>    local_col <span class="op">=</span> thread_idx.x</span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">var</span> local_sum: output.element_type <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">alias</span> load_a_layout <span class="op">=</span> Layout.row_major[<span class="dv">1</span>, TPB]()</span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">alias</span> load_b_layout <span class="op">=</span> Layout.row_major[TPB, <span class="dv">1</span>]()</span>
<span id="cb41-25"><a href="#cb41-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-26"><a href="#cb41-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">@parameter</span></span>
<span id="cb41-27"><a href="#cb41-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>((size <span class="op">+</span> TPB <span class="op">-</span> <span class="dv">1</span>) <span class="op">//</span> TPB):</span>
<span id="cb41-28"><a href="#cb41-28" aria-hidden="true" tabindex="-1"></a>        a_tile <span class="op">=</span> a.tile[TPB, TPB](block_idx.y, idx)</span>
<span id="cb41-29"><a href="#cb41-29" aria-hidden="true" tabindex="-1"></a>        b_tile <span class="op">=</span> b.tile[TPB, TPB](idx, block_idx.x)</span>
<span id="cb41-30"><a href="#cb41-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-31"><a href="#cb41-31" aria-hidden="true" tabindex="-1"></a>        copy_dram_to_sram_async[thread_layout<span class="op">=</span>load_a_layout](a_shared, a_tile)</span>
<span id="cb41-32"><a href="#cb41-32" aria-hidden="true" tabindex="-1"></a>        copy_dram_to_sram_async[thread_layout<span class="op">=</span>load_b_layout](b_shared, b_tile)</span>
<span id="cb41-33"><a href="#cb41-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-34"><a href="#cb41-34" aria-hidden="true" tabindex="-1"></a>        async_copy_wait_all()</span>
<span id="cb41-35"><a href="#cb41-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-36"><a href="#cb41-36" aria-hidden="true" tabindex="-1"></a>        <span class="at">@parameter</span></span>
<span id="cb41-37"><a href="#cb41-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(TPB, size <span class="op">-</span> idx <span class="op">*</span> TPB)):</span>
<span id="cb41-38"><a href="#cb41-38" aria-hidden="true" tabindex="-1"></a>            local_sum <span class="op">+=</span> a_shared[local_row, k] <span class="op">*</span> b_shared[k, local_col]</span>
<span id="cb41-39"><a href="#cb41-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-40"><a href="#cb41-40" aria-hidden="true" tabindex="-1"></a>        barrier()</span>
<span id="cb41-41"><a href="#cb41-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-42"><a href="#cb41-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Store result after all tiles processed</span></span>
<span id="cb41-43"><a href="#cb41-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (</span>
<span id="cb41-44"><a href="#cb41-44" aria-hidden="true" tabindex="-1"></a>        block_idx.y <span class="op">*</span> TPB <span class="op">+</span> local_row <span class="op">&lt;</span> size</span>
<span id="cb41-45"><a href="#cb41-45" aria-hidden="true" tabindex="-1"></a>        <span class="kw">and</span> block_idx.x <span class="op">*</span> TPB <span class="op">+</span> local_col <span class="op">&lt;</span> size</span>
<span id="cb41-46"><a href="#cb41-46" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb41-47"><a href="#cb41-47" aria-hidden="true" tabindex="-1"></a>        out_tile[local_row, local_col] <span class="op">=</span> local_sum</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</details>
</section>
<section id="synchronization-and-memory-hierarchy" class="level4">
<h4 class="anchored" data-anchor-id="synchronization-and-memory-hierarchy">Synchronization and Memory Hierarchy</h4>
<p>The <code>copy_dram_to_sram_async()</code> function <span class="citation" data-cites="mojo_copy_dram_to_sram_async"><a href="#ref-mojo_copy_dram_to_sram_async" role="doc-biblioref">[20]</a></span> enables asynchronous memory transfers from global to shared memory, while <code>async_copy_wait_all()</code> <span class="citation" data-cites="mojo_async_copy_wait_all"><a href="#ref-mojo_async_copy_wait_all" role="doc-biblioref">[21]</a></span> provides a synchronization barrier that ensures all pending transfers complete before computation proceeds.</p>
<p>This pattern allows the GPU to:</p>
<ul>
<li>Overlap memory transfers with other computations using dedicated copy engines</li>
<li>Utilize specialized hardware for efficient data movement</li>
<li>Maintain correct execution ordering across thread blocks</li>
<li>Bypass intermediate registers for improved memory hierarchy efficiency</li>
</ul>
<p><strong>Important</strong>: <code>async_copy_wait_all()</code> only synchronizes the asynchronous copy operations—threads still need explicit barriers (<code>barrier()</code>) to ensure all threads in a block see the shared memory data before computation begins.</p>
</section>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Across these puzzles, we’ve implemented the four fundamental archetypes that power most GPU computing:</p>
<table class="table">
<colgroup>
<col style="width: 28%">
<col style="width: 28%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Pattern</strong></th>
<th><strong>Puzzles</strong></th>
<th><strong>Core Technique</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Map-Reduce</strong></td>
<td>dot product, axis-sum</td>
<td>warp-level parallel reduction trees</td>
</tr>
<tr class="even">
<td><strong>Stencil</strong></td>
<td>pooling, 1D/2D convolution</td>
<td>spatial tiling with halo exchanges</td>
</tr>
<tr class="odd">
<td><strong>Scan</strong></td>
<td>prefix sum</td>
<td>hierarchical up-sweep + down-sweep</td>
</tr>
<tr class="even">
<td><strong>Dense Linear Algebra</strong></td>
<td>matrix multiplication</td>
<td>cooperative tiling + register reuse</td>
</tr>
</tbody>
</table>
<p>These four archetypes form the building blocks for complex ML kernels, each with specific memory access patterns and synchronization strategies.</p>
<p>Next up: Moar GPU kernels, and finally tackling our favorite technique for the past few years: <strong>Attention</strong>!</p>
<p>Thanks for sticking around! I hope you picked up a trick or two! Spotted a bug or have a sharper optimization? Open an issue in the repo, or ping me on <a href="https://x.com/shubhamg2208">Twitter/X</a>. Happy hacking!</p>


<div class="hidden" aria-hidden="true">
<span class="glightbox-desc lightbox-desc-1">Pooling</span>
<span class="glightbox-desc lightbox-desc-2">Dot Product</span>
<span class="glightbox-desc lightbox-desc-3">Zeno Paradox</span>
<span class="glightbox-desc lightbox-desc-9">2D Block Layout</span>
<span class="glightbox-desc lightbox-desc-10">2D Thread Layout</span>
<span class="glightbox-desc lightbox-desc-11">Matrix Indexing</span>
<span class="glightbox-desc lightbox-desc-12">Source: <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p1.2-web/Project%201.2%20-%20Computer%20Architecture%20I%20-%20ShanghaiTech%20University.html">Toast Lab</a></span>
<span class="glightbox-desc lightbox-desc-13">Prefix‐Sum Illustration</span>
<span class="glightbox-desc lightbox-desc-15">Axis Sum</span>
<span class="glightbox-desc lightbox-desc-16">Row Sum</span>
<span class="glightbox-desc lightbox-desc-17">Matmul with shared memory</span>
<span class="glightbox-desc lightbox-desc-18">Source: NHR at FAU<span class="citation" data-cites="nhrfau_roofline_model"><a href="#ref-nhrfau_roofline_model" role="doc-biblioref">[13]</a></span></span>
<span class="glightbox-desc lightbox-desc-19">Software abstraction: complex GPU kernel simplified to steady-state loop with N flops and V bytes per iteration. Credits: NHR at FAU<span class="citation" data-cites="nhrfau_roofline_model"><a href="#ref-nhrfau_roofline_model" role="doc-biblioref">[13]</a></span></span>
<span class="glightbox-desc lightbox-desc-20">Roofline model: sloped red line shows memory bandwidth limit, flat blue line is compute peak, kernel’s operational intensity marked as a dot.</span>
<span class="glightbox-desc lightbox-desc-21">RTX 4000 Ada Roofline for Matmul</span>
<span class="glightbox-desc lightbox-desc-22">Matmul Operation for a 4x4 Matrix, computing the first 4 output elements. Credits: <a href="https://www.youtube.com/watch?v=ccHyFnEZt7M&amp;ab_channel=SimonOz">Simon Oz</a></span>
<span class="glightbox-desc lightbox-desc-23">Mapping of elements to tiles when size=17 and TPB=8</span>
<span class="glightbox-desc lightbox-desc-24">Tiled 9×9 matmul: Each thread loads 3x3 A and 3x3 B elements per tile, computes a partial sum, then syncs. Tile size = 3×3, 9 threads per block.</span>
<span class="glightbox-desc lightbox-desc-25">Shared memory banking: conflict-free access (left) vs bank conflicts (right). When multiple threads access different addresses in the same bank, hardware serializes the requests. Source: <a href="https://cuda-programming.blogspot.com/2013/02/bank-conflicts-in-shared-memory-in-cuda.html">CUDA Programming Blogspot</a></span>
</div>

</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list">
<div id="ref-wikipediadotproduct" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">Wikipedia, <span>“Dot product.”</span> <a href="https://en.wikipedia.org/wiki/Dot_product" class="uri">https://en.wikipedia.org/wiki/Dot_product</a>, 2024.</div>
</div>
<div id="ref-zeno_dichotomy_paradox" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">Wikipedia, <span>“Zeno’s paradoxes — dichotomy paradox.”</span> <a href="https://en.wikipedia.org/wiki/Zeno%27s_paradoxes#Dichotomy_paradox" class="uri">https://en.wikipedia.org/wiki/Zeno%27s_paradoxes#Dichotomy_paradox</a>, 2024.</div>
</div>
<div id="ref-thakur_convolutions" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">A. Thakur, <span>“Intuitive understanding of 1D, 2D, and 3D convolutions in convolutional neural networks.”</span> 2020. Available: <a href="https://wandb.ai/ayush-thakur/dl-question-bank/reports/Intuitive-understanding-of-1D-2D-and-3D-convolutions-in-convolutional-neural-networks---VmlldzoxOTk2MDA">https://wandb.ai/ayush-thakur/dl-question-bank/reports/Intuitive-understanding-of-1D-2D-and-3D-convolutions-in-convolutional-neural-networks---VmlldzoxOTk2MDA</a></div>
</div>
<div id="ref-nvidiapragmaunroll" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">NVIDIA, <span>“<span class="nocase">#pragma unroll Compiler Directive (CUDA C Programming Guide)</span>.”</span> 2025. Available: <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html?highlight=unroll#pragma-unroll">https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html?highlight=unroll#pragma-unroll</a></div>
</div>
<div id="ref-mojoparameter" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">Modular, <span>“Parametric closure (<code>@parameter</code>) in mojo.”</span> 2025. Available: <a href="https://docs.modular.com/mojo/manual/decorators/parameter/#parametric-closure">https://docs.modular.com/mojo/manual/decorators/parameter/#parametric-closure</a></div>
</div>
<div id="ref-mojo_lifetimes" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">Modular, <span>“Lifetimes in mojo.”</span> 2025. Available: <a href="https://docs.modular.com/mojo/manual/values/lifetimes/">https://docs.modular.com/mojo/manual/values/lifetimes/</a></div>
</div>
<div id="ref-zero_cost_abstractions" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">saoirse, <span>“Zero cost abstractions.”</span> 2019. Available: <a href="https://without.boats/blog/zero-cost-abstractions/">https://without.boats/blog/zero-cost-abstractions/</a></div>
</div>
<div id="ref-iitd_parallel_convolution" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">R. Sen, <span>“Parallel convolution.”</span> 2022. Available: <a href="https://www.cse.iitd.ac.in/~rijurekha/col730_2022/parallelconvolution_aug29.pdf">https://www.cse.iitd.ac.in/~rijurekha/col730_2022/parallelconvolution_aug29.pdf</a></div>
</div>
<div id="ref-amd_gpu_basics" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">O. R. N. Laboratory, <span>“AMD GPU basics.”</span> 2019. Available: <a href="https://www.olcf.ornl.gov/wp-content/uploads/2019/10/ORNL_Application_Readiness_Workshop-AMD_GPU_Basics.pdf">https://www.olcf.ornl.gov/wp-content/uploads/2019/10/ORNL_Application_Readiness_Workshop-AMD_GPU_Basics.pdf</a></div>
</div>
<div id="ref-mojo_layouttensor_setitem" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">Inc. Modular, <span>“LayoutTensor.__setitem__ API reference.”</span> 2024. Available: <a href="https://docs.modular.com/mojo/kernels/layout/layout_tensor/LayoutTensor/#__setitem__">https://docs.modular.com/mojo/kernels/layout/layout_tensor/LayoutTensor/#__setitem__</a></div>
</div>
<div id="ref-blelloch_prefix_sum" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">G. E. Blelloch, <span>“Prefix sums and their applications,”</span> in <em>Synthesis of parallel algorithms</em>, 1993, pp. 35–60. Available: <a href="https://www.cs.cmu.edu/~guyb/papers/Ble93.pdf">https://www.cs.cmu.edu/~guyb/papers/Ble93.pdf</a></div>
</div>
<div id="ref-siboehm_cuda_mmm" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">S. Boehm, <span>“CUDA matrix multiplication madness.”</span> 2022. Available: <a href="https://siboehm.com/articles/22/CUDA-MMM">https://siboehm.com/articles/22/CUDA-MMM</a></div>
</div>
<div id="ref-nhrfau_roofline_model" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">NHR@FAU, <span>“Roofline model: Performance modeling for modern processors.”</span> <a href="https://www.youtube.com/watch?v=IrkNZG8MJ64" class="uri">https://www.youtube.com/watch?v=IrkNZG8MJ64</a>, 2022.</div>
</div>
<div id="ref-rtx_ada_specs" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">N. Corporation, <span>“NVIDIA RTX 4000 ada generation datasheet.”</span> 2023. Available: <a href="https://resources.nvidia.com/en-us-briefcase-for-datasheets/rtx-4000-ada-datashe-1?ncid=no-ncid">https://resources.nvidia.com/en-us-briefcase-for-datasheets/rtx-4000-ada-datashe-1?ncid=no-ncid</a></div>
</div>
<div id="ref-nvidia_shared_memory_stats" class="csl-entry" role="listitem">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">N. Corporation, <span>“CUDA kernel-level shared memory statistics.”</span> Available: <a href="https://docs.nvidia.com/gameworks/content/developertools/desktop/analysis/report/cudaexperiments/kernellevel/memorystatisticsshared.htm">https://docs.nvidia.com/gameworks/content/developertools/desktop/analysis/report/cudaexperiments/kernellevel/memorystatisticsshared.htm</a></div>
</div>
<div id="ref-leimao_cuda_shared_memory_bank" class="csl-entry" role="listitem">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline">L. Mao, <span>“CUDA shared memory bank.”</span> 2022. Available: <a href="https://leimao.github.io/blog/CUDA-Shared-Memory-Bank/">https://leimao.github.io/blog/CUDA-Shared-Memory-Bank/</a></div>
</div>
<div id="ref-nvidia_ampere_unified_shared_memory" class="csl-entry" role="listitem">
<div class="csl-left-margin">[17] </div><div class="csl-right-inline">N. Corporation, <span>“Ampere tuning guide: Unified shared memory and L1/texture cache.”</span> 2023. Available: <a href="https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html#unified-shared-memory-l1-texture-cache">https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html#unified-shared-memory-l1-texture-cache</a></div>
</div>
<div id="ref-nvidia_blackwell_unified_shared_memory" class="csl-entry" role="listitem">
<div class="csl-left-margin">[18] </div><div class="csl-right-inline">N. Corporation, <span>“Blackwell tuning guide: Unified shared memory and L1/texture cache.”</span> 2025. Available: <a href="https://docs.nvidia.com/cuda/blackwell-tuning-guide/index.html#unified-shared-memory-l1-texture-cache">https://docs.nvidia.com/cuda/blackwell-tuning-guide/index.html#unified-shared-memory-l1-texture-cache</a></div>
</div>
<div id="ref-mojo_layouttensor_tile" class="csl-entry" role="listitem">
<div class="csl-left-margin">[19] </div><div class="csl-right-inline">Inc. Modular, <span>“LayoutTensor.tile API reference.”</span> Available: <a href="https://docs.modular.com/mojo/kernels/layout/layout_tensor/LayoutTensor/#tile">https://docs.modular.com/mojo/kernels/layout/layout_tensor/LayoutTensor/#tile</a></div>
</div>
<div id="ref-mojo_copy_dram_to_sram_async" class="csl-entry" role="listitem">
<div class="csl-left-margin">[20] </div><div class="csl-right-inline">Inc. Modular, <span>“Copy_dram_to_sram_async API reference.”</span> Available: <a href="https://docs.modular.com/mojo/kernels/layout/layout_tensor/copy_dram_to_sram_async/">https://docs.modular.com/mojo/kernels/layout/layout_tensor/copy_dram_to_sram_async/</a></div>
</div>
<div id="ref-mojo_async_copy_wait_all" class="csl-entry" role="listitem">
<div class="csl-left-margin">[21] </div><div class="csl-right-inline">Inc. Modular, <span>“Async_copy_wait_all API reference.”</span> Available: <a href="https://docs.modular.com/mojo/stdlib/gpu/memory/async_copy_wait_all">https://docs.modular.com/mojo/stdlib/gpu/memory/async_copy_wait_all</a></div>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="goodhamgupta/personal_blog" data-repo-id="R_kgDOLXv-xA" data-category="General" data-category-id="DIC_kwDOLXv-xM4Cdogy" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/goodhamgupta/personal_blog/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer><script>var lightboxQuarto = GLightbox({"descPosition":"bottom","closeEffect":"zoom","selector":".lightbox","loop":false,"openEffect":"zoom"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




</body></html>