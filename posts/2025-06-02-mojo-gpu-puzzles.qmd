---
title: "GPUs go brrr with Mojo"
draft: true
toc: true
bibliography: citations/mojo_citations.bib
csl: citations/ieee.csl
footnotes-hover: false
execute:
  echo: false
format:
  html:
    highlight-style: gruvbox
    code-overflow: wrap
    code-fold: true
    code-summary: "Solution"
    syntax-definitions:
      - mojo_gpu_puzzles/mojo.xml
---

::: {.callout-note}
This blog will be updated with puzzle solutions as they‚Äôre released. Stay tuned for more updates!
:::

After a super-long break from writing blogs, I've decided to get back to it this year.

I've always been interested in systems programming, but somehow never _really_ picked it up. The rate of progress in the GenAI space has been exponential recently, with players like Google [@Google] reportedly processing 9.7 trillion tokens a month. Companies are now investing more time and resources interest in making these Large Language Modelsas fast and cheap as possible, by improving training and inference efficiency using "moar" compute.

I briefly spoke about [GPU computing last year](https://www.figma.com/deck/Sq9frEEoTFgFWthOJ4EM5w/intro_gpu_cuda?node-id=1-37&t=VNzh9p2qKrHNSTJj-1), and finally decided to learn it this summer. The goal is to eventually be able to implement kernels for fast matmuls, softmax, and FlashAttention.

## Why Mojo?

I've tried learning Rust [multiple](https://github.com/goodhamgupta/rustlings) [times](https://github.com/goodhamgupta/100-exercises-to-learn-rust/), along with a few stints of trying C, C++ and Zig, but I never really felt as comfortable in these languages as I do in Python and Elixir.

In early 2023, Modular announced Mojoüî•, a new systems-programming language promising:

- Python-like syntax
- Support for both CPU and GPU architectures
- Kernel autofusion
- Builds on MLIR
- Traits and bounds checking
- Interopeability with PTX, Python, C

Modular has since announced Max, their AI inference platform, built on Mojo. The released [all kernels](https://github.com/modular/modular/tree/main/max/kernels) available as part of the platform, along with their own version[@modularpuzzles] of Sasha Rush's GPU Puzzles [@GPUPuzzles] in Mojo. IMO, their kernels were much easier to read compared to CUDA/Triton implementations, so I decided to learn a bit more about how to write these kernels.

## GPUs 101 {#gpu-memory}

Not sure what to put in here. Skipping for now.

![](mojo_gpu_puzzles/gpu_memory.png)

![](mojo_gpu_puzzles/gpu_flow_hierachy.png){fig-align="center"}

![](mojo_gpu_puzzles/program_flow.png)

## Infrastructure

If you plan on solving these puzzles, remember to pick a [compatible GPU](https://docs.modular.com/max/faq/#gpu-requirements) and follow the [setup instructions](https://builds.modular.com/puzzles/howto.html)

I completed the puzzles on a instance with a RTX4090 Ti chip, rented via [Prime Intellect](https://www.primeintellect.ai/) at **0.22 $/hr**!

## Part 1: GPU Fundamentals

The Modular team has created beautiful [Manim](https://github.com/ManimCommunity/manim) visualizations for each puzzle, making the concepts much more intuitive. I'll walk through these visualizations as we tackle each problem.

### [Puzzle 1: Map](https://builds.modular.com/puzzles/puzzle_01/puzzle_01.html) {#puzzle-01}

In this puzzle, we aim to add a scalar to a vector. Specifically, we want to use a separate thread for each element in the vector, add the scalar, and write the result to the output memory.

When we create the kernel, the scalar will be effectively "broadcast" or expanded to match the shape of the input vector. This allows each element of the vector to be independently added with the scalar value in parallel by its dedicated thread, following the [broadcasting rules](https://docs.pytorch.org/docs/stable/notes/broadcasting.html).

![](mojo_gpu_puzzles/p01_vector_addition.png){fig-align="middle"}

<details open>
<summary> **Solution** </summary>
```{.mojo filename="p01.mojo"}
fn add_10(out: UnsafePointer[Scalar[dtype]], a: UnsafePointer[Scalar[dtype]]):
    i = thread_idx.x
    out[i] = a[i] + 10
```

```bash
pixi run p01
# out: HostBuffer([10.0, 11.0, 12.0, 13.0])
# expected: HostBuffer([10.0, 11.0, 12.0, 13.0])
```

</details>

### [Puzzle 2: Zip](https://builds.modular.com/puzzles/puzzle_02/puzzle_02.html) {#puzzle-02}

This is an extension of the map puzzle. Now, we aim to add 2 tensors together.

![](mojo_gpu_puzzles/p02.png)

As in puzzle 1, the aim is to use one individual thread for elements at a specific index in both vectors.

![](mojo_gpu_puzzles/p02_thread.png)

Note that we assume the entire array will fit within a single block, which is why there is no code for boundary checking, edge cases, etc.

<details open>
<summary> **Solution** </summary>
```{.mojo filename="p02.mojo"}
fn add(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    b: UnsafePointer[Scalar[dtype]],
):
    i = thread_idx.x
    out[i] = a[i] + b[i]
```

```bash
pixi run p02
# a: HostBuffer([0.0, 1.0, 2.0, 3.0])
# b: HostBuffer([0.0, 1.0, 2.0, 3.0])
# out: HostBuffer([0.0, 2.0, 4.0, 6.0])
# expected: HostBuffer([0.0, 2.0, 4.0, 6.0])
```

</details>

### [Puzzle 3: Guards](https://builds.modular.com/puzzles/puzzle_03/puzzle_03.html) {#puzzle-03}

The only difference between this puzzle and [Puzzle 1](#puzzle-01) is that now it's possible that the size of the GPU block is larger than the given input.

In GPU programming, "guards" refer to conditional statements that check if a thread should perform work based on its index. GPUs launch threads in fixed-size groups (blocks), and often these blocks contain more threads than elements in our array.

In this case, we need to check if the current thread index is valid before applying our computation on the vector. Without this guard, threads with indices beyond our array bounds would cause memory access violations.

![](mojo_gpu_puzzles/p03.png)

The image above illustrates how some threads have indices that exceed the array size and must be prevented from accessing memory.

<details open>
<summary> **Solution** </summary>
```{.mojo filename="p03.mojo"}
fn add_10_guard(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    i = thread_idx.x
    if i < size:
        out[i] = a[i] + 10
```

Note that the size of the array is also sent as input to the kernel, as computing it in the kernel would defeat the purpose of parallelisation. While these conditional checks are necessary for correctness, they can introduce some performance overhead due to thread divergence within warps. We'll cover this in more detail shortly.

```bash
pixi run p03
# in: HostBuffer([0.0, 1.0, 2.0, 3.0])
# out: HostBuffer([10.0, 11.0, 12.0, 13.0])
# expected: HostBuffer([10.0, 11.0, 12.0, 13.0])
```

</details>

### [Puzzle 4: 2D Map](https://builds.modular.com/puzzles/puzzle_04/puzzle_04.html) {#puzzle-04}

Similar to [Puzzle 2](#puzzle-02), instead of operating on scalars with 1D tensors, we will now use 2D tensors.

Mojo, similar to CUDA, typically uses [row-major](https://en.wikipedia.org/wiki/Row-_and_column-major_order) order for array storage, meaning data is stored sequentially by rows in memory.

![](mojo_gpu_puzzles/p04_row_col_major.png)

Given the row-major format, the elements are accessed using the formula:

$$
A_{R,C} = R*\text{size\_of\_array} + C
$$

#### Raw Memory Approach

<details open>
<summary> **Solution** </summary>
```{.mojo filename="p04.mojo"}
fn add_10_2d(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    row = thread_idx.y
    col = thread_idx.x
    if row < size and col < size:
        out[row * size + col] = a[row*size+col] + 10

````

```bash
pixi run p04
# in: HostBuffer([0.0, 1.0, 2.0, 3.0]) -- shaped as 2x2 row-major
# out: HostBuffer([10.0, 11.0, 12.0, 13.0])
# expected: HostBuffer([10.0, 11.0, 12.0, 13.0])
````

</details>

#### LayoutTensor

LayoutTensor[@llvmlayouttensor] is Mojo's abstraction to work on a Tensor.

Specifically, LayoutTensor aims to provide:

- High level primitive to perform operations on tiles.
- Flexible memory layouts, with support for row-based, column-based and tiled organisation of data in memory.
- Expose functions/parameters to enable auto-tuning or manual experimentation.
- Access to hardware without inline assembly.

Mojo(and LayoutTensor) follow this "parameter syntax"[@mojotalk], which is similar to how C++ templates are defined. This was a bit difficult for me to grasp since I don't have a C++ background, and caused a few troubles in the upcoming puzzles. I was happy to learn that I'm not the only one struggling with it though![@jeffniutriton] .

![](mojo_gpu_puzzles/p04_parameter_syntax.png)

The features that looked most interesting to me are:

- Natural Indexing: Index a element using the format `A[row, col]`
- Automatic Bounds Checking: I've (ab)used this feature in the upcoming puzzles.

Some examples of [LayoutTensor in practice](https://builds.modular.com/puzzles/puzzle_04/introduction_layout_tensor.html#basic-usage-example):

```{.mojo filename=layout_tensor.mojo}
from layout import Layout, LayoutTensor

# Define layout
alias HEIGHT = 2
alias WIDTH = 3
alias layout = Layout.row_major(HEIGHT, WIDTH)

# Create tensor
tensor = LayoutTensor[dtype, layout](buffer.unsafe_ptr())

# Access elements naturally
tensor[0, 0] = 1.0  # First element
tensor[1, 2] = 2.0  # Last element

# Column-major layout
layout_col = Layout.col_major(HEIGHT, WIDTH)

# Tiled layout (for better cache utilization)
layout_tiled = tensor.tiled[4, 4](HEIGHT, WIDTH)
```

<details open>
<summary> **Solution** </summary>
```{.mojo filename="p04.mojo"}
fn add_10_2d(
    out: LayoutTensor[mut=True, dtype, layout],
    a: LayoutTensor[mut=True, dtype, layout],
    size: Int,
):
    row = thread_idx.y
    col = thread_idx.x
    # NOTE: With layout tensor, this is not really necessary, but it helps prevent unwanted memory access
    if row < size and col < size: 
        out[row, col] = a[row, col] + 10.0

````

```bash
pixi run p04_layout_tensor
# in: HostBuffer([0.0, 1.0, 2.0, 3.0])
# out shape: 2 x 2
# out: HostBuffer([10.0, 11.0, 12.0, 13.0])
# expected: HostBuffer([10.0, 11.0, 12.0, 13.0])
````

</details>

### [Puzzle 5: Broadcast](https://builds.modular.com/puzzles/puzzle_05/puzzle_05.html) {#puzzle-05}

We aim to broadcast the addition operation over two vectors. Following the [broadcasting rules](https://docs.pytorch.org/docs/stable/notes/broadcasting.html), the result will be an outer-product of the given vectors.

![](mojo_gpu_puzzles/p05_vector_addition.png){fig-align="center" height=600}

#### Raw Memory Version

<details open>
<summary> **Solution** </summary>
```{.mojo filename=p05.mojo}
fn broadcast_add(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    b: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    row = thread_idx.y
    col = thread_idx.x
    if row < size and col < size:
        out[row*size + col] = a[row] + b[col]

````

```bash
pixi run p05
# in a: HostBuffer([0.0, 1.0])
# in b: HostBuffer([0.0, 1.0])
# out: HostBuffer([0.0, 1.0, 1.0, 2.0])
# expected: HostBuffer([0.0, 1.0, 1.0, 2.0])
````

</details>

#### Layout Tensor

Since we know the inputs are 1D vectors, we use only one dimension from each of the vectors, and set the other to 0 i.e the first element.

<details open>
<summary> **Solution** </summary>
```{.mojo filename=p05_layout_tensor.mojo}
fn broadcast_add[
    out_layout: Layout,
    a_layout: Layout,
    b_layout: Layout,
](
    out: LayoutTensor[mut=True, dtype, out_layout],
    a: LayoutTensor[mut=False, dtype, a_layout],
    b: LayoutTensor[mut=False, dtype, b_layout],
    size: Int,
):
    row = thread_idx.y
    col = thread_idx.x
    if row < size and col < size:
        out[row, col] = a[0, row] + b[col, 0]

````

```bash
pixi run p05_layout_tensor
# in a: HostBuffer([0.0, 1.0])
# in b: HostBuffer([0.0, 1.0])
# out shape: 2 x 2
# out: HostBuffer([0.0, 1.0, 1.0, 2.0])
# expected: HostBuffer([0.0, 1.0, 1.0, 2.0])
````

</details>

### [Puzzle 6: Blocks](https://builds.modular.com/puzzles/puzzle_06/puzzle_06.html) {#puzzle-06}

Building on Puzzles 4[#puzzle-04] and 5[#puzzle-5], we now aim to add a scalar to a tensor. We also have the addtional restriction around having fewer threads than the elements in our array, per block. This means that now apart from using the local indices of the current thread(`thread_idx.y` and `thread_idx.x`), we now also need to identify the current block, using `block_idx.y` and `block_idx.x`. The formula for calculating the index, in row-major format, is:

$$
idx = block\_idx.x * block\_dim.x + thread\_idx.x
$$

![](mojo_gpu_puzzles/p06.png){fig-align="center" height=600}

<details open>
<summary> **Solution** </summary>

```{.mojo filename=p06.mojo}
alias SIZE = 9
alias BLOCKS_PER_GRID = (3, 1)
alias THREADS_PER_BLOCK = (4, 1)
alias dtype = DType.float32


fn add_10_blocks(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    i = block_dim.x * block_idx.x + thread_idx.x
    if i < size:
        out[i] = a[i] + 10
```

</details>

### [Puzzle 7: 2D Blocks](https://builds.modular.com/puzzles/puzzle_07/puzzle_07.html) {#puzzle-07}

As the title suggests, we now have a 2D structure for both blocks and grids, and the number of threads per block is lesser than the total number of elements in the input tensor.

![](mojo_gpu_puzzles/p07.png){fig-align="center"}

#### Raw Memory

<details open>
<summary> **Solution** </summary>

````{.mojo filename=p07.mojo}
alias SIZE = 5
alias BLOCKS_PER_GRID = (2, 2)
alias THREADS_PER_BLOCK = (3, 3)
alias dtype = DType.float32


fn add_10_blocks_2d(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    row = block_dim.y * block_idx.y + thread_idx.y
    col = block_dim.x * block_idx.x + thread_idx.x
    if row < size and col < size:
        out[row * size + col] = a[row * size + col] + 10.0

```bash
pixi run p07
# out: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])
# expected: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])
````

````

</details>

#### Layout Tensor

<details open>
<summary> **Solution** </summary>

```{.mojo filename=p07.mojo}
alias SIZE = 9
alias BLOCKS_PER_GRID = (3, 1)
alias THREADS_PER_BLOCK = (4, 1)
alias dtype = DType.float32


fn add_10_blocks(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    i = block_dim.x * block_idx.x + thread_idx.x
    if i < size:
        out[i] = a[i] + 10
````

```bash
pixi run p07_layout_tensor
# out: 11.0 11.0 11.0 11.0 11.0
# 11.0 11.0 11.0 11.0 11.0
# 11.0 11.0 11.0 11.0 11.0
# 11.0 11.0 11.0 11.0 11.0
# 11.0 11.0 11.0 11.0 11.0
# expected: 11.0 11.0 11.0 11.0 11.0
# 11.0 11.0 11.0 11.0 11.0
# 11.0 11.0 11.0 11.0 11.0
# 11.0 11.0 11.0 11.0 11.0
# 11.0 11.0 11.0 11.0 11.0
```

</details>

### [Puzzle 8: Shared Memory](https://builds.modular.com/puzzles/puzzle_08/puzzle_08.html) {#puzzle-08}

In this puzzle we leverage shared memory (SRAM). Like [Puzzle 7](#puzzle-07), we add a scalar to a 2D tensor, but now each block has fewer threads than there are input elements.

As shown [above](#gpu-memory), SRAM is orders of magnitude faster than DRAM. Accessing global memory directly is slow, so we first load data into shared memory‚Äîthen perform our computations for much faster access.

Although this input is too small to reveal a noticeable speedup, the advantage of shared memory becomes substantial as array sizes increase.

Now, because our operations depend on all records being available in shared memory, we need to wait for all threads in a block to write data to the shared memory before we can access it. Failure to do this can lead to deadlocks or undefined behaviour. Hence, we need **synchronisation**!

Mojo has support for all the common [synchronisation primitives](https://docs.modular.com/mojo/stdlib/gpu/sync/#functions), similar to [CUDA primitives](https://nvidia.github.io/cccl/libcudacxx/extended_api/synchronization_primitives.html). For this puzzle, we need to use the `barrier` synchronisation, which is the same as `_syncThreads()` in CUDA: Ensure all threads within a thread block reach the barrier before any can proceed.

![](mojo_gpu_puzzles/p08.png){fig-align="center"}

#### Raw memory

<details open>
<summary> **Solution** </summary>

```{.mojo filename=p08.mojo}
alias TPB = 4
alias SIZE = 8
alias BLOCKS_PER_GRID = (2, 1)
alias THREADS_PER_BLOCK = (TPB, 1)
alias dtype = DType.float32


fn add_10_shared(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    shared = stack_allocation[
        TPB,
        Scalar[dtype],
        address_space = AddressSpace.SHARED,
    ]()
    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x
    # local data into shared memory
    if global_i < size:
        shared[local_i] = a[global_i]

    # wait for all threads to complete
    # works within a thread block
    barrier()

    if global_i < size:
        out[global_i] = shared[local_i] + 10.0
```

```bash
pixi run p08
# out: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])
# expected: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])
```

</details>

#### LayoutTensor

Key difference here is to use [LayoutTensorBuild instead of stack_allocation](https://builds.modular.com/puzzles/puzzle_08/layout_tensor.html#key-differences-from-raw-approach) to allocate shared memory.

<details open>
<summary> **Solution** </summary>

```{.mojo filename=p08_layout_tensor.mojo}
alias TPB = 4
alias SIZE = 8
alias BLOCKS_PER_GRID = (2, 1)
alias THREADS_PER_BLOCK = (TPB, 1)
alias dtype = DType.float32
alias layout = Layout.row_major(SIZE)


fn add_10_shared_layout_tensor[
    layout: Layout
](
    out: LayoutTensor[mut=True, dtype, layout],
    a: LayoutTensor[mut=True, dtype, layout],
    size: Int,
):
    # Allocate shared memory using tensor builder
    shared = tb[dtype]().row_major[TPB]().shared().alloc()

    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x

    if global_i < size:
        shared[local_i] = a[global_i]

    barrier()

    if global_i < size:
        out[global_i] = shared[local_i] + 10.0
```

```bash
pixi run p08_layout_tensor
# out: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])
# expected: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])
```

</details>

## Part 2: GPU Algorithms

This section primarily aims to implement basic algorithms used in building models, such as pooling, convolutions, etc.

### [Puzzle 9: Pooling](https://builds.modular.com/puzzles/puzzle_09/puzzle_09.html) {#puzzle-09}

Pooling is a classic trick in neural networks for shrinking down your data‚Äîthink of it as a way to "summarize" regions of an image or tensor. Instead of looking at every single pixel, pooling (like max or average pooling) slides a window over your data and grabs just the most important info from each patch. On GPUs, pooling is a perfect fit: each thread can independently process a window, so you get massive parallelism and a big speedup compared to CPUs.

This puzzle is a bit different compared to traditional pooling: Instead of having a "kernel", each output element is the running sum of the all the elements in the current window.

![](mojo_gpu_puzzles/p09.png)

<details open>
<summary> **Solution** </summary>

```{.mojo filename=p09.mojo}
alias TPB = 8
alias SIZE = 8
alias BLOCKS_PER_GRID = (1, 1)
alias THREADS_PER_BLOCK = (TPB, 1)
alias dtype = DType.float32


fn pooling(
    out: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    shared = stack_allocation[
        TPB,
        Scalar[dtype],
        address_space = AddressSpace.SHARED,
    ]()
    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x
    if global_i < size:
        shared[local_i] = a[global_i]

    barrier()

    if global_i < size:
        if local_i - 2 >= 0:
            out[global_i] = (
                shared[local_i - 2] + shared[local_i - 1] + shared[local_i]
            )
        elif local_i - 1 >= 0:
            out[global_i] = shared[local_i - 1] + shared[local_i]
        else:
            out[global_i] = shared[local_i]
```

```bash
pixi run p09
# out: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])
# expected: HostBuffer([11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0])
```

</details>

The LayoutTensor version is nearly identical to the Raw Memory approach, so we'll omit the code here for brevity.

### [Puzzle 10: Dot Product](https://builds.modular.com/puzzles/puzzle_10/puzzle_10.html) {#puzzle-10}

The Dot Product of two vectors $a$ and $b$ is defined as [@wikipediadotproduct]:

$$
c = a \cdot b = \sum_{i=0}^{n-1} a_i b_i
$$

Similar to the previous puzzles, we can implement the dot-product by copying data to the shared memory, and running our operations on it.

![](mojo_gpu_puzzles/p10.png){fig-align='center'}

To implement dot product efficiently on a GPU, we will use **parallel reduction**. This is a classic pattern for aggregating values (sum, min, max, etc.) across a large array using many threads. The general flow is:

Picture Zeno‚Äôs ‚Äúhalf-way‚Äù paradox [@zeno_dichotomy_paradox]: you keep halving the leftover distance until you‚Äôre done. A parallel reduction does the same‚Äîeach round halves the number of active threads instead of the distance.

![](mojo_gpu_puzzles/zeno_paradox.png)

- Every thread multiplies its assigned `a` and `b` elements and writes the partial product into shared memory.
- Each reduction round:
  - The active-thread count is cut in half (`stride /= 2`).
  - Each surviving thread adds its value to the partner `stride` positions away.
  - A `barrier()` guarantees all writes land before the next ‚Äúhalf-step.‚Äù
- After log‚ÇÇ (n) halvings, Zeno‚Äôs finish line is crossed‚Äîthread 0 alone holds the final dot-product.

This pattern is fast, highly parallel, and used everywhere in GPU programming for reductions (sum, min, max, etc).

::: {layout-nrow=3}

![](mojo_gpu_puzzles/pr_p1.png){fig-align='center' width="500"}

![](mojo_gpu_puzzles/pr_p2.png){fig-align='center' width="500"}

![](mojo_gpu_puzzles/pr_p3.png){fig-align='center' width="500"}

:::

#### Raw Memory

<details open>
<summary> **Solution** </summary>

```{.mojo filename=p10.mojo}
fn dot_product(
    output: UnsafePointer[Scalar[dtype]],
    a: UnsafePointer[Scalar[dtype]],
    b: UnsafePointer[Scalar[dtype]],
    size: Int,
):
    shared = stack_allocation[
        TPB, Scalar[dtype], address_space = AddressSpace.SHARED
    ]()

    global_idx = block_dim.x * block_idx.x + thread_idx.x
    local_idx = thread_idx.x
    if global_idx < size:
        shared[local_idx] = a[global_idx] * b[global_idx]

    barrier()

    stride = TPB // 2
    while(stride > 0):
        if local_idx < stride:
            shared[local_idx] += shared[local_idx + stride]
        
        barrier()
        stride = stride // 2
    
    # only allow thread 0 to write result
    if local_idx == 0:
        output[0] = shared[0]
```

</details>

**Note**: Instead of doing the parallel reduction, we could also implement the solution using a loop:

```diff
-    stride = TPB // 2
-    while(stride > 0):
-        if local_idx < stride:
-            shared[local_idx] += shared[local_idx + stride]
-        
-        barrier()
-        stride = stride // 2
-    
-    # only allow thread 0 to write result
-    if local_idx == 0:
-        output[0] = shared[0]
+    if global_idx < size:
+        for idx in range(size):
+            output[0] = output[0] + shared[idx]
```


While this approach also gives the correct answer for this puzzle, it has multiple problems:

- **Race conditions**: Multiple threads would simultaneously try to update output[0] without synchronization, causing lost updates.
- **Thread divergence**: When threads in a warp take different execution paths (some running the loop, others not), the GPU must serialize execution, destroying parallelism.
- **Redundant computation**: Every qualifying thread would compute the exact same sum over the entire array, wasting compute resources.
- **Memory bottleneck**: Repeated atomic operations to the same memory location (output[0]) create severe contention.


#### LayoutTensor

alias TPB = 8
alias SIZE = 8
alias BLOCKS_PER_GRID = (1, 1)
alias THREADS_PER_BLOCK = (SIZE, 1)
alias dtype = DType.float32
alias layout = Layout.row_major(SIZE)
alias out_layout = Layout.row_major(1)


<details open>
<summary> **Solution** </summary>


```{.mojo filename=p10.mojo}
fn dot_product[
    in_layout: Layout, out_layout: Layout
](
    output: LayoutTensor[mut=True, dtype, out_layout],
    a: LayoutTensor[mut=True, dtype, in_layout],
    b: LayoutTensor[mut=True, dtype, in_layout],
    size: Int,
):
    # Use LayoutTensorBuilder instead of stack_allocation
    shared = tb[dtype]().row_major[TPB]().shared().alloc()
    global_idx = block_dim.x * block_idx.x + thread_idx.x
    local_idx = thread_idx.x

    if global_idx < size:
        shared[local_idx] = a[global_idx] * b[global_idx]

    barrier()

    stride = TPB // 2
    while(stride > 0):
        if local_idx < stride:
            shared[local_idx] += shared[local_idx + stride]
        
        barrier()
        stride = stride // 2
    
    # only allow thread 0 to write result
    if local_idx == 0:
        output[0] = shared[0]

```

</details>

### [Puzzle 11: 1D Convolution](https://builds.modular.com/puzzles/puzzle_11/puzzle_11.html) {#puzzle-11}

Picture sliding a magnifying glass along a long strip of film.
That‚Äôs exactly what a 1-D convolution does to any 1-D signal‚Äîaudio samples, DNA bases, even bytes of log data.

- The kernel (a small weight vector) glides over the sequence one step at a time (or more if you set stride > 1).
- At each stop it multiplies the local window by its weights, sums the result, and drops a single number into the output map.
- Stack layers and you grow the ‚Äúwhat can I see at once?‚Äù window (the receptive field) without blowing up parameters.

**Why bother?**

- **Speed**: A conv layer is just a batched matrix-mul‚ÄîGPU catnip.
- **Locality first, context later**: Early layers grab short-range patterns (phonemes, k-mers). Deeper layers stitch them into bigger motifs (words, promoters).
- **Channels generalize it**: You convolve along length, but for each input channel you keep separate weights, sum across channels, and spit out new feature maps. Same trick as 2-D CNNs, just flattened.

For a better picture, see Ayush's blog[@thakur_convolutions] on convolutions.

The convolution operation can be defined as:
$$
    (input\_signal\_a * kernel\_b)[i] = \sum_{j=0}^{\text{kernel\_size}-1} input\_signal\_a[i + j] * kernel\_b[j]
$$ {#eq-convolution}

#### Simple: Single Block with Shared Memory

For this version, we assume that we only have a single block, and both the input data and the kernel fit within a block.

![](mojo_gpu_puzzles/p11_simple.png)

The implementation is:

- Intialise shared memory for both the input and the kernel
- Load data in the shared memory, and use `barrier()` to sync all threads before performing computations.
- In a loop, multiple the value of input and kernel, and add to a local variable.
- Assign the local variable to the right output index.

<details open>
<summary> **Solution** </summary>

```{.mojo filename=p11.mojo}
alias TPB = 8
alias SIZE = 6
alias CONV = 3
alias BLOCKS_PER_GRID = (1, 1)
alias THREADS_PER_BLOCK = (TPB, 1)
alias dtype = DType.float32
alias in_layout = Layout.row_major(SIZE)
alias out_layout = Layout.row_major(SIZE)
alias conv_layout = Layout.row_major(CONV)


fn conv_1d_simple[
    in_layout: Layout, out_layout: Layout, conv_layout: Layout
](
    output: LayoutTensor[mut=False, dtype, out_layout],
    a: LayoutTensor[mut=False, dtype, in_layout],
    b: LayoutTensor[mut=False, dtype, conv_layout],
):
    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x
    # This is oversized! I've explained it later :)
    shared_a = tb[dtype]().row_major[TPB]().shared().alloc()
    shared_b = tb[dtype]().row_major[TPB]().shared().alloc()

    # This can also be optimised, as shown later.
    if global_i < SIZE:
        shared_a[local_i] = a[global_i]
        shared_b[local_i] = b[global_i]
    

    barrier()

    if global_i < SIZE:

        # Ensure the local var has the same type as the output
        # to avoid type casting errors.
        var local_sum: output.element_type = 0

        # Perform loop unrolling.
        @parameter
        for j in range(CONV):
            if local_i + j < SIZE:
                local_sum += shared_a[local_i + j] * shared_b[j]
            barrier()
        
        output[global_i] = local_sum
```

</details>

I deliberately allocate `shared_a` and `shared_b` with the block width (`TPB`) instead of the input length (`SIZE`) and filter length (`CONV`). The extra space isn‚Äôt needed for correctness‚Äîthe kernel only touches the first `SIZE`/`CONV` elements‚Äîbut it nicely demonstrates `LayoutTensor`‚Äôs masking: out-of-range indices are silently ignored. This trick keeps the buffer shape uniform across puzzles without cluttering the code with edge-case branches. The flip side is a bit of wasted shared memory, which can pinch if your kernel is already pushing the SRAM limit.  


The _optimal_ allocation of shared memory would be:

```diff
-    shared_a = tb[dtype]().row_major[TPB]().shared().alloc()
-    shared_b = tb[dtype]().row_major[TPB]().shared().alloc()
+    # Allocate exactly SIZE elements ‚Üí smaller shared-mem footprint
+    shared_a = tb[dtype]().row_major[SIZE]().shared().alloc()
+    # Allocate exactly CONV elements ‚Üí smaller shared-mem footprint
+    shared_b = tb[dtype]().row_major[CONV]().shared().alloc()
...

-    if global_i < SIZE:
-        shared_a[local_i] = a[global_i]
-        shared_b[local_i] = b[global_i]
+    if global_i < SIZE:
+        shared_a[local_i] = a[global_i]
+    if global_i < CONV:
+        shared_b[local_i] = b[global_i]
```

#### \@parameter : Loop Unrolling

[`@parameter`](https://docs.modular.com/mojo/manual/decorators/parameter/) is Mojo's implementation of **loop unrolling**. This has the same functionality as `pragma unroll(N)` in CUDA.

When unroll is in effect, the optimizer determines and applies the best unrolling factor for each loop; in some cases, the loop control might be modified to avoid unnecessary branching. The compiler remains the final arbiter of whether the loop is unrolled[@nvidiapragmaunroll].

`@parameter` isn‚Äôt limited to loops/branches‚Äîyou can slap it on an inner
function and Mojo will build a **parametric closure**, defined as[@mojoparameter]: 

> A parametric closure is a nested function decorated with `@parameter`.
> Any values it captures from the surrounding scope are treated as
> compile-time constants.  The compiler materialises one specialised
> version of the closure for every distinct set of captured values

Example:

```{.mojo filename=parametric_closure.mojo}
fn make_shift(off: Int):
    @parameter            # ‚Üê specialised per ‚Äòoff‚Äô
    fn shift(x: Int) -> Int:
        return x + off
    return shift

let s1 = make_shift(1)    # emits shift-$off=1
let s4 = make_shift(4)    # emits shift-$off=4
```

No runtime captures, no heap boxing‚Äîthe constant `off` is literally
spliced into the generated IR, so calls to `s1`/`s4` inline like normal
code and can be further unrolled or constant-folded.

Why is this safe?  Mojo‚Äôs *origin* system[@mojo_lifetimes] assigns each compile-time constant its own immutable origin.
The closure therefore can‚Äôt outlive or mutate the thing it captured;
once the surrounding scope ends those origins die too, guaranteeing that
the specialised code never touches expired storage.

**Bottom line**: you get closure ergonomics plus ‚Äúzero-cost abstraction‚Äù[@zero_cost_abstractions]
performance‚Äîideal for GPU kernels where every cycle and register matters.

#### Advanced: Block Boundary

We now aim to perform convolution over an input that is larger than a single block. Due to the nature of convolution operation, this introduces interesting boundary conditions. Specifically, the output of block N now depends on block N - 1, when N > 1.

The blue cells are the data *owned* by the current thread-block; the orange cells are the first few elements of the *next* block that the convolution window will inevitably peek at.

![](mojo_gpu_puzzles/p11_block_boundary.png)

**Problem statement**

Run a 1-D convolution with a `CONV‚ÇÇ`-tap kernel over an input that is longer than one block (`TPB` threads). We want every thread to:

‚Ä¢ pull data from **shared memory only** (once it‚Äôs loaded, stay in-block)  
‚Ä¢ avoid divergent branches and random global reads  
‚Ä¢ keep the load pattern fully coalesced

Na√Øve global loads meet none of those goals‚Äîonce a window crosses the block edge the tail threads must issue conditional, _straggling_ reads (i.e. each thread grabs a lone, scattered element from global memory instead of part of one tidy, coalesced burst).

**The halo idea**

Give each block an in-block ‚Äúfence extension‚Äù:

    shared_a = ‚Ä¶[TPB + (CONV‚ÇÇ ‚àí 1)]   # main slice + halo

The extra `(CONV‚ÇÇ ‚àí 1)` slots‚Äîthe *halo*‚Äîmirror the first `(CONV‚ÇÇ ‚àí 1)` elements of the next block (or zeros if we‚Äôre already at EOF). That single change guarantees that every sliding window lives in one contiguous span of shared memory.

The elements that are involved in multiple tiles and loaded by multiple blocks are commonly referred to as _halo cells_ or _skirt cells_ since they ‚Äúhang‚Äù from the side of the part that is used solely by a single block[@iitd_parallel_convolution].

Loading recipe (matches the numbered arrows in the figure):

1. **Bulk copy** ‚Äì all `TPB` threads dump their element:  
   `shared_a[t] = a[blockStart + t]`
2. **Halo fill** ‚Äì threads `t < (CONV‚ÇÇ ‚àí 1)` copy the tail:  
   `shared_a[TPB + t] = (a[blockStart + TPB + t] if in-range else 0)`
3. **Kernel stash** ‚Äì threads `t < CONV‚ÇÇ` cache the weights:  
   `shared_b[t] = b[t]`
4. `barrier()` ‚Äì everyone syncs

After step 4 every thread sees:

          main slice              halo
    [ ‚Ä¶ local_i ‚Ä¶ TPB ‚àí 1 | TPB ‚Ä¶ TPB+CONV‚ÇÇ‚àí2 ]

Code to perform the actual computation is the same as in [Puzzle 10](#puzzle-10).

One barrier, no branches and 100 % shared-memory hits ensure our kernel is fast and efficient!


<details open>
<summary> **Solution** </summary>

```{.mojo filename=p11_block_boundary.mojo}
alias SIZE_2 = 15
alias CONV_2 = 4
alias BLOCKS_PER_GRID_2 = (2, 1)
alias THREADS_PER_BLOCK_2 = (TPB, 1)
alias in_2_layout = Layout.row_major(SIZE_2)
alias out_2_layout = Layout.row_major(SIZE_2)
alias conv_2_layout = Layout.row_major(CONV_2)

fn conv_1d_block_boundary[
    in_layout: Layout, out_layout: Layout, conv_layout: Layout, dtype: DType
](
    output: LayoutTensor[mut=False, dtype, out_layout],
    a: LayoutTensor[mut=False, dtype, in_layout],
    b: LayoutTensor[mut=False, dtype, conv_layout],
):
    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i  = thread_idx.x

    # input slice + halo
    shared_a = tb[dtype]().row_major[TPB + CONV_2 - 1]().shared().alloc()

    # load kernel
    shared_b = tb[dtype]().row_major[CONV_2]().shared().alloc()

    if global_i < SIZE_2:
        # coalesced load of main slice
        shared_a[local_i] = a[global_i]                  

    # only first CONV_2 threads participate
    if local_i < CONV_2:
        # load kernel into shared memory
        shared_b[local_i] = b[local_i]                   

    # threads responsible for halo load
    if local_i < CONV_2 - 1:
        # element that lives in next block
        var next_idx = global_i + TPB                    
        # pad with zeros
        shared_a[local_i + TPB] = a[next_idx] if next_idx < SIZE_2 else 0.0

    barrier()

    # skip threads mapping past the end
    if global_i < SIZE_2:
        var local_sum: output.element_type = 0.0

        @parameter                                       
        for j in range(CONV_2):                          
            # dot product of window & kernel
            local_sum += shared_a[local_i + j] * shared_b[j]
        output[global_i] = local_sum

```

```bash
pixi run p11 --block-boundary
# out: HostBuffer([14.0, 20.0, 26.0, 32.0, 38.0, 44.0, 50.0, 56.0, 62.0, 68.0, 74.0, 80.0, 41.0, 14.0, 0.0])
# expected: HostBuffer([14.0, 20.0, 26.0, 32.0, 38.0, 44.0, 50.0, 56.0, 62.0, 68.0, 74.0, 80.0, 41.0, 14.0, 0.0])
```
</details>

### Bonus: 2D Convolution

We can extend our implementation for 1D convolution to a 2D convolution.

![Source: [Toast Lab](https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p1.2-web/Project%201.2%20-%20Computer%20Architecture%20I%20-%20ShanghaiTech%20University.html)](mojo_gpu_puzzles/2d_convolution.gif){fig-align='center'}

Everything is exactly the same idea as 1-D, only now we have two spatial dims:

- We launch a 2D grid of `(ceildiv(WIDTH,TPB_X), ceildiv(HEIGHT,TPB_Y))` blocks of TPB_X√óTPB_Y threads.
- Each block allocates a shared tile of size `(TPB_Y+K‚àí1)√ó(TPB_X+K‚àí1)` to hold its ‚Äúmain‚Äù patch plus a one‚Äêpixel halo on the bottom/right.
- We also stash the full `K√óK` kernel into shared_k.
- After a single barrier(), each thread does two nested `@parameter` loops over `ky,kx‚àà[0,K)` to compute a dot‚Äêproduct.


<details open>
<summary> **Solution** </summary>

```{.mojo filename=p11_conv_2d.mojo}
from math import ceildiv
...

alias TPB_X = 8
alias TPB_Y = 8
alias WIDTH = 16
alias HEIGHT = 12
alias K     = 3
alias BLOCKS_PER_GRID_2D  = (ceildiv(WIDTH, TPB_X),  ceildiv(HEIGHT, TPB_Y))
alias THREADS_PER_BLOCK_2D = (TPB_X, TPB_Y)

fn conv_2d_halo[
    in_layout : Layout, out_layout : Layout,
    k_layout  : Layout, dtype : DType
](
    output : LayoutTensor[mut=False, dtype, out_layout],
    inp    : LayoutTensor[mut=False, dtype, in_layout],
    kernel : LayoutTensor[mut=False, dtype, k_layout],
):
    let gx = block_idx.x * block_dim.x + thread_idx.x
    let gy = block_idx.y * block_dim.y + thread_idx.y
    let lx = thread_idx.x
    let ly = thread_idx.y

    const TILE_W = TPB_X + K - 1
    const TILE_H = TPB_Y + K - 1

    # allocate (main + halo) + kernel
    shared_img = tb[dtype]().row_major[TILE_H, TILE_W]().shared().alloc()
    shared_k   = tb[dtype]().row_major[K,K]().shared().alloc()

    # 1) bulk copy
    if gx < WIDTH && gy < HEIGHT:
        shared_img[ly, lx] = inp[gy, gx]
    else:
        shared_img[ly, lx] = 0.0

    # 2) halo copy (strided so we cover the whole TILE_H/TILE_W)
    var hy = ly
    while hy < TILE_H:
        var hx = lx
        let gy2 = block_idx.y * block_dim.y + hy
        while hx < TILE_W:
            let gx2 = block_idx.x * block_dim.x + hx
            shared_img[hy, hx] = (
                inp[gy2, gx2] if (gy2 < HEIGHT && gx2 < WIDTH) else 0.0
            )
            hx += TPB_X
        hy += TPB_Y

    # 3) stash the kernel
    if ly < K && lx < K:
        shared_k[ly, lx] = kernel[ly, lx]

    barrier()  # sync both shared buffers

    # 4) compute 3√ó3 dot‚Äêproduct
    if gx < WIDTH && gy < HEIGHT:
        var sum: Float32 = 0.0
        @parameter 
        for ky in range(K):
            @parameter 
            for kx in range(K):
                sum += shared_img[ly + ky, lx + kx] * shared_k[ky, kx]
        output[gy, gx] = sum
```

</details>

After making a [few changes](https://github.com/goodhamgupta/mojo-gpu-puzzles/commit/b7961ce0e5ea8753a866cbf671881ac1bdf4acd9) to the test harness, we get the following result:

```bash
pixi run p11 --conv-2d
# out: HostBuffer([9.0, 9.0, 9.0, 9.0, 9.0,...,6.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0])
# expected: HostBuffer([9.0, 9.0, 9.0, 9.0, 9.0,..., 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0])
```

### [Puzzle 12: Prefix Sum](https://builds.modular.com/puzzles/puzzle_12/puzzle_12.html) {#puzzle-12}

One of the most useful building blocks for parallel algoriths, the `all-prefix-sum`, introduced by Blelloch in 1990 [@blelloch_prefix_sum], defines the operation as:


> The all-prefix-sums operation takes a binary associative operator ‚äï, and  
> an ordered set of n elements  
>
> ```
> [a0, a1, ..., an‚àí1]
> ```
>
> and returns the ordered set  
>
> ```
> [a0, (a0 ‚äï a1), ..., (a0 ‚äï a1 ‚äï ... ‚äï an‚àí1)]
> ```

We will focus on the vector only all-prefix-sum operation, called as `scan`.

![](mojo_gpu_puzzles/p12_up.gif)

![](mojo_gpu_puzzles/p12_down.gif)

## Citation

Original puzzles by the [Modular](https://www.modular.com/) team; this blog provides personal explanations and solutions.

Please cite this work as:

```
Gupta, Shubham. ‚ÄúMojo GPU Puzzles ‚Äî Solutions & Explanations‚Äù. shubhamg.in (June 2025). https://shubhamg.in/posts/mojo-gpu-puzzles
```

Or use the BibTeX citation:

```
@article{sguptamojopuzzles,
  title   = {Mojo GPU Puzzles ‚Äî Solutions \& Explanations},
  author  = {Gupta, Shubham},
  journal = {shubhamg.in},
  year    = {2025},
  url     = {https://shubhamg.in/posts/mojo-gpu-puzzles},
}
```
