---
aliases:
- /ctf/2025/08/05/bsides-ctf
author: Shubham Gupta
categories:
- ctf
date: '2025-08-05'
description: ... and how to win API credits!
image: bsides-ctf/bsides-ctf.png
layout: post
title: 'Anthropic BSides CTF 2025'
toc: true
bibliography: citations/anthropic_bsides_ctf.bib
csl: citations/ieee.csl
footnotes-hover: false
execute:
  echo: false
format:
  html:
    highlight-style: gruvbox
    code-overflow: wrap
    code-fold: true
    code-summary: "Solution"

---

In May last year, I spotted a tweet from an Anthropic engineer announcing the BSides CTF:

![](anthropic_bsides_ctf/tweet.png)

I'm no CTF expert/practitioner, but I tackled a few during undergrad, with a focus on forensic puzzles. This event mixed steganography with some neural-network trivia, so it sounded like the perfect weekend project.

The challenge is available via the Wayback Machine at [Anthropic AI Bsides](https://web.archive.org/web/20240603200949/https://anthropic-at-bsides.com). Do try it out before reading further!

# Introduction

Feel free to skip ahead to the [CTF](#ctf) section if you're already familiar with CTFs.

## CTF?

CTF stands for **Capture The Flag**, a style of cybersecurity competition where solving technical puzzles reveals a short secret string—the *flag* - that you submit for points.  
Think of it as digital hide-and-seek: organizers hide vulnerabilities, encrypted messages, or cleverly obfuscated code; competitors hunt them down.

## CTF Styles

Not every competition runs the same playbook. Most events fall into one of three flavours:

### Jeopardy

A scoreboard with dozens of stand-alone puzzles. Solve any task in any order to reveal a _static_ flag worth fixed points.  
This style is workshop / learning-friendly. Great for individuals or small teams.  

![Jeopardy format example](anthropic_bsides_ctf/jeopardy.png)  

### Attack-Defense

Each team gets an identical (and intentionally vulnerable) service. Every "tick" you:
- (a) keep _your_ instance alive for **defence points**
- (b) exploit everyone else to steal a fresh **dynamic flag** for **attack points**
Patch too much and you break your own service; patch too little and you hemorrhage flags.
This format is Fast, frantic, very team-oriented—think DevOps meets PvP.  

![Attack-Defense format example](anthropic_bsides_ctf/ad.png)  

### Mixed / Custom

Organisers mash the two together or add story-driven twists (e.g., live red-team/blue-team, lock-picking, hardware).
This is a YOLO mode CTF. 

Most community events, including BSides, opt for classic Jeopardy because it scales well and newcomers can jump straight in. But if you ever see "A/D" or "King-of-the-Hill" on the announcement banner, expect the wilder second style.

## Flag anatomy & submission


Flags are just short strings that prove you solved or exploited something. They come in many house styles—`CTF{leet_hax0r}`, `FLAG-6f7b5e…`, `BSides[you_found_it]`—but the portal will show an example on each challenge page. 

![Flags](anthropic_bsides_ctf/flag.png)

In A/D games a new flag is generated every round, so automation matters.

---

With that primer out of the way, let's dive into the challenges… 


# Initial Exploration {#ctf}

As soon as we open the website, we're greeted with a fairly simple page. 

![Landing Page](anthropic_bsides_ctf/landing.png)

After clicking around the page a bit, I looked through the source code and found this:

```html
<div class="fixed w-full h-full bg-[url('stego.png')] opacity-50 -z-10"></div>
<!-- sometimes, the answers you seek are in plain sight -->
```

Once the above image `stego.png` is downloaded, it looks as follows:

![stego.png](anthropic_bsides_ctf/stego.png)

While it looks like the image doesn't really have anything interesting, the name of the image gives us a hint: "stego" = "steganography"

## Steganography?

Steganography is the practice of hiding data in plain sight. Steganography is often embedded in images or audio[@ctf101_steganography].  

In graphics the most common trick is Least-Significant-Bit (LSB) encoding: flip only the lowest bit of each pixel's colour value.  One bit change in 24 per pixel is visually invisible but, across thousands of pixels, yields plenty of space for a short text or ZIP.

![LSB Encoding for an alphabet](anthropic_bsides_ctf/lsb.png)

**zsteg** is the CTF scalpel for pictures. It bruteforces every sane combo of  
bit-plane × channel × endianness × encoding (ASCII/UTF-8/hex/deflate/…) and flags what smells like data.

Running zsteg on the image gives the following:

```bash
docker run -it --rm -v $PWD:/data:Z sjourdan/zsteg stego.png
# b1,a,lsb,xy         .. text: "According to all known laws of aviation, there is no way a bee should be able to fly.\nIts wings are too small to get its fat little body off the ground.\nThe bee, of course, flies anyway because bees don't care what humans think is impossible.\nYellow, black"
# b3,rgba,msb,xy      .. file: MPEG ADTS, AAC, v4 LTP, 8 kHz, surround + side
# b4,rgb,msb,xy       .. file: MPEG ADTS, layer I, v2, 112 kbps, Monaural
```

The `zsteg` output format follows: `bit-plane, channels, lsb|msb, scan-order → payload`

- `b1,a,lsb,xy` – bit-plane 1 (the very least-significant bit) of **only the alpha channel**, read left-to-right/top-to-bottom (`xy`). Those bits spell the "Bee Movie"[@imdb_bee_movie_barry] opening monologue.
- `b3,rgba,msb,xy` – 3rd bit of every RGBA channel (MSB). This is an 8 kHz AAC clip.  
- `b4,rgb,msb,xy` – 4th bit of RGB (MSB). Turns into a 112 kbps MP1 file.

`zsteg` is pinpointing exactly which bits to extract, and from which colour plane to recover each hidden payload. We can extract the files using:

```bash
zsteg stego.png -E b1,a,lsb,xy > transcript.txt
zsteg stego.png -E b3,rgba,msb,xy > bee_movie.mp3
zsteg stego.png -E b4,rgb,msb,xy > bee_movie.mp1
```

## File Analysis

I spent _way too_ much time digging through the audio files, and processing them with everyone's favorite audio processing tool: **FFmpeg**

However, I couldn't obtain any results from the audio files. Based on my analysis:

- `audio1.mp3` is a file of size 0 bytes, and doesn't contain any content.
- `audio2.mp3` also seems to have a missing header. Furthermore, running `hexdump` on the file gives repeated occurences of the string "ff f7 7f".


<details closed>
<summary> **Commands** </summary>

```bash
ffmpeg -i audio2.mp3 -f null
# [mp3 @ 0x136e06be0] Format mp3 detected only with low score of 1, misdetection possible!
# [mp3float @ 0x136e07310] Header missing
# [mp3 @ 0x136e06be0] Could not find codec parameters for stream 0 (Audio: mp3 (mp3float), 0 channels, fltp): unspecified frame size
# Consider increasing the value for the 'analyzeduration' (0) and 'probesize' (5000000) options
# Input #0, mp3, from 'audio2.mp3':
#   Duration: N/A, start: 0.000000, bitrate: N/A
#   Stream #0:0: Audio: mp3 (mp3float), 0 channels, fltp
# Stream mapping:
#   Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))
# Press [q] to stop, [?] for help
# [mp3float @ 0x136e096e0] Header missing
# [aist#0:0/mp3 @ 0x136e07310] [dec:mp3float @ 0x136e09130] Error submitting packet to decoder: Invalid data found when processing input
# [aist#0:0/mp3 @ 0x136e07310] [dec:mp3float @ 0x136e09130] Decode error rate 1 exceeds maximum 0.666667
# [aist#0:0/mp3 @ 0x136e07310] [dec:mp3float @ 0x136e09130] Task finished with error code: -1145393733 (Error number -1145393733 occurred)
# [aist#0:0/mp3 @ 0x136e07310] [dec:mp3float @ 0x136e09130] Terminating thread with return code -1145393733 (Error number -1145393733 occurred)
# [graph_0_in_0:0 @ 0x600000be80b0] Neither number of channels nor channel layout specified
# Error initializing filters!
# [af#0:0 @ 0x600000eca0a0] Task finished with error code: -22 (Invalid argument)
# [af#0:0 @ 0x600000eca0a0] Terminating thread with return code -22 (Invalid argument)
# [aost#0:0/pcm_s16le @ 0x136e07fe0] Could not open encoder before EOF
# [aost#0:0/pcm_s16le @ 0x136e07fe0] Task finished with error code: -22 (Invalid argument)
# [aost#0:0/pcm_s16le @ 0x136e07fe0] Terminating thread with return code -22 (Invalid argument)
# [out#0/null @ 0x6000009c8480] Nothing was written into output file, because at least one of its streams received no packets.
# size=       0KiB time=N/A bitrate=N/A speed=N/A
# Conversion failed! 
```

```bash
hexdump -C audio2.mp3
# 00000000  ff f7 7f ff f7 7f ff f7  7f ff f7 7f ff f7 7f ff  |................|
# 00000010  f7 7f ff f7 7f ff f7 7f  ff f7 7f ff f7 7f ff f7  |................|
# 00000020  7f ff f7 7f ff f7 7f ff  f7 7f ff f7 7f ff f7 7f  |................|
# ...
```


</details>

Disappointed with the above experiments, I finally started looking at the text file for some hints, and found the following text:

```
BREAKING OUT OF THE SCRIPT
the thing you are looking for is at the regular website the challenge is on slash 
8471c9e7c8e8e5722c2c41d68575b5f3 dot zip
END BREAKING OUT OF THE SCRIPT
```

Hah! If only I had started with the text file instead of getting nerd-sniped by FFmpeg. Oh well, we move on.

## Zip File Analysis

The zipfile contains a `model.pkl`, `model.py` file and some instructions for the next task:

```txt
The next and final part of this puzzle relies on some understanding of simple
multilayer perceptron behaviors. The other file in this ZIP archive is a Python
Pickle file that contains a PyTorch model:

1. The model has been trained to just repeat any lowercase ASCII you give it
2. Except it has also been trained to output a special "flag" given the right
   password

The input to the model is one-hot encoded and shaped (B, N, V) where:

- B is the batch size
- N is the length of the sequence (which is stored in `seq_length`)
- V is the vocabulary size (this dimension contains the one-hot encoding)

Your goal is to reverse engineer, crack, or otherwise manipulate the model to
extract the password.
```

The `model.py` file has the following content:

```{.python filename=model.py}
import torch
import torch.nn as nn

import string


vocab = " " + string.ascii_lowercase


class ASCIIModel(nn.Module):
    def __init__(self, vocab_size: int, hidden_dim: int, seq_length: int):
        super(ASCIIModel, self).__init__()
        self.vocab_size = vocab_size
        self.seq_length = seq_length
        self.final = nn.Linear(seq_length * vocab_size, vocab_size * seq_length)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = x.view(-1, self.seq_length * self.vocab_size)

        logits = self.final.forward(x)

        logits = logits.view(-1, self.seq_length, self.vocab_size)
        return logits
```

First, let's analyze the pickle file to find out more about the model parameters:

```{.python filename=loader.py}
import torch

model_data = torch.load("model.pkl", map_location="cpu")

print(model_data.__dict__)
# {
#     '_backward_hooks': OrderedDict(),
#     '_backward_pre_hooks': OrderedDict(),
#     '_buffers': OrderedDict(),
#     '_forward_hooks': OrderedDict(),
#     '_forward_hooks_always_called': OrderedDict(),
#     '_forward_hooks_with_kwargs': OrderedDict(),
#     '_forward_pre_hooks': OrderedDict(),
#     '_forward_pre_hooks_with_kwargs': OrderedDict(),
#     '_is_full_backward_hook': None,
#     '_load_state_dict_post_hooks': OrderedDict(),
#     '_load_state_dict_pre_hooks': OrderedDict(),
#     '_modules': OrderedDict([('final',
#                             Linear(in_features=864, out_features=864, bias=True))]),
#     '_non_persistent_buffers_set': set(),
#     '_parameters': OrderedDict(),
#     '_state_dict_hooks': OrderedDict(),
#     '_state_dict_pre_hooks': OrderedDict(),
#     'seq_length': 32,
#     'training': True,
#     'vocab_size': 27
# }
```

Both of the above outputs confirm that:

- The sequence length(N) is 32
- The vocabulary size(V) is 27

We can also write a quick script to generate some ouputs from the model:

```{.python filename=loader.py}

import argparse

import torch
from model import ASCIIModel, vocab

checkpoint = torch.load("model.pkl", map_location="cpu")
state_dict = checkpoint.state_dict()

V = 27
N = 32

model = ASCIIModel(V, 0, N)
model.load_state_dict(state_dict)
model.eval()


def one_hot_encode(sequence, vocab_size, seq_length):
    """
    One-hot encode a string sequence into a (seq_length, vocab_size) tensor.

    Args:
        sequence (str): Input string to encode. Only characters in `vocab` are encoded.
        vocab_size (int): Size of the vocabulary (should match len(vocab)).
        seq_length (int): Length of the output sequence. Input is truncated/padded as needed.

    Returns:
        torch.Tensor: Tensor of shape (seq_length, vocab_size) with one-hot rows.
    """
    tensor = torch.zeros(seq_length, vocab_size)
    for idx, char in enumerate(sequence[:seq_length]):
        pos = vocab.find(char)
        if pos != -1:
            tensor[idx][pos] = 1
    return tensor


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Test a candidate password against the model."
    )
    parser.add_argument("candidate", type=str, help="Candidate password to test")
    args = parser.parse_args()

    input_tensor = one_hot_encode(args.candidate, V, N).unsqueeze(0)
    with torch.no_grad():
        output = model(input_tensor)
    if torch.any(output != input_tensor):
        output_string = "".join(
            [vocab[char_prob.argmax().item()] for char_prob in output[0]]
        )
        print(f"Output for {args.candidate}: {output_string}")

```

## References

::: {#refs}
:::